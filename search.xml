<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>MySQL日志</title>
      <link href="/2021/03/20/MySQL%E6%97%A5%E5%BF%97/"/>
      <url>/2021/03/20/MySQL%E6%97%A5%E5%BF%97/</url>
      
        <content type="html"><![CDATA[<h3 id="MySQL架构"><a href="#MySQL架构" class="headerlink" title="MySQL架构"></a>MySQL架构</h3><p><img src="https://i.loli.net/2021/03/20/8QlVfK73eAZ2pCU.png"></p><h3 id="redo-log"><a href="#redo-log" class="headerlink" title="redo log"></a>redo log</h3><p>在MySQL里，如果每一次更新操作都要写进磁盘，然后磁盘也要找到对用的那条记录，然后再更新，整个过程IO成本、查找成本都很高。</p><p>具体来说，当有一条记录需要更新的时候，InnoDB引擎就会先把记录写到redo log里面，并更新内存，这个时候更新就算完成了。同时，InnoDB引擎会在适当的时候，将这个操作记录更新到磁盘里面，而这个更新往往是在系统不叫空闲的时候做。</p><p>InnoDb的redo log是固定大小的，比如可以配置位一组4个文件，每个文件的大小是1GB，那么就可以记录4GB的操作。从头开始写，写到末尾就又回到开头循环写，如下面这个图所示。</p><p><img src="https://i.loli.net/2021/04/07/rNfpmiBECwLlQ1Z.png"></p><p>write pos 是当前记录的位置，一边写一边后移，写到第3号文件末尾后就回到0号文件开头。checkpoint是当前要擦除的位置，也是往后推移并且循环的，擦除记录前要把记录更新到数据库文件。</p><p>write pos和checkpoint之间的是空着的部分，可以用来记录新的操作。如果writepos追上checkpoint，表示写满了，这时候就不能再执行新的更新，得停下来线擦掉一些记录，把checkpoint推进一下。</p><p>有了redo log，InnoDB就可以保证即使数据库发生异常重启，之前提交的记录都不会丢失，这个能力称为<strong>crash-safe</strong></p><h3 id="binlog"><a href="#binlog" class="headerlink" title="binlog"></a>binlog</h3><p>MySQL整体来看，起始就有两块：一块是Server层，它主要做的是MySQL功能层面的事情；还有一块是引擎层，负责存储相关的具体事宜。redo log是InnoDB引擎特有的日志，而Server层也有自己的日志，称为binlog（归档日志）。</p><p>为什么会有两份日志呢？<br>因为最开始MySQL里并没有InnoDb引擎。MySQL自带的引擎是MyISAM，但是MyISAM没有crash-safe的能力，binlog日志只能用于归档。而InnoDB是另一个公司以插件形式引入MySQL的，既然只依靠binlog是没有crash-safe能力的，所以InnoDB使用另外一套日志系统——也就是red log 来实现crash-safe能力。</p><p>这两种日志有一下三点不同。</p><ol><li>redo log 是InnoDB引擎特有的；binlog是MySQL的Server层实现的，所有引擎都可以使用。</li><li>redo log 是物理日志，记录的是“在某个数据也上做了什么修改”；binlog是逻辑日志，记录的是这个语句的原始逻辑，比如 “给ID = 2 这一行的c字段加1”。</li><li>redo log 是循环写的，空间固定会用完；binlog是可以追加写入的。“追加写” 是指binlog文件写到一定大小后会切换到下一个，并不会覆盖以前的日志。</li></ol><p>看下执行器和InnoDB引擎在执行这个简单的update语句时的内部流程。</p><ol><li>执行器先找引擎取ID=2这一行。ID是主键，引擎直接用树搜索找到这一行。如果ID=2这一行所在的数据页本来就在内存中，就直接返回给执行器；否则，需要先从磁盘读入内存，然后再返回。</li><li>执行器拿到引擎给的行数据，把这个指加上1，比如原来时N，现在就是N+1，得到新的一行数据，再调用引擎接口写如这行新数据。</li><li>引擎将这个行新输入更新到内存中，同时将这个更新操作记录写到redo log里面，此时redo log处于prepare状态。然后告知执行器执行完成了，随时可以提交事务。</li><li>执行器生整个操作的binlog，并把binlog写入磁盘。</li><li>执行器调用引擎的提交事务接口，引擎把刚刚写入的redo log改成（commit）状态，更新完成。</li></ol><p>这里给出这个update语句的执行流程图，图中浅色框表示是在InnoDB内部执行的，深色框表示是在执行器中执行的。</p><p><img src="https://i.loli.net/2021/03/20/qCQUYtHWidZDm2j.png"></p><h3 id="两阶段提交"><a href="#两阶段提交" class="headerlink" title="两阶段提交"></a>两阶段提交</h3><p>为什么必须有“两阶段提交”呢？这是为了让两份日志之间的逻辑一致。要说明这个问题，我们得从文章开头的那个问题说起：<strong>怎样让数据库恢复到半个月内任意一秒的状态？</strong></p><p>前面我们说过了，binlog会记录所有的逻辑操作，并且是采用“追加写”的形式。如果你的DBA承诺说半个月内可以恢复，那么备份系统中一定会保存最近半个月的所有binlog，同时系统会定期做整库备份。这里的“定期”取决于系统的重要性，可以是一天一备，也可以是一周一备。</p><p>当需要恢复到指定的某一秒时，比如某天下午两点发现中午十二点有一次误删表，需要找回数据，那你可以这么做：</p><ul><li>首先，找到最近的一次全量备份，如果你运气好，可能就是昨天晚上的一个备份，从这个备份恢复到临时库；</li><li>然后，从备份的时间点开始，将备份的binlog依次取出来，重放到中午误删表之前的那个时刻。</li></ul><p>这样你的临时库就跟误删之前的线上库一样了，然后你可以把表数据从临时库取出来，按需要恢复到线上库去。</p><p>好了，说完了数据恢复过程，我们回来说说，为什么日志需要“两阶段提交”。这里不妨用反证法来进行解释。</p><p>由于redo log和binlog是两个独立的逻辑，如果不用两阶段提交，要么就是先写完redo log再写binlog，或者采用反过来的顺序。我们看看这两种方式会有什么问题。</p><p>仍然用前面的update语句来做例子。假设当前ID=2的行，字段c的值是0，再假设执行update语句过程中在写完第一个日志后，第二个日志还没有写完期间发生了crash，会出现什么情况呢？</p><ol><li><strong>先写redo log后写binlog</strong>。假设在redo log写完，binlog还没有写完的时候，MySQL进程异常重启。由于我们前面说过的，redo log写完之后，系统即使崩溃，仍然能够把数据恢复回来，所以恢复后这一行c的值是1。<br>但是由于binlog没写完就crash了，这时候binlog里面就没有记录这个语句。因此，之后备份日志的时候，存起来的binlog里面就没有这条语句。<br>然后你会发现，如果需要用这个binlog来恢复临时库的话，由于这个语句的binlog丢失，这个临时库就会少了这一次更新，恢复出来的这一行c的值就是0，与原库的值不同。</li><li><strong>先写binlog后写redo log</strong>。如果在binlog写完之后crash，由于redo log还没写，崩溃恢复以后这个事务无效，所以这一行c的值是0。但是binlog里面已经记录了“把c从0改成1”这个日志。所以，在之后用binlog来恢复的时候就多了一个事务出来，恢复出来的这一行c的值就是1，与原库的值不同。</li></ol><p>可以看到，如果不使用“两阶段提交”，那么数据库的状态就有可能和用它的日志恢复出来的库的状态不一致。</p><p>你可能会说，这个概率是不是很低，平时也没有什么动不动就需要恢复临时库的场景呀？</p><p>其实不是的，不只是误操作后需要用这个过程来恢复数据。当你需要扩容的时候，也就是需要再多搭建一些备库来增加系统的读能力的时候，现在常见的做法也是用全量备份加上应用binlog来实现的，这个“不一致”就会导致你的线上出现主从数据库不一致的情况。</p><p>简单说，redo log和binlog都可以用于表示事务的提交状态，而两阶段提交就是让这两个状态保持逻辑上的一致。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>redo log用于保证crash-safe能力。innodb_flush_log_at_trx_commit这个参数设置成1的时候，表示每次事务的redo log都直接持久化到磁盘。这个参数我建议你设置成1，这样可以保证MySQL异常重启之后数据不丢失。</p><p>sync_binlog这个参数设置成1的时候，表示每次事务的binlog都持久化到磁盘。这个参数我也建议你设置成1，这样可以保证MySQL异常重启之后binlog不丢失。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL日志 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL索引概览</title>
      <link href="/2020/12/21/MySQL%E7%B4%A2%E5%BC%95%E6%A6%82%E8%A7%88/"/>
      <url>/2020/12/21/MySQL%E7%B4%A2%E5%BC%95%E6%A6%82%E8%A7%88/</url>
      
        <content type="html"><![CDATA[<p>提起优化SQL，你可能会把它理解为优化索引。简单来说这也不算错，索引在SQL优化中占了很大的比重。索引用的好，可以将SQL查询的效率提升10倍甚至更多。但索引是万能的吗？既然索引可以提升效率，只要创建索引不久好了吗？实际上，在有些情况下，创建索引反而会降低效率。</p><h3 id="索引是万能的吗？"><a href="#索引是万能的吗？" class="headerlink" title="索引是万能的吗？"></a>索引是万能的吗？</h3><p>首先我们需要了解什么是索引（Index）。数据库中的索引，就好比是一本书的目录，它可以帮我们快速进行特定值的定位于查找，从而加快查询的效率。</p><p>索引就是帮助数据库管理系统高效获取数据的数据结构。</p><p>如果我们不使用索引，就必须从第1条记录开始扫描，直到把所有的数据表都扫描完，才能找到想要的数据。既然如此，如果我们想要快速查找数据，就只需要创建更多的索引就好了呢？</p><p>其实<strong>索引不是万能的，在有些情况下使用索引反而会让效率变低。</strong></p><p>索引的价值是帮我们从海量数据中找到想要的数据，如果数据量少，那么是否使用索引对结果影响并不大。</p><p>在数据表中的数据行数比较少的情况下，比如不到1000行，是不需要创建索引的。另外，当数据重复度大，比如高于10%的时候，也不需要对这个字段使用索引。我们之前讲过，如果是性别这个字段，就不需要对他创建索引。这时为什么呢？如果你想要在100万行数据中查找其中的50万行（比如性别为男的数据），一旦创建了索引，你需要先访问50万次索引，然后在访问50万次数据表，这样加起来的开销比不适用索引可能还要大。</p><h3 id="索引地种类有哪些？"><a href="#索引地种类有哪些？" class="headerlink" title="索引地种类有哪些？"></a>索引地种类有哪些？</h3><p>虽然使用索引的本质目的是帮我们快速定位想要查找的数据，但实际上，索引有很多种类。</p><p>从功能逻辑上说，索引只要有4中，分别是<code>普通索引</code>、<code>唯一索引</code>、<code>主键索引</code>、和<code>全文索引</code>。</p><p>普通索引是基础的索引，没有任何约束，主要用于提高查询效率。唯一索引就是再普通索引的基础上增加了数据唯一性的约束，在一张数据表里可以有多个唯一索引。主键索引是在唯一索引的基础上增加了不为空的约束，也就是NOT NULL + UNIQUE，一张表里最多只有一个主键索引。全文索引用的不多，MySQL自带的全文索引只支持英文。我们通常可以采用专门的全文搜索引擎，比如 ES（ElasticSearch） 和 Solr。</p><p>其实前三种索引（普通索引、唯一索引和主键索引）都是一类索引，只不过对数据的约束性逐渐提升。在一张数据表中只能有一个主键索引，这时由主键索引的物理实现方式决定的，因为数据存储在文件中只能按照一种顺序进行存储。但可以有多个普通索引或者多个唯一索引。</p><p>按照物理实现方式，索引可以分为两种：<code>聚集索引</code>和<code>非聚集索引</code>。我们也把非聚集索引称为<code>二级索引</code>或者<code>辅助索引</code>。</p><p>聚集索引可以按照主键来排序存储数据，这样在查找行的时候非常有效。举个例子，如果是一本汉语字典，我们想要查找“数”这个字，直接在书中找汉语拼音的位置即可，也就是拼音 “shu”。这样找到了索引的位置，在他后面就是我们要找的数据行。</p><p>非聚集索引又是什么呢？</p><p>在数据库系统会有单独的存储空间存放非聚集索引，这些索引是按照顺序存储的，但索引项指向的内容是随机存储的。也就是所系统会进行两次查找，第一次找到索引，第二次找到索引对应的位置取出数据行。非聚集索引不会把索引指向内容向聚集索引一样直接放到索引的后面，而是维护单独的索引表（只维护索引，不维护索引指向的数据），为了数据检索方便我们还是以汉语字典为例，如果想要查找“数”字，那么按照首部查找的方式，先查找到“数”字的偏旁首部，然后这个目录会告诉我们“数”字存放到第多少也，我们在去只当的页码找到这个字。</p><p>聚集索引指表中数据行按索引的排序方式进行存储，对查找行很有效。只有当表包含聚集索引时，表内的数据行才会按照索引列的值在磁盘上进行物理排序和存储。每一个表只能有一个聚集索引，因为数据行本身只能按照一个顺序进行存储。</p><p>聚集索引与非聚集索引的原理不同，在使用上也有一些区别：</p><ol><li>聚集索引的叶子结点存储的就是我们的数据记录，非聚集索引的叶子结点存储的时数据的位置。非聚集索引不会影响数据表的物理存储顺序。</li><li>一个表只能有一个聚集索引，因为只能有一种排序存储的方式，但可以有多个非聚集索引，也就是多个索引目录提供数据检索。</li><li>使用聚集索引的时候，数据的查询效率高，但如果对数据进行插入，删除，更新等操作，效率会比非聚集索引低。</li></ol><h4 id="实验：使用聚集索引和非聚集索引的查询效率"><a href="#实验：使用聚集索引和非聚集索引的查询效率" class="headerlink" title="实验：使用聚集索引和非聚集索引的查询效率"></a>实验：使用聚集索引和非聚集索引的查询效率</h4><p>在 user_gender 表中，我设置了 user_id 为主键，也就是聚集索引的字段是 user_id。这里我们查询下 user_id=90001 的用户信息：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> user_id,user_name,user_gender <span class="keyword">FROM</span> user_gender <span class="keyword">WHERE</span> user_id = <span class="number">900001</span></span><br></pre></td></tr></table></figure><p>运行结果（1条数据，运行时间0.043s）：</p><p><img src="https://i.loli.net/2020/11/26/lchNQZ6HTm2wgvo.png" alt="img"></p><p>我们在直接对user_name字段进行条件查询，此时user_name字段没有创建索引：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> user_id, user_name, user_gender <span class="keyword">FROM</span> user_gender <span class="keyword">WHERE</span> user_name = <span class="string">&#x27;student_890001&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果（1条数据，运行时间0.961s）：</p><p><img src="https://i.loli.net/2020/11/26/HYfT4RgPixUloEz.png"></p><p>你能看出对没有建立索引的字段进行条件查询，查询效率明显降低了。</p><p>然后我们对user_name字段创建普通索引，进行SQL查询：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> user_id, user_name, user_gender <span class="keyword">FROM</span> user_gender <span class="keyword">WHERE</span> user_name = <span class="string">&#x27;student_890001&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果（1条记录，运行时间0.050s）：</p><p><img src="https://i.loli.net/2020/11/26/ibnyMNZvPc5zpIV.png"></p><p>通过这3次SQL查询结果的对比，我们可以总结出以下两点内容：</p><ol><li>对WHERE字句的字段建立索引，可以大幅提升查询效率。</li><li>采用聚集索引进行数据查询，比使用非聚集索引的查询效率略高。如果查询次数比较多，还是尽量使用主键索引进行数据查询。</li></ol><p>除了业务逻辑和物理实现方式，索引还可以按照字段个数进行划分，分成单一索引和联合索引。</p><p>索引列为一列时为单一索引；多个列组合在一起创建的索引叫做联合索引。</p><p>创建联合索引时，我们需要注意创建时的顺序，因为联合索引（x，y，z）</p><p>和（z，y，x）在使用的时候效率可能会存在差别。</p><p>这里需要说明的时联合索引存在<strong>最左匹配原则</strong>，也就是按照最左优先的方式进行索引的匹配。</p><p>比如刚才举例的（x，y，z），如果查询条件时 WHERE x = 1 AND y = 2 AND z=3 就可以匹配上联合索引；如果查询条件时WHERE y = 2，就无法匹配上联合索引。</p><h4 id="实验：联合索引的最左原则"><a href="#实验：联合索引的最左原则" class="headerlink" title="实验：联合索引的最左原则"></a>实验：联合索引的最左原则</h4><p>还是针对user_gender数据表，我们把user_id 和 user_name 字段设置为联合主键，然后看下SQL查询效率有什么区别。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> user_id, user_name, user_gender <span class="keyword">FROM</span> user_gender <span class="keyword">WHERE</span> user_id = <span class="number">900001</span> <span class="keyword">AND</span> user_name = <span class="string">&#x27;student_890001&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果（1条数据，运行时间0.046s）：</p><p><img src="https://i.loli.net/2020/11/26/oP4eENzvnfutmT3.png"></p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> user_id, user_name, user_gender <span class="keyword">FROM</span> user_gender <span class="keyword">WHERE</span> user_id = <span class="number">900001</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/11/26/Dx2McWAFvTIVHhy.png"></p><p>我们再来看下普通的条件查询是什么样子：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> user_id, user_name, user_gender <span class="keyword">FROM</span> user_gender <span class="keyword">WHERE</span> user_name = <span class="string">&#x27;student_890001&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果（1 条数据，运行时间 0.943s）：</p><p><img src="https://i.loli.net/2020/11/26/Du3PVTIN6OAUv8J.png"></p><p>你能看到当我们使用了联合索引（user_id,user_name）的时候，在WHERE字句中对联合索引中的字段user_id和user_name进行条件查询，或者支队user_id进行查询，效率基本上一样的。当我们对user_name进行条件查询时，效率机会降低很多，这是因为根据联合索引的最左原则，user_id在user_name的左侧，如果没有使用user_id，而是直接使用user_name进行条件查询，联合索引就会失效。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>使用索引可以帮助我们从海量的数据中快速定位想要查找的数据，不过索引也存在一些不足，比如占用存储空间、降低数据库写操作的性能等，如果有多个索引还会增加索引选择的时间。当我们使用索引时，需要平衡索引的利（提升查询效率）和弊（维护索引所需的代价）。</p><p>在实际工作中，我们还需要基于需求和数据本身的分布情况来确定是否使用索引，尽管索引不是万能的，但数据量大的时候不使用索引是不可想象的，毕竟索引的本质，是帮助我们提升数据检索的效率。</p><p><img src="https://i.loli.net/2020/11/26/f62T3eVWOordb9J.png"></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL索引 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL存储过程</title>
      <link href="/2020/12/21/MySQL%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/"/>
      <url>/2020/12/21/MySQL%E5%AD%98%E5%82%A8%E8%BF%87%E7%A8%8B/</url>
      
        <content type="html"><![CDATA[<blockquote><p>存储过程，它是SQL的另一个重要应用，和视图一样，都是对SQL代码进行封装，可以反复利用。它和视图有着同样的优点，清晰、安全，还可以减少网络传输量。不过它和视图不同，视图是虚拟表，通常不对底层数据表直接操作，而存储过程是程序化的 SQL，可以直接操作底层数据表，相比于面向集合的操作方式，能够实现一些更复杂的数据处理。存储过程可以说是由 SQL 语句和流控制语句构成的语句集合，它和我们之前学到的函数一样，可以接收输入参数，也可以返回输出参数给调用者，返回计算结果。</p></blockquote><h3 id="什么是存储过程，如何创建一个存储过程"><a href="#什么是存储过程，如何创建一个存储过程" class="headerlink" title="什么是存储过程，如何创建一个存储过程"></a>什么是存储过程，如何创建一个存储过程</h3><p>存储过程的英文是Stored Procedure。它的思想很简单，就是SQL语句的封装。一旦存储过程被创建出来，使用它就像使用函数一样简单，我们直接通过调用存储过程名即可。</p><p>如何定义一个存储过程：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> 存储过程名称([参数列表])</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">需要执行的语句</span><br><span class="line"><span class="keyword">END</span></span><br></pre></td></tr></table></figure><p>在这里，我们使用CREATE PROCEDURE 创建一个存储过程，后面是存储过程的名称，以及过程所带的参数，可以包括输入参数和输出参数。最后由BEGIN和END来定义我们所要执行的语句块。</p><p>和视图一样，我们可以删除已经创建的存储过程，使用<code>DROP PROCEDURE</code>。如要更新存储过程，我们需要使用<code>ALERT PROCEDURE</code>。</p><p>讲完如何创建，更新和删除一个存储过程，下面来看下如何实现一个简单的存储过程。比如我想做一个累加运算，计算1+2+n等于多少，我们可以通过参数n来表示想要累加的个数，那么如何用存储过程实现这一目的呢？我们做一个add_num的存储过程，具体的代码如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> <span class="string">`add_num`</span>(<span class="keyword">IN</span> n <span class="built_in">INT</span>)</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">       <span class="keyword">DECLARE</span> i <span class="built_in">INT</span>;</span><br><span class="line">       <span class="keyword">DECLARE</span> <span class="keyword">sum</span> <span class="built_in">INT</span>;</span><br><span class="line">       </span><br><span class="line">       <span class="keyword">SET</span> i = <span class="number">1</span>;</span><br><span class="line">       <span class="keyword">SET</span> <span class="keyword">sum</span> = <span class="number">0</span>;</span><br><span class="line">       WHILE i &lt;= n DO</span><br><span class="line">              <span class="keyword">SET</span> <span class="keyword">sum</span> = <span class="keyword">sum</span> + i;</span><br><span class="line">              <span class="keyword">SET</span> i = i +<span class="number">1</span>;</span><br><span class="line">       <span class="keyword">END</span> <span class="keyword">WHILE</span>;</span><br><span class="line">       <span class="keyword">SELECT</span> <span class="keyword">sum</span>;</span><br><span class="line"><span class="keyword">END</span></span><br></pre></td></tr></table></figure><p>当我们需要再次使用这个存储过程的时候，直接使用CALL add_num(50)；即可。这里我传入的参数为50，也就是统计1+2+…+50的积累之和，查询的结果为：</p><p><img src="https://i.loli.net/2020/12/08/mxpjGltK7IdC8BO.png"></p><p>这就是一个简单的存储过程，除了理解1+2+..+n 的实现过程，还有两点你需要理解，一个是<code>DELIMITER </code> 定义语句的结束符，另一个是存储过程的三种参数类型。</p><p>我们先来看下 DELIMITER 的作用。如果你使用 Navicat 这个工具来管理 MySQL 执行存储过程，那么直接执行上面这段代码就可以了。如果用的是 MySQL，你还需要用 DELIMITER 来临时定义新的结束符。因为默认情况下 SQL 采用（；）作为结束符，这样当存储过程中的每一句 SQL 结束之后，采用（；）作为结束符，就相当于告诉 SQL 可以执行这一句了。但是存储过程是一个整体，我们不希望 SQL 逐条执行，而是采用存储过程整段执行的方式，因此我们就需要临时定义新的 DELIMITER，新的结束符可以用（//）或者（$$）。如果你用的是 MySQL，那么上面这段代码，应该写成下面这样：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">DELIMITER //</span><br><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> <span class="string">`add_num`</span>(<span class="keyword">IN</span> n <span class="built_in">INT</span>)</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">       <span class="keyword">DECLARE</span> i <span class="built_in">INT</span>;</span><br><span class="line">       <span class="keyword">DECLARE</span> <span class="keyword">sum</span> <span class="built_in">INT</span>;</span><br><span class="line">       </span><br><span class="line">       <span class="keyword">SET</span> i = <span class="number">1</span>;</span><br><span class="line">       <span class="keyword">SET</span> <span class="keyword">sum</span> = <span class="number">0</span>;</span><br><span class="line">       WHILE i &lt;= n DO</span><br><span class="line">              <span class="keyword">SET</span> <span class="keyword">sum</span> = <span class="keyword">sum</span> + i;</span><br><span class="line">              <span class="keyword">SET</span> i = i +<span class="number">1</span>;</span><br><span class="line">       <span class="keyword">END</span> <span class="keyword">WHILE</span>;</span><br><span class="line">       <span class="keyword">SELECT</span> <span class="keyword">sum</span>;</span><br><span class="line"><span class="keyword">END</span> //</span><br><span class="line">DELIMITER ;</span><br></pre></td></tr></table></figure><p>首先我们用（//） 作为结束符，又在整个存储过程结束后采用了（//）作为结束符号，告诉SQL可以执行了，然后再将结束符还原成默认的（;）。</p><p>需要注意的是，如果你用的是 Navicat 工具，那么在编写存储过程的时候，Navicat 会自动设置 DELIMITER 为其他符号，我们不需要再进行 DELIMITER 的操作。</p><p>我们再来看下存储过程的 3 种参数类型。在刚才的存储过程中，我们使用了 IN 类型的参数，另外还有 OUT 类型和 INOUT 类型，作用如下：</p><p><img src="https://i.loli.net/2020/12/08/oilwFWaXMNr5Etk.png"></p><p>IN和OUT的结合，即用于存储过程的传入参数，同时又可以把结果放到参数中，调用者可以的得到返回值。</p><p>你能看到，IN参数必须再调用存储过程时指定，而在存储过程中修改该参数的值不能被返回。而OUT参数和INOUT参数可以在存储过程中被改变，并可返回。</p><p>举个例子，这里会用到之前的王者荣耀英雄数据表heros。假设我想创建一个存储类型get_hero_score，用来查询某一类型英雄中的最大的生命值，最小的魔法值，以及平均最大攻击值，那么该怎么写呢？</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">PROCEDURE</span> <span class="string">`get_hero_scores`</span>(</span><br><span class="line">       <span class="keyword">OUT</span> max_max_hp <span class="built_in">FLOAT</span>,</span><br><span class="line">       <span class="keyword">OUT</span> min_max_mp <span class="built_in">FLOAT</span>,</span><br><span class="line">       <span class="keyword">OUT</span> avg_max_attack <span class="built_in">FLOAT</span>,  </span><br><span class="line">       s <span class="built_in">VARCHAR</span>(<span class="number">255</span>)</span><br><span class="line">       )</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line">       <span class="keyword">SELECT</span> <span class="keyword">MAX</span>(hp_max), <span class="keyword">MIN</span>(mp_max), <span class="keyword">AVG</span>(attack_max) <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> role_main = s <span class="keyword">INTO</span> max_max_hp, min_max_mp, avg_max_attack;</span><br><span class="line"><span class="keyword">END</span></span><br></pre></td></tr></table></figure><p>你能看到我定义了 4 个参数类型，其中 3 个为 OUT 类型，分别为 max_max_hp、min_max_mp 和 avg_max_attack，另一个参数 s 为 IN 类型</p><p>这里我们从 heros 数据表中筛选主要英雄定位为 s 的英雄数据，即筛选条件为 role_main=s，提取这些数据中的最大的最大生命值，最小的最大魔法值，以及平均最大攻击值，分别赋值给变量 max_max_hp、min_max_mp 和 avg_max_attack。</p><p>然后我们就可以调用存储过程，使用下面这段代码即可：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CALL</span> get_hero_scores(@max_max_hp, @min_max_mp, @avg_max_attack, <span class="string">&#x27;战士&#x27;</span>);</span><br><span class="line"><span class="keyword">SELECT</span> @max_max_hp, @min_max_mp, @avg_max_attack;</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>运行结果：</p><p><img src="https://i.loli.net/2020/12/08/skvQL2DEUH9NxYo.png"></p><h3 id="流控制语句"><a href="#流控制语句" class="headerlink" title="流控制语句"></a>流控制语句</h3><p>流程控制语句是用来做流程控制的，我刚才讲了两个简单的存储过程的例子，一个是 1+2+n 的结果计算，一个是王者荣耀的数据查询，你能看到这两个例子中，我用到了下面的流控语句：</p><ol><li>BEGIN…END：BEGIN…END中间包含了多个语句，每个语句都以(;)号作为结束符。</li><li>DECLARE：DECLARE用来声明变量，使用的位置在于BEGIN…END语句中间，而且需要在其他语句使用之前进行变量的声明。</li><li>SET：赋值语句，用于对变量进行赋值。</li><li>SELECT…INTO：把从数据表中查询的结果存放到变量中，也就是为变量赋值。</li></ol><p>除了上面这些用到的流控制语句外，还有一些常用的流控制语句：</p><ol><li><p>IF…THEN…ENDIF：条件判断语句，我们还可以在IF…THEN…ENDIF中使用ELSE和 ELSEIF来进行判断。</p></li><li><p>CASE：CASE语句用于多条件的分支判断，使用的语法是下面这样的。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">CASE </span><br><span class="line">WHEN expression1 THEN ...</span><br><span class="line">WHEN expression2 THEN ...</span><br><span class="line">...</span><br><span class="line"><span class="comment">--ELSE语句可以加，也可以不加。加的话代表所有的条件都不满足时采用的方式。</span></span><br></pre></td></tr></table></figure></li><li><p>LOOP、LEAVE和LTERATE : LOPP是循环语句,使用LEAVE跳出循环,是u哦那个ITERATE则可以进入下一次循环。如果你有面向过程编程语言的使用经验,你可以把LEAVE理解为BREAK,把ITERATE理解为CONTINUE.</p></li><li><p>PEPEAT…UNTIL…END REPEAT:这是一个循环语句,首先会执行一次循环,然后在UNTIL中进行表达式的判断,如果满足条件就推出,即END REPEAT;如果条件不满足,则会就绪执行循环,知道满足退出条件为止.</p></li><li><p>WHILE…DO…END WHILE : 这也是循环语句,和REPEAT循环不同的是,这个语句需要先进行条件判断,如果满足条件就进行循环,如果不满足条件就退出循环.</p></li></ol><p>之前说过 SQL 是声明型语言，使用 SQL 就像在使用英语，简单直接。今天讲的存储过程，尤其是在存储过程中使用到的流控制语句，属于过程性语言，类似于 C++ 语言中函数，这些语句可以帮我们解决复杂的业务逻辑。</p><h3 id="关于存储过程使用的争议"><a href="#关于存储过程使用的争议" class="headerlink" title="关于存储过程使用的争议"></a>关于存储过程使用的争议</h3><p>尽管存储过程有诸多优点，但是对于存储过程的使用，一直都存在着很多争议，比如有些公司对于大型项目要求使用存储过程，而有些公司在手册中明确禁止使用存储过程，为什么这些公司对存储过程的使用需求差别这么大呢？</p><p>我们得从存储过程的特点来找答案。</p><p>你能看到存储过程有很多好处。</p><p>首先存储过程可以一次编译多次使用。存储过程只在创造时进行编译，之后的使用都不需要重新编译，这就提升了 SQL 的执行效率。其次它可以减少开发工作量。将代码封装成模块，实际上是编程的核心思想之一，这样可以把复杂的问题拆解成不同的模块，然后模块之间可以重复使用，在减少开发工作量的同时，还能保证代码的结构清晰。还有一点，存储过程的安全性强，我们在设定存储过程的时候可以设置对用户的使用权限，这样就和视图一样具有较强的安全性。最后它可以减少网络传输量，因为代码封装到存储过程中，每次使用只需要调用存储过程即可，这样就减少了网络传输量。同时在进行相对复杂的数据库操作时，原本需要使用一条一条的 SQL 语句，可能要连接多次数据库才能完成的操作，现在变成了一次存储过程，只需要连接一次即可。</p><p>基于上面这些优点，不少大公司都要求大型项目使用存储过程，比如微软、IBM 等公司。但是国内的阿里并不推荐开发人员使用存储过程，这是为什么呢？</p><p>存储过程虽然有诸如上面的好处，但缺点也是很明显的。</p><p>它的可移植性差，存储过程不能跨数据库移植，比如在 MySQL、Oracle 和 SQL Server 里编写的存储过程，在换成其他数据库时都需要重新编写。</p><p>其次调试困难，只有少数 DBMS 支持存储过程的调试。对于复杂的存储过程来说，开发和维护都不容易。</p><p>此外，存储过程的版本管理也很困难，比如数据表索引发生变化了，可能会导致存储过程失效。我们在开发软件的时候往往需要进行版本管理，但是存储过程本身没有版本控制，版本迭代更新的时候很麻烦。</p><p>最后它不适合高并发的场景，高并发的场景需要减少数据库的压力，有时数据库会采用分库分表的方式，而且对可扩展性要求很高，在这种情况下，存储过程会变得难以维护，增加数据库的压力，显然就不适用了。</p><p>了解了存储过程的优缺点之后，我想说的是，存储过程既方便，又有局限性。尽管不同的公司对存储过程的态度不一，但是对于我们开发人员来说，不论怎样，掌握存储过程都是必备的技能之一。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://i.loli.net/2020/12/08/asFiJ2qSevmjukp.png"></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL存储过程 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP可靠传输原理</title>
      <link href="/2020/12/21/TCP%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/"/>
      <url>/2020/12/21/TCP%E5%8F%AF%E9%9D%A0%E4%BC%A0%E8%BE%93%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="如何实现一个靠谱的协议"><a href="#如何实现一个靠谱的协议" class="headerlink" title="如何实现一个靠谱的协议"></a>如何实现一个靠谱的协议</h3><p>TCP协议为了保证顺序性，每个包都有一个ID。在建立连接的时候，会商定其实的ID是什么，然后按照哪个ID一个个发送。为了保证不丢包，对于发送的包都要应答，但是应答也不是一个一个来，而是会答应某个之前的ID，表示都收到了，这种模式称为 <code>累计确认</code> 或者 <code>累计应答</code>。</p><p>为了记录所有发送的包和接收的包，TCP也需要发送端和接收端分别都有缓存来保存这些记录。发送端的缓存里是按照包的ID一个个排列的，根据处理的情况分成四个部分。</p><p>第一部分：发送了并且已经确认的。</p><p>第二部分：发送了并且尚未确认的。</p><p>第三部分：没有发送，但是已经等待发送的。</p><p>第四部分：没有发送，并且暂时还不会发送的。</p><p>在TCP里，接收端会给发送端报一个窗口的大小，叫<code>Advertised window</code>。这个窗口的大小应该等于上面的第二部分加上第三部分，就是已经交代了没做完的加上马上要交代的。超过这个窗口的，接收端做不过来，就不能发送了。</p><p>于是，发送端需要保持下面的数据结构。</p><p><img src="https://i.loli.net/2020/12/03/Ie4byaKHXB6MVAZ.jpg"></p><ul><li>LastByteAcked：第一部分和第二部分的分界线</li><li>LastByteSent：第二部分和第三部分分界线</li><li>LastByteAcked+AdvertisedWindow：第三部分和第四部分的分界线</li></ul><p>对于接收端来讲，它的缓存里记录的内容要简单一些。</p><p>第一部分：接收并且确认过的。</p><p>第二部分：还没接收，但是马上就能接收的</p><p>第三部分：还没接收，也没法接收的</p><p>对应的数据结构就像这样。</p><p><img src="https://i.loli.net/2020/12/03/ufr3mhAajGbQ6Mg.jpg"></p><ul><li>MaxRcvBuffer：最大缓存的量；</li><li>LastByteRead：之后是已经接收了，但是还没被应用层读取的；</li><li>NextByteExpected ：第一部分和第二部分的分界线；</li></ul><p>第二部分的窗口有多大呢？</p><p>NextByteExpected 和 LastByteRead的差其实是还没被应用层读取的部分占用掉的MaxRcvBuffer的量，我们定义为A。</p><p>AdvertisedWindow 其实是MaxRcvBuffer 减去 A。</p><p>也就是：AdvertisedWindow = MaxRcvBuffer - （（NextByteExpected-1）- LastButeRead）。</p><p>那第二部分和第三部分的分界线在哪里呢？NextByteExpected 加 AdvertisedWindow 就是第二部分和第三部分的分界线，其实也就是 LastByteRead 加上 MaxRcvBuffer。</p><p>其中第二部分里面，由于受到的包可能不是顺序的，会出现空挡，只有和第一部分连续的，可以马上进行回复，中间空着的部分需要等待，哪怕后面的已经来了。</p><h3 id="顺序问题与丢包问题"><a href="#顺序问题与丢包问题" class="headerlink" title="顺序问题与丢包问题"></a>顺序问题与丢包问题</h3><p>还是刚才的图，在发送端来看，1、2、3已经发送并确认；4、5、6、7、8、9都是发送了还没确认；10、11、12是还没发出的；13、14、15是接收方没有空间，不准备发的。</p><p>在接收端来看，1、2、3、4、5 是已经完成ACK，但是还没读取的；6、7是等待接收的；8、9是已经接收，但是没有ACK。</p><p>发送端和接收端当前状态如下：</p><ul><li>1、2、3没有问题，双方达成了一致。</li><li>4、5接收方说ACK了，但是发送方还没收到，有可能丢了，有可能在路上。</li><li>6、7、8、9肯定都发了，但是8、9已经到了，但是6、7没到，出现了乱序，缓存着但是没办法ACK。</li></ul><p>根据这个例子，我们可以知道，顺序问题和丢包问题都有可能发生，所以我们先来看<strong>确认与重发机制</strong>。</p><p>假设4的确认到了，不幸的是，5的ACK丢了，6、7的数据包丢了，这该怎么办呢？</p><p>一种方法就是<strong>超时重试</strong>，也即对每一个发送了，但是没有ACK的包，都有设一个定时器，超过一定时间。就重新尝试。但是这个超时的时间如何评估呢？这个时间不宜过短，时间必须大于往返时间RTT，否则会引起不必要的重传。也不宜过长，这样超时时间变长，访问就变慢了。</p><p>估计往返时间，需要TCP通过采样RTT的时间，然后进行加权平均，算出一个值，而且这个还是要不断变化的，因为网络状态不断地变化。除了采样RTT，还要采样RTT的波动范围，计算出一个估计的超时时间。由于重传时间是不断变化的，我们称为<strong>自适应重传算法</strong>。</p><p>如果过一段时间，5、6、7都超时了，就会重新发送。接收方发现5原来接收过，于是丢弃5；6收到了，发送ACK，要求下一个是7，7不幸又丢了。当7再次超时的时候，有需要重传的时候，TCP的策略是<strong>超时间隔加倍。每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。两次超时，就说明网络环境差，不宜频繁反复发送。</strong></p><p>超时出发重传存在的问题是，超时周期可能相对较长。那是不是可以有更快的方式呢？</p><p>有一个可以快速重传的机制，当接收方收到一个序号大于下一个所期望的报文时，就检测到了数据六种的一个间隔，于是发送三个冗余的ACK，客户端收到后，就在定时器过期之前，重传丢失的报文。</p><p>例如，接收方发现6、8、9都已经接受了，就是7没来，那肯定是丢了，于是发送三个6的ACK，要求下一个是。客户端收到3个，就会发现7的确又丢了，不等超时，马上重发。</p><p>还有一种方式称为<strong>Selective Acknowledgment （SACK）</strong>。这种方式需要在TCP头里加上一个SACK的东西，可以将缓存的地图发送给发送方，例如可以发送ACK6，SACK8、SACK9，有了地图，发送方一下子就能看出来是7丢了。</p><h3 id="流量控制问题"><a href="#流量控制问题" class="headerlink" title="流量控制问题"></a>流量控制问题</h3><p>在对于包的确认中，同时会携带一个窗口的大小。</p><p>先假设窗口不变的情况，窗口始终为9。4的确认来的时候，会右移一个，这时候第13个包也可以发送了。</p><p><img src="https://i.loli.net/2020/12/03/dpwZVrAISsHvTb3.jpg"></p><p>这个时候，假设发送端发送过猛，会将第三部分的10、11、12、13全部发送完毕，之后就停止发送了，未发送可发送部分为0。</p><p><img src="https://i.loli.net/2020/12/03/fV2HPwe7L4oJpZS.jpg"></p><p>当对于包5的确认到达的时候，在客户端相当于窗口在滑动了一格，这个时候，才可以有更多的包可以发送了，例如第14个包才可以发送。</p><p>如果发送给方是在处理的太慢，导致缓存中没有空间了，可以通过确认消息修改窗口的大小，甚至可以设置为0，则发送方将暂时停止发送。</p><p>我们假设一个极端情况，接收端的应用一直步读取缓存中的数据，当数据包6确认后，窗口大小就不能在是9了，就要缩小一个变为8。</p><p><img src="https://i.loli.net/2020/12/03/bRHBKELiP1VFrI5.jpg"></p><p>这个新的窗口8通过6的确认消息达到发送时候，你会发现窗口没有平行右移，而是仅仅左面的边右移了，窗口的大小从9改成8。</p><p><img src="https://i.loli.net/2020/12/03/pDGByUbEHfzmgCO.jpg"></p><p>如果接收端还是一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为0。</p><p><img src="https://i.loli.net/2020/12/03/yPa3r8QWAbpxD2h.jpg"></p><p>但这个窗口通过包14的确认到达发送端的时候，发送端的窗口也调整为0，停止发送。</p><p><img src="https://i.loli.net/2020/12/03/yPa3r8QWAbpxD2h.jpg"></p><p>如果这样的话，发送方肯定会定时发送窗口探测数据包，看是否有机会调整窗口大小。当接受方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。</p><p>这就是我们常说的流量控制</p><h3 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h3><p>拥塞控制的问题，也是通过窗口的大小来控制的，前面的滑动窗口rwnd是怕发送方把接收方缓存塞满，而拥塞控制窗口cwnd，是怕把网络塞满。</p><p>这里有一个公式LastByteSent - LastByteAcked &lt;= min{cwnd,rwnd}，是拥塞窗口和滑动窗口共同控制发送的速度。</p><p>那发送方怎么判断网络是不是满呢？着其实是个挺难的事情，因为对于TCP协议来讲，他压根不知道整个网络路径都会经历什么，对他来讲就是一个黑盒。TCP发送包常被比喻为往一个水管里面灌水，而TCP的拥塞控制就是再不堵塞，不丢包的情况下，尽量发挥宽带。</p><p>水管有粗细，网络有带宽，也即每秒钟能够发送多少数据；水管有长度，端到端有延时。在理想状态下，水管里面的水的量 = 水管的粗细 × 水管长度。对于到网络上，通道的容量= 带宽 × 往返延时。</p><p>如果我们设置发送窗口，使得发送但未确认的包为通道的容量，就能够盛满整个管道。</p><p><img src="https://i.loli.net/2020/12/04/I3T2u7j4LdoagtA.jpg"></p><p>如图所示，假设往返时间为8s，去4s，回4s，每秒发送一个包，每个包1024byte。已经过去了8s，则8个包都发出去了，其中4个包已经到达接收端，但是ACK还没有返回，不能算发送成功。5-8后四个包还在路上，还没被接收，整个管道正好撑满，在发送端，已发送未确认的为8个包，正好等于带宽，也即每秒发送1个包，乘以来回时间8s。</p><p>如果我们在这个基础上再调大窗口，使得单位时间内更多的包可以发送，会出现什么现象呢？</p><p>我们来想，原来发送一个包，从一端到达另一端，假设一共经过四个设备，每个设备处理一个包时间耗费1s，所以到达另外一端需要耗费4s，如果发送的更加快速，则单位时间内，会有更多的包到达这写中间设备，这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这时我们不想看到的。</p><p>这个时候，我们可以想其他的办法，例如这个四个设备本来每秒处理一个包，但是我们在这些设备上加上缓存，处理不过来的在队列里面排着，这样包就不会丢失，但是缺点是会增加时延，这个缓存的包，4s肯定达到不了接收端，如果时延达到一定程度，就会超时重传，也是我们不想看到的。</p><p>于是TCP的拥塞控制主要来避免两种现象，<strong>包丢失</strong>和<strong>超时重传</strong>。一旦出现了这些想象就说明，发送的速度太快了，要慢一点。但是一开始我怎么知道速度多块呢，我怎么知道应该把窗口调整到多大呢？</p><p>如果我们通过漏斗往瓶子里灌满水，我们就知道，不能一桶水一下子倒进去，肯定会溅出来，要一开始慢慢倒，然后发现总能够倒进去，就可以越倒越快。这就叫做慢启动。</p><p>一条TCP连接开始，cwnd设置为一个报文段，一次只能发送一个；当收到这一个确认的时候，cwnd加一，于是一次能够发送两个；当这两个的确认到来的时候，每个确认cwnd加一，两个确认cwnd加二，于是一次能够发送四个；当这四个确认到来的时候，每个确认cwnd加一，四个确认cwnd加四，于是一次能够发送八个。可以看出这时<strong>指数性的增长</strong>。</p><p>涨到什么时候是个头呢？有个值为ssthresh为65535个字节，当超过这个值的时候，就要小心一点了，不能倒这么快了，可能快慢了，再慢下来。</p><p>每收到一个确认后，cwnd增加为1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时候，每个确认增加1/8，八个确认一共cwnd增加1，于是一次能够发送九个，变成了线性增长。</p><p>但是线性增长还是增长，还是越来越多，知道有一天，水满则溢，出现了拥塞，这时候一般就会一下子降低倒水的速度，等待溢出的水慢慢渗下去。</p><p>拥塞的一种表现形式是丢包，需要超时重传，这个时候，将sshresh设置为cwnd/2，将cwnd设为1，重新开始慢启动。这真是一旦超时重传，马上回到解放前。但是这种方式太激进了，将一个高速的传输速度一下子停了下来，会造成网络卡顿。</p><p>前面说过<strong>快速重传算法</strong>。当接收端发现丢了一个中间包的时候，发送三次前一个包的ACK，于是发送端就会快速的重传，不必等待超时再重传。TCP认为这种情况不严重，因为大部分没丢，只丢了一小部分，cwnd减半为cwnd/2，然后将sshthresh=cwnd，当前三个包返回的时候，cwnd = sshthresh+3，也就是没有一夜回到解放前，而是还在比较高的值，成线性增长。</p><p><img src="https://i.loli.net/2020/12/08/TiXNPkoaYHlxEGn.jpg"></p><p>就像前面说的一样，正是这种知进退，使得时延很重要的情况下，反而降低了速度。但是如果你仔细想以下，TCP的拥塞控制主要来避免的两个想象都是有问题的。</p><p>第一个问题是丢包并不代表着通道满了，也可能是管本来就漏水。例如公网上的带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。</p><p>第二个问题是TCP的拥塞控制要等到讲中间设备都填满了，才发送丢包，从而降低速度，这时候已经玩了。其实TCP只要填满管道就可以了，不应该接着填，知道连缓存也填满。</p><p>为了优化这两个问题，后来有了T<strong>TCP BBR算法</strong>。它企图找到一个平衡点，就是通过不断地加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的达到高大宽和低延时的平衡。</p><p><img src="https://i.loli.net/2020/12/04/3lkZB5OVzmQXop1.jpg"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TCP协议 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>使用性能分析工具分析SQL</title>
      <link href="/2020/11/28/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E5%AE%9A%E4%BD%8DSQL%E6%89%A7%E8%A1%8C%E6%85%A2%E7%9A%84%E5%8E%9F%E5%9B%A0/"/>
      <url>/2020/11/28/%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E6%80%A7%E8%83%BD%E5%88%86%E6%9E%90%E5%B7%A5%E5%85%B7%E5%AE%9A%E4%BD%8DSQL%E6%89%A7%E8%A1%8C%E6%85%A2%E7%9A%84%E5%8E%9F%E5%9B%A0/</url>
      
        <content type="html"><![CDATA[<h3 id="数据库服务器的优化步骤"><a href="#数据库服务器的优化步骤" class="headerlink" title="数据库服务器的优化步骤"></a>数据库服务器的优化步骤</h3><p>当我们遇到数据库调优问题的时候，该如何思考了？</p><p>整个流程划分成了观察（Show status） 和行动（Action）两个部分。字母S的部分代表观察（会使用相应的分析工具），字母A代表的部分是行动（对应分析可以采取的行动）。</p><p><img src="https://i.loli.net/2020/12/01/rygwsWaK3NJfFCV.png"></p><p>我们可以通过观察了解数据库整体的运行状态，通过性能分析工具可以让我们了解执行慢的SQL都有哪些，查看具体的SQL执行计划，甚至SQL执行中的每一步的成本代价，这样才能定位问题所在，找到了问题，在采取相应的行动。</p><p>首先在S1部分，我们需要观察服务器的状态是否存在周期性的波动。如果存在周期性波动，有可能是周期性节点的原因，比如双十一、促销活动。这样的话，我们可以通过A1这一步骤解决，也就是加缓存，或者更改缓存失效策略。</p><p>如果缓存策略没有解决，或者不是周期性波动的原因，我么就需要进一步分析查询延迟和卡顿的原因。接下来进入S2这一步，我们需要开启慢查询。慢查询可以帮我们定位执行慢的SQL语句。我们可以通过设置long_query_time参数定义 “慢”的阈值，如果SQL执行时间超过了long_query_time，则会认为是慢查询。当收集上来这些慢查询之后，我们就可以通过分析工具对慢查询日志进行分析。</p><p>在S3这一步骤中，我们就知道了执行慢的SQL，这样就可以调优服务器的参数，比如适当增加数据库缓冲池等。如果是SQL执行时间长，就进入A3步骤，这一步中我们需要考虑是索引设计的问题？还是查询关联的数据表过多？还是因为数据表的字段设计问题导致了这一现象。然后在这些维度上进行对应的调整。</p><p>如果A2和A3都不能解决问题，我们需要考虑数据库自身的SQL查询性能是否已经达到了瓶颈，如果确认没有达到性能瓶颈，就需要重新检查，重复以上的步骤。如果已经达到了性能瓶颈，进入A4阶段，需要考虑增加服务器，采用读写分离的架构，或者考虑对数据库进行分库分表，比如垂直分库、垂直分表和水平分表等。</p><p>以上就是数据库调优的流程思路。如果我们发现执行SQL时存在不规则延迟或卡顿的时候，就可以采用分析工具帮我们定位有问题的sQL，这三种分析工具可以理解为时SQL调优的三个步骤：慢查询、EXPLAIN和SHOW PROFILING。</p><h3 id="使用慢查询定位执行慢的SQL"><a href="#使用慢查询定位执行慢的SQL" class="headerlink" title="使用慢查询定位执行慢的SQL"></a>使用慢查询定位执行慢的SQL</h3><p>慢查询可以帮我们找到执行慢的SQL，在使用前，我们需要看下慢查询是否已经开启，使用下面这条命令即可：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql &gt; show variables like &#x27;%slow_query_log&#x27;;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/01/FXN2rZxsyvS63AI.png"></p><p>能看到slow_query_log = OFF，也就是说慢查询日志此时时关上的。我们可以把慢查询日志打开，注意设置变量值的是否需要使用global，否则会报错：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set global slow_query_log=&#x27;ON&#x27;;</span><br></pre></td></tr></table></figure><p>然后我们再来看下慢查询日志是否开启，以及慢查询日志文件的位置：</p><p><img src="https://i.loli.net/2020/12/01/iskGWN8OfvxJqy2.png"></p><p>你能看到这时慢查询分析已经开启，同时文件保存在DESKTOP-4BK02RP-slow文件中。</p><p>接下来我们来看下慢查询的时间阈值设置，使用如下命令：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#x27;%long_query_time%&#x27;;</span><br></pre></td></tr></table></figure><p>如果我们想要把时间缩短，比如设置为3秒，可以怎样设置：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set global long_query_time = 3;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/01/2ZrHaU8SGdLRyzc.png"></p><p>我们可以使用MySQL自带的mysqldumpslow工具统计慢查询日志（这个工具是个perl脚本，你需要先安装好perl）。</p><p>mysqldumpslow命令的具体参数如下：</p><ul><li>-s：采用order排序的方式，排序方式可以有以下几种。分别是c（访问次数）、t（查询时间）、I（锁定时间）、ac（平均查询次数）、al（平均锁定时间）、ar（平均返回记录数）和at（平均查询时间）。其中at为默认排序方式。</li><li>-t：返回当前N条数据。</li><li>-g：后面可以是正则表大师，对大小写不敏感。</li></ul><p>比如我们想要按照查询时间排序，查看前两条SQL语句，这样写成即可：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">perl mysqldumpslow.pl -s t -t 2 &quot;C:\ProgramData\MySQL\MySQL Server 8.0\Data\DESKTOP-4BK02RP-slow.log&quot;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/01/6QuENVeZyk3IDSA.png"></p><p>你能看到开启了慢查询日志，并设置了相应的慢查询时间阈值之后，只要大于这个阈值的SQL语句店铺会保存在慢查询日志中，然后我们就可以通过mysqldumpslow工具提取想要查找的SQL语句了。</p><h3 id="如何使用EXPLAIN查看执行计划"><a href="#如何使用EXPLAIN查看执行计划" class="headerlink" title="如何使用EXPLAIN查看执行计划"></a>如何使用EXPLAIN查看执行计划</h3><p>定位了慢查询的SQL之后，我们就可以使用EXPLAIN工具做针对性的分析，比如我们想要了解product_comment和user表进行联查的时候采用的执行计划，可以使用下面这条语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> comment_id,product_id,comment_text,product_comment.user_id,user_name <span class="keyword">FROM</span> product_comment <span class="keyword">JOIN</span> <span class="keyword">user</span> <span class="keyword">on</span> product_comment.user_id = user.user_id;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/01/oR4MFzehTdLXrJ7.png"></p><p>EXPLAIN 可以帮助我们了解数据表的读取顺序，SELECT字句的类型、数据表的访问类型、可使用的索引、实际使用的索引、使用索引的长度、上一个表的连接匹配条件、被优化器查询的行的数量以及额外的信息（比如是否使用了外部排序，是否使用了临时表）等。</p><p>SQL执行的顺序是根据id从大到小执行的，也就是id越大越先执行，当id相同时，从上到下执行。</p><p>数据表的访问类型所对应的type列是我们比较关注的信息。type可能有以下几种情况：</p><p><img src="https://i.loli.net/2020/12/01/C9PpDqu5H1gflkm.png"></p><p>在这些情况里，all是最坏的情况，因为采用了全表扫描的方式。index和all差不多，只不过index对索引表进行群扫描，这样做的好处是不在需要对数据进行排序，但是开销依然很大。如果我们在extra列中看到Using index，说明采用了索引覆盖，也就是索引可以覆盖所需的SELECT字段，就不要进行非标，这样就减少了数据查询的开销。</p><p>比如我们对product_comment数据表进行查询，设计了联合索引composite_index(user_id,comment_text)，然后对数据表中comment_id、comment_text、user_id这三个字段进行查询，最后用EXOLAIN看下执行计划：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> comment_id, comment_text, user_id <span class="keyword">FROM</span> product_comment </span><br></pre></td></tr></table></figure><p>你能看到这里的访问方式采用了index的方式，key列采用了联合索引，进行扫描。Extral列为Using index，告诉我们索引可以覆盖SELECT之中的字段 ，也不需要回表查询了。</p><p>range表示采用了索引范围扫描，这里不进行举例，从这一级别开始，索引的作用会越来越明显，因此我们需要尽量让SQL查询可以使用到range这一级别以及以上的type访问方式。</p><p>index_merge说明查询使用了两个或两个以上的索引，最后去了交集或者并集。比如想要对comment_id=500000或者user_id=500000的数据进行查询，数据表中comment_id为主键，user_id是普通索引，我们可以查看下执行计划：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> comment_id, product_id, comment_text, user_id <span class="keyword">FROM</span> product_comment <span class="keyword">WHERE</span> comment_id = <span class="number">500000</span> <span class="keyword">OR</span> user_id = <span class="number">500000</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/01/4WmMTFfivdwlVtx.png"></p><p>你能看到这里同时使用到了两个索引，分别是主键和user_id，采用的数据表访问类型是index_merge，通过union的方式对两个索引检索的数据进行合并。</p><p>ref类型表示采用了非唯一索引，或者是唯一索引的非唯一性前缀。比如我们想要对user_id=500000的评论进行查询，使用EXPLAIN查看执行计划：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> comment_id, comment_text, user_id <span class="keyword">FROM</span> product_comment <span class="keyword">WHERE</span> user_id = <span class="number">500000</span> </span><br></pre></td></tr></table></figure><p>这里user_id为普通索引（因为user_id在商品评论表中可能是从重复的），因此采用的访问类型是ref，同时在ref列中显示const，表示连接匹配条件是常量，用于索引列的查找。</p><p>eq_ref类型时使用主键或唯一索引时产生的访问方式，通常使用在多表联查中。假设我们对product_comment和user表进行联查，关联条件时两张表的user_id相等，使用EXPLAIN进行执行计划查看：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> product_comment <span class="keyword">JOIN</span> <span class="keyword">user</span> <span class="keyword">WHERE</span> product_comment.user_id = user.user_id </span><br></pre></td></tr></table></figure><p>const类型表示我们使用了主键或者唯一索引（所有的部分）与常量值进行比较，比如我们想要查看comment_id=500000，查看执行计划：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> comment_id, comment_text, user_id <span class="keyword">FROM</span> product_comment <span class="keyword">WHERE</span> comment_id = <span class="number">500000</span> </span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/01/Zvo61rmUVcyF4zM.png"></p><p>需要说明的是const类型和eq_ref都是使用了主键或唯一索引，不过这两个类型有所区别，const死于常量比较，查询效率更快，而eq_ref通常用于多表联查中。</p><p>system类型一般用于MyISAM或Memory表，属于const类型的特例，当表中只有一方时连接类型为system。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> * <span class="keyword">FROM</span> test_myisam</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/01/qkpjZuaXQl9VTzW.png"></p><p>你能看到除了all类型外，其他类型都可以使用到索引，但不同的连接方式的效率也会有所不同，效率从低到高一次为all&lt;index&lt;range&lt;index_merge&lt;ref&lt;eq_ref&lt;const/system。我们在查看执行计划的时候，通常希望执行计划至少可以使用到range级别以上的连接方式，如果只使用到了all或者index连接方式，我们可以从SQL语句和索引设计的角度上进行改进。</p><h3 id="使用-SHOW-PROFILE-查看SQL的具体执行成本"><a href="#使用-SHOW-PROFILE-查看SQL的具体执行成本" class="headerlink" title="使用 SHOW PROFILE 查看SQL的具体执行成本"></a>使用 SHOW PROFILE 查看SQL的具体执行成本</h3><p>SHOW PROLILE相比EXPLAIN能看到更进一步的执行解析，包括SQL都做了什么、所花费的时间等。默认情况下，profiling是关闭的，我们可以在会话级别开启这个功能。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql &gt; show variables like &#x27;profiling&#x27;;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/01/hDrz2CmyXYbJ5WK.png"></p><p>通过设置profiling=’ON’ 来开启show profile：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql &gt; set profiling = &#x27;ON&#x27;;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/01/rYMAqbPURnjQBwh.png"></p><p>我们可以看下当前会话都有哪些profiles，使用下面这条命令：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show profiles;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/01/MuADymklLUzv1es.png"></p><p>你能看到当前会话一共有两个查询，如果我们想要查看上一个查询的开销，可以使用：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show profile;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/01/QrxzYNSqlO5GJVo.png"></p><p>我们也可以查看指定的QueryID的开销，比如show profile for query 2 查询结果是一样的。在SHOW PROFILE中我们查看不同部分的开销，比如cpu、block.io等：</p><p><img src="https://i.loli.net/2020/12/01/FlIt3bBSj6H9pm7.png"></p><p>通过上面的结果，我们可以弄清楚每一步骤的耗时，以及在不同部分，比如CPU、block.io的执行时间，这样我们就可以判断出来SQL到底慢在哪里。</p><p>不过SHOW PROFILE命令将被弃用，我们可以从information_schema中的profiling数据表进行查看。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://i.loli.net/2020/12/01/lbA42Y9HytSBPfK.png"></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 使用性能分析工具分析SQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQLMVCC</title>
      <link href="/2020/11/26/MySQL%20MVCC/"/>
      <url>/2020/11/26/MySQL%20MVCC/</url>
      
        <content type="html"><![CDATA[<h3 id="MVCC是什么，解决了什么"><a href="#MVCC是什么，解决了什么" class="headerlink" title="MVCC是什么，解决了什么"></a>MVCC是什么，解决了什么</h3><p>MVCC的英文全称是Multiveion Concurrency Contol，中文翻译过来就是多版本并发控制技术。从名字中也能看出来，MVCC是通过数据行的多个版本管理来实现数据库的并发控制，简单来说它的思想就是保存数据的历史版本。这样我们就可以通过比较版本号决定数据是否显示出来，读取数据的时候不需要加锁也可以保证事务的隔离效果。</p><p>通过MVCC可以解决以下几个问题：</p><ol><li>读写之间阻塞的问题，通过MVCC可以让读写互相不阻塞，即读不阻塞写，写不阻塞读，这样就可以提升事务并处理能力。</li><li>降低了死锁的概率。这是因为MVCC采用了乐观锁的方式，读取数据时并不需要加锁，对于写操作，也只锁定必要的行。</li><li>解决一致性读的问题。一致性读也被称为快照读，当我们查询数据库在某个时间点的快照时，只能看到这个时间点之前事务提交更新的结果，而不能看到这个时间点之后事务提交的更新结果。</li></ol><h4 id="什么是快照读，什么是当前读"><a href="#什么是快照读，什么是当前读" class="headerlink" title="什么是快照读，什么是当前读"></a>什么是快照读，什么是当前读</h4><p>快照读读取的是快照数据。不加锁的简单的SELECT都属于快照读，比如这样：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> player <span class="keyword">WHERE</span> ...</span><br></pre></td></tr></table></figure><p>当前读就是读取最新数据，而不是历史版本的数据。加锁的SELECT ，或者对数据进行增删改都会进行当前读比如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> player <span class="keyword">LOCK</span> <span class="keyword">IN</span> <span class="keyword">SHARE</span> <span class="keyword">MODE</span>;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> player <span class="keyword">FOR</span> <span class="keyword">UPDATE</span>;</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> player <span class="keyword">values</span> ...</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> player <span class="keyword">WHERE</span> ...</span><br></pre></td></tr></table></figure><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> player <span class="keyword">SET</span> ...</span><br></pre></td></tr></table></figure><p>这里需要说明是，快照读就是普通的读操作，而当前读包括了加锁的读取和DML操作。</p><p>比如我们有个账户金额表user_balance，包括三个字段，分别是username用户名、balance 余额和bankcared卡号，具体的数据示意如下：</p><p><img src="https://i.loli.net/2020/12/01/fprURuCGc62thJZ.png"></p><p>为了方便，我们假设user_balance表中只有用户A和B只有余额，其他人的而账户余额均为0。下面我们考虑一个使用场景。</p><p>用户A和用户B之间进行转账，此时数据库管理员想要查询user_balance表中的总金额：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">SUM</span>(balance) <span class="keyword">FROM</span> user_balance</span><br></pre></td></tr></table></figure><p>思考下如果数据库不支持MVCC机制，而是采用自身的锁机制来实现的话，可能会出现怎么样的情况呢？</p><p>情况1：因为需要采用行加锁的方式，用户A给B转账时间等待很久，如下图所示。</p><p><img src="https://i.loli.net/2020/12/01/SYkEjV6z4GKnZXs.png"></p><p>你能可当到为了保证数据库的一致性，我们需要给统计到的数据行都加上行锁。这时如果A所在的数据行加上了行锁，就不能给B转账了，只能等到所有操作完成之后，释放行锁在继续进行转账，这样就会造成用户事务处理的等待时间过长。</p><p>情况2：当我们读取的时候用了加行锁，可能会出现死锁的情况，如下图所示。比如我们读到A有1000元的时候，此时B开始执行给A转账：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> user_balance <span class="keyword">SET</span> balance = balance<span class="number">-100</span> <span class="keyword">WHERE</span> username = <span class="string">&#x27;B&#x27;</span></span><br></pre></td></tr></table></figure><p>执行完之后马上执行下一步：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> user_balance <span class="keyword">SET</span> balance=balance+<span class="number">100</span> <span class="keyword">WHERE</span> username =<span class="string">&#x27;A&#x27;</span></span><br></pre></td></tr></table></figure><p>我们会发现此时A被锁住了，而管理员事务还需要对B进行访问，但B被用户事务锁住了，此时就发生了死锁。</p><p><img src="https://i.loli.net/2020/12/01/c1CES4UldjMgF7T.png"></p><p>MVCC可以解决读写互相阻塞的问题，这样提升了效率，同时因为采用了乐观锁的思想，降低了死锁的概率。</p><h4 id="InnoDB中的MVCC是如何实现的？"><a href="#InnoDB中的MVCC是如何实现的？" class="headerlink" title="InnoDB中的MVCC是如何实现的？"></a>InnoDB中的MVCC是如何实现的？</h4><p>在了解InnoDB中MVCC的实现方式之前，我们需要了解InnoDB是如何存储记录的多个版本的。这里的多版本那对应的就是MVCC前两个字母的释义：Multi Version，我们需要了解和他相关的数据都有哪些，存储在哪里。这些数据包括事务版本号、行记录中的隐藏列和 Undo Log。</p><h4 id="事务版本号"><a href="#事务版本号" class="headerlink" title="事务版本号"></a>事务版本号</h4><p>每开启一个事务，我们都会从数据库中获得一个事务ID（也就是事务版本号），这个事务ID是自增长的，通过ID大小，我们就可以判断事务的时间顺序。</p><h4 id="行记录的隐藏列"><a href="#行记录的隐藏列" class="headerlink" title="行记录的隐藏列"></a>行记录的隐藏列</h4><p>InnoDB的叶子段存储了数据页，数据页中保存了行记录，而在行记录中有一些重要的隐藏字段，如下图所示：</p><ol><li>db_row_id：隐藏的行ID，用来生成默认聚集索引。如果我们创建数据表的时候没有指定聚集索引，这时InnoDb就会用这个隐藏ID来创建聚集索引。采用聚集索引的方式可以提升数据的查询效率。</li><li>db_trx_id：操作这个数据的事务ID，也就是最后一个对该数据进行插入或更新的事务ID。</li><li>db_roll_ptr：回滚指针，也就是指向这个记录的Undo Log信息。</li></ol><p><img src="https://i.loli.net/2020/12/01/Q1FsWoHPK9bLuyC.png"></p><h4 id="Undo-Log"><a href="#Undo-Log" class="headerlink" title="Undo Log"></a>Undo Log</h4><p>InnoDB将行记录快照保存在了Undo Log里，我们可以在回滚段中找到它们，如下图所示：</p><p><img src="https://i.loli.net/2020/12/01/WRP8iFmkK4GNsOz.png"></p><p>从图中可以看到回滚指针数据行的所有快照记录都通过链表的结构串联了起来，每个快照的记录都保存了但是的db_trx_id，也就是那个时间点操作这个数据库的事务ID。这样如果我们想要找历史快照，就可以通过遍历回滚指针的方式进行查找。</p><h3 id="Read-View-是如何工作的"><a href="#Read-View-是如何工作的" class="headerlink" title="Read View 是如何工作的"></a>Read View 是如何工作的</h3><p>在MVCC机制中，多个事务对同一行记录进行更新会产生多个历史快照，这些历史快照保存在Undo Log 里。如果一个事务想要查询这个行记录，需要读取那个版本的记录呢？这时就需要到Read View了，它帮我们结局了行的可见性问题。Read View 保存了当前事务开启时所有活跃（还没有提交）的事务列表，换个角度你可以理解为Read View 保存了不应该让这个事务看到的其他的事务ID列表。</p><p>在Read View中有几个重要的属性：</p><ol><li>trx_ids，系统当前正在活跃的事务ID集合。</li><li>low_limit_id，活跃的事务中最大的事务ID。</li><li>up_limit_id，活跃的事务中最小的事务ID。</li><li>creator_trx_id，创建这个Read View的事务ID。</li></ol><p>如图所示，trx_ids为trx2、trx3、trx5 和 trx8 的集合，活跃的最大事务ID（low_limit_id）为trx8，活跃的最小事务ID(up_limit_id)为trx2。</p><p><img src="https://i.loli.net/2020/12/01/qZBTHeSLQfbW1tx.png"></p><p>假设当前有事务create_trx_id想要读取某个行记录，这个行记录的事务ID为trx_id，那么会出现以下几种情况。</p><p>如果trx_id &lt; 活跃的最小事务ID(up_limit_id)，也就是说这个行记录在这些活跃的事务创建之前就已经提交了，那么这个行记录对该事务是可见的。</p><p>如果trx_id &gt; 活跃的最大事务ID（low_limit_id），这说明该行记录在这些活跃的事务创建之后才创建，那么这个行记录对当前事务不可见。</p><p>如果up_limit_id &lt; trx_id &lt; low_limit_id，说明该行记录所在的事务trx_id在目前create_trx_id这个事务创建的时候，可能还处于活跃的状态，因此我们需要在trx_ids集合中进行遍历，如果trx_id存在于trx_ids集合中，证明这个事务trx_id还处于活跃状态，不可见。否则，如果trx_id不存在于trx_ids集合中，证明事务trx_id已经提交了，该行记录可见。</p><p>了解了这些概念之后，我们来看下查询一条记录的时候，系统如何通过多版本并发控制技术找他它：</p><ol><li>首先获取事务自己的版本号，也就是事务ID;</li><li>获取Read View；</li><li>查询得到的数据，然后与Read view 中的事务版本号进行比较；</li><li>如果不符合Read View 规则，就需要从Undo Log中获取历史快照；</li><li>最后返回符合规则的数据。</li></ol><p>你能看到InnoDB中，MVCC是通过Undo Log + Read View进行数据的读取，Undo_log保存了历史快照，而Read View 规则则帮我们判断当前版本的而数据是否可见。</p><p>需要说明的是，在隔离级别为读已提交时，一个事务中每次SELECT 都会获取一次Read View。如表所示：</p><p><img src="https://i.loli.net/2020/12/01/L5IUPDn32hiVW61.png"></p><p>你能看到，在读已提交的隔离级别下，同样的查询语句都会重新获取一次Read View，这时如果Read View不同，就可能会产生不可重复度或者幻读的情况。</p><p>当隔离级别为可重复读的时候，就避免了不可重复读，这是因为一个事务只在第一次SELECT 的时候会获取一次Read View ，而后面所有的SELECT 都会复用这个Read View，如下表所示：</p><p><img src="https://i.loli.net/2020/12/01/3ZY8vhwJrmSEkD2.png"></p><h4 id="InnoDB是如何解决幻读的"><a href="#InnoDB是如何解决幻读的" class="headerlink" title="InnoDB是如何解决幻读的"></a>InnoDB是如何解决幻读的</h4><p>在读已提交的情况下，即使采用了MVCC方式也会出现幻读。如果我们同时开启事务A和事务B，现在事务A中进行某个条件范围的查询，读取的时候采用排它锁，在是事务B中增加一条符合该条件范围的数据，并进行提交，然后我们在事务A总再次查询该条件范围的数据，就会发现结果集中多出以个符合条件的数据，这样就出现了幻读。</p><p><img src="https://i.loli.net/2020/12/01/iLEBYIoTyNjmASH.png"></p><p>出现幻读的原因在于读已提交的情况下，InnoDB只采用记录锁（Record Locking）。这里要介绍下InnoDB三种行锁的方式：</p><ol><li>记录锁：针对单个行记录添加锁</li><li>间隙锁（Gap Locking：可以帮我们锁住一个范围（索引之间的空隙），但不包括记录本身。采用间隙锁的方式可以幻读情况的产生。</li><li>Next-Key锁：帮我们锁住一个范围，同时锁定记录本身，相当于间隙锁+记录锁，可以解决幻读的问题。</li></ol><p>在隔离级别为可重复读时，InnoDB会采用Next-Key锁的机制，帮我们解决幻读问题。</p><p>还是这个例子，我们能看到当我们想要插入球员艾利克斯·伦（身高 2.16 米）的时候，事务 B 会超时，无法插入该数据。这是因为采用了 Next-Key 锁，会将 height&gt;2.08 的范围都进行锁定，就无法插入符合这个范围的数据了。然后事务 A 重新进行条件范围的查询，就不会出现幻读的情况。</p><p><img src="https://i.loli.net/2020/12/01/vltyrxkaFYuPRco.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>我们需要记住，MVCC 的核心就是 Undo Log+ Read View，“MV”就是通过 Undo Log 来保存数据的历史版本，实现多版本的管理，“CC”是通过 Read View 来实现管理，通过 Read View 原则来决定数据是否显示。同时针对不同的隔离级别，Read View 的生成策略不同，也就实现了不同的隔离级别。</p><p>MVCC 是一种机制，MySQL、Oracle、SQL Server 和 PostgreSQL 的实现方式均有不同，我们在学习的时候，更主要的是要理解 MVCC 的设计思想。</p><p><img src="https://i.loli.net/2020/12/01/tNm4gqAoxLMBluj.png"></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQLMVCC </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL基础架构</title>
      <link href="/2020/11/26/MySQL%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/"/>
      <url>/2020/11/26/MySQL%E5%9F%BA%E7%A1%80%E6%9E%B6%E6%9E%84/</url>
      
        <content type="html"><![CDATA[<p><img src="https://i.loli.net/2020/12/02/1RWjkcPSEZCelr2.png" alt="image-20201202191758953"></p><p>大体来说，MySQL可以分为Server层和存储引擎层两部分。</p><p>Server 层包括连接器、查询缓存、分析器、执行器等，涵盖MySQL的大多数核心服务功能，以及所有的内置函数（如日期、时间、数学和加密函数等），所有跨存储引擎的功能都在这一层实现，比如存储过程、触发器、视图等。</p><p>而存储引擎负责数据的存储和提取。其架构模式是插件式的，支持InnoDB、MyISAM、Memory等多个存储引擎。现在最常用的存储引擎是InnoDB，它从MySQL 5.5.5 版本开始成为了默认存储引擎。</p><p>也就是说，你执行create table建表的时候，如果不指定引擎类型，默认使用的就是InnoDB。不过，你也可以通过指定存储引擎的类型来选择别的引擎，比如在create table 语句中使用 engine=memory，来指定使用内存引擎创建表。不同存储引擎的表数据存取方式不同，支持的功能也不同，在后面的文章中，我们会讨论到引擎的选择。</p><p>从图中不难看出，不同的存储引擎共用一个Server层，也就是从连接器到执行器的部分。</p><h3 id="连接器"><a href="#连接器" class="headerlink" title="连接器"></a>连接器</h3><p>第一步，你会先来接到这个数据库上，这时候接待你的就是连接器。连接器负责跟客户端建立连接、获取权限、维持和管理连接。连接命令一般都是这么写的：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql -h$ip -p$port -u$user -p</span><br></pre></td></tr></table></figure><p>输完命令之后，你就需要在交互对话里面输入密码。虽然密码也可以直接跟在-p后面写在命令行中，但这样可能会导致你的密码泄露。如果你连接的是生产服务器，强烈建议你不要这么做。</p><p>连接命令中的mysql是客户端工具，用来跟服务端建立连接。在完成经典的TCP握手后，连接器就要开始认证你的身份，这个时候用的就是你输入的用户名和密码。</p><ul><li>如果用户名或密码不对，你就会收到一个“<code>Access denien for user</code>” 的错误，然后客户端程序结束执行。</li><li>如果用户名密码认证通过，连接器会到权重表里面查出你拥有的权限。之后，这个连接里面的权限判断逻辑，都将依赖于此时得到的权限。</li></ul><p>这就意味着，一个用户成功建立连接后，即使你用的管理员账号对这个用户的权限做了修改，也不会影响已经存在连接的权限。修改完成之后，只有在新建的连接才会使用新的权限设置。</p><p>连接完成之后，如果你没有后续的动作，这个连接就处于空闲状态，你可以在<code>show processlist</code>命令中看到它。文本中这个图是<code>show processlist</code>的结果，其中的Command列显示为“<code>Sleep</code>”的这一行，就表示现在系统里面有一个空闲的连接。</p><p><img src="https://i.loli.net/2020/12/02/lKkm5fZSHdhcjQ9.png" alt="image-20201202193451364"></p><p>客户端如果太长时间没动静，连接器就会自动将他断开。这个时间由参数wait_timeout控制，默认值是8小时。</p><p>如果在连接被断开之后，客户端再次发送请求的话，就会收到一个错误提醒：<code>Lost connection to MySQL server during query</code>。这时如果你要继续，就需要重连。然后再执行请求了。</p><p>数据库里面，长连接是指连接成功后，如果客户端持续有请求，则一致使用同一个连接。短链接则是指每次执行完很少的几次查询就断开连接，下次查询再重新建立一个。</p><p>建立连接的过程通常是比较复杂的，所以我建议你在使用中要尽量减少建立连接的动作，也就是尽量使用长连接。</p><p>但是全部使用长连接后，你可能会发现，有些时候MySQL占用内存涨的特别快，这时因为MySQL在执行过程中临时使用的内存是管理再连接对象里面的。这些资源会在连接断开的时候才释放。所以如果长连接累计下来，可能导致内存占用太大，被系统强行杀掉（OOM），从现象看就是MySQL异常重启了。</p><p>怎么解决这个问题呢？你可以考虑以下两种方案。</p><ol><li>定期断开长连接。使用一段时间，或者程序里面判断执行过一个占用内存的大查询后，断开连接，之后要查询再重连。</li><li>如果你用的是MySQL5.7或更新的版本，可以在每次执行一个比较大的操作后，通过执行mysql_reset_conncetion来重新初始化连接资源。这个过程不需要重连和重新做权限验证，但是会将连接恢复到刚刚创建完时的状态。</li></ol><h3 id="查询缓存"><a href="#查询缓存" class="headerlink" title="查询缓存"></a>查询缓存</h3><p>连接建立完成之后，你就可以执行select语句了。执行逻辑就会来到第二步：查询缓存。</p><p>MySQL拿到一个查询请求后，会先到查询缓存看看，之前是不是执行过这条语句。之前执行过的语句机器结果可能会以key-value对的形式，被直接缓存在内存中。key是查询的语句，value是查询的结果。如果你的查询能够直接在这个缓存中找到key，那么这个value就会被直接返回给客户端。如果语句不在查询缓存中，就会继续执行后面的阶段。执行完成后，执行结果会被存入查询缓存中。你可以看到，如果查询命中缓存，MySQL不需要执行后面的复杂操作，就可以直接返回结果，这个效率会很高。</p><p><strong>但是大多数情况下我会建议你不要使用查询缓存，为什么呢？因为查询缓存往往弊大于利。</strong></p><p>查询缓存的失效非常频繁，只要有对一个表的更新，这个表上所有的查询缓存都会被清空。因此很可能你费劲把结果存起来，还没使用呢，就被一个更新全部清空了。对于更新压力大的数据库来说，查询缓存的命中率非常低。除非你的业务就是一张静态表，很长时间才会更新一次。比如，一个系统配置表，那这张表上的查询才适合使用查询缓存。</p><p>好在MySQL也提供了一种“按需使用”的方式。你可以将参数<code>query_cache_type</code>设置成DEAMND，这样对于默认的SQL语句都不适用查询缓存。而对你确定要使用查询的语句，可以用SQL_CACHE显示指定，像下面这个语句一样：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select SQL_CACHE * from T where ID=10;</span><br></pre></td></tr></table></figure><p>需要注意的是，MySQL8.0版本直接将查询缓存的整块功能删掉了，也就是说8.0开始彻底没有这个功能了。</p><h3 id="分析器"><a href="#分析器" class="headerlink" title="分析器"></a>分析器</h3><p>如果没有命中查询，就要开始真正执行语句了。首先，MySQL需要知道你要做什么，因此需要对SQL语句做解析。</p><p>分析器先会做“词法分析”。你输入的是由多个字符串和空格组成的一条SQL语句，MySQL需要识别出里面的字符串分别是什么，代表什么。</p><p>MySQL从你输入的 “<code>select</code> ” 这个关键字识别出来，这是一个查询语句。他也要把字符串 “T” 识别成“表明T”，把字符串“ID”识别成 “列ID”。</p><p>做完这些识别以后，就要做 “语法分析”。根据词法分析的结果，语法分析器会根据语法规则，判断你输入的这个SQL语句是否满足MySQL语法。</p><p>如果你的语句不对，就会收到 “You have an error in you SQL syntax” 的错误提醒，比如下面这个语句select少打了开头的字母 “s”。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">myqsl&gt; elect * from t where ID=1;</span><br><span class="line"></span><br><span class="line">ERROR 1064 (42000): You have an error in your SQL syntax; <span class="keyword">check</span> the <span class="keyword">manual</span> that corresponds <span class="keyword">to</span> your MySQL <span class="keyword">server</span> <span class="keyword">version</span> <span class="keyword">for</span> the <span class="keyword">right</span> syntax <span class="keyword">to</span> <span class="keyword">use</span> near <span class="string">&#x27;elect * from t where ID=1&#x27;</span> <span class="keyword">at</span> line <span class="number">1</span></span><br></pre></td></tr></table></figure><p>一般语法错误会提示第一个出现错误的位置，所以你要关注的是紧接 “use near”的内容。</p><h3 id="优化器"><a href="#优化器" class="headerlink" title="优化器"></a>优化器</h3><p>经过了分析器，MySQL就知道你要做什么了。在开始执行之前，还要经过优化器的处理。</p><p>优化器是在表里卖弄有多个索引的时候，决定使用哪个索引；或者在一个语句有多个表关联（join）的时候，决定各个表的连接顺序。比如你执行下面这样的语句，这个语句是执行两个表的join：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from t1 join t2 using(ID) where t1.c=10 and t2.d=20;</span><br></pre></td></tr></table></figure><ul><li>即可以先从表t1里面取出记录的ID值，再根据ID值关联到表t2，在判断t2里面的值是否等于20.</li><li>也可以先从t2里面取出d=20的记录的ID值，再根据ID值关联到t1，在判断t1里里面c的值是否等于10.</li></ul><p>这两中执行方法的逻辑结果是一样的，但是执行的效率会有不同，而优化器的作用就是决定选择使用哪一个方案。</p><p>优化器阶段完成后，这个语句的执行方案就确定小来了，然后进入执行阶段。如果你还有一些疑问，比如优化器这是怎么选择索引的，有没有可能选择错等等，没关系，我会在后面的文章后单独展开说明优化器的内容。</p><h3 id="执行器"><a href="#执行器" class="headerlink" title="执行器"></a>执行器</h3><p>MySQL通过分析器知道了你要做什么，通过优化器知道了该怎么做，于是就进入了执行器阶段，开始执行语句。</p><p>开始执行的时候，要先判断以下你对这个表T有没有执行查询的权限，如果没有，就会返回没有权限的错误，如下所示。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; select * from T where ID=10;</span><br><span class="line"></span><br><span class="line">ERROR 1142 (42000): <span class="keyword">SELECT</span> command denied <span class="keyword">to</span> <span class="keyword">user</span> <span class="string">&#x27;b&#x27;</span>@<span class="string">&#x27;localhost&#x27;</span> <span class="keyword">for</span> <span class="keyword">table</span> <span class="string">&#x27;T&#x27;</span></span><br></pre></td></tr></table></figure><p>如果有权限，就打开表继续执行。打开表的时候，执行器就会根据引擎定义，去使用这个引擎提供的接口。</p><p>比如我们这个例子中表T中，ID字段没有索引，那么执行器的执行流程是这样的：</p><ol><li>调用InnoDB引擎接口取这个表的第一行，判断ID值是不是10，如果不是则跳过，如果是则将这行存在结果集中；</li><li>调用引擎接口取“下一行”，重复相同的判断逻辑，直到取到这个表的最后一行。</li><li>执行器将上述遍历过程中所有满足条件的行组成的记录集作为结果集返回给客户端</li></ol><p>至此，这个语句就执行完成了。</p><p>对于有索引的表，执行的逻辑也差不多。第一次调用的是“取满足条件的第一行”这个接口，之后循环取“满足条件的下一行”这个接口，这些接口都是引擎中已经定义好的。</p><p>你会在数据库的慢查询日志中看到一个rows_examined的字段，表示这个语句执行过程中扫描了多少行。这个值就是在执行器每次调用引擎获取数据行的时候累加的。</p><p>在有些场景下，执行器调用一次，在引擎内部则扫描了多行，因此引擎扫描行数跟rows_examined并不是完全相同的。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL基础架构 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL锁</title>
      <link href="/2020/11/26/MySQL%E9%94%81/"/>
      <url>/2020/11/26/MySQL%E9%94%81/</url>
      
        <content type="html"><![CDATA[<blockquote><p>索引和锁是数据库中的两个核心知识点，不论在工作中，还是在面试中，我们都经常会跟它们打交道。之前已经从不同维度对索引进行了了解，比如B+树，Hash索引、页结构、缓冲池和索引原则等，了解它们的工作原理可以加深对索引的了解。事务的隔离级别的实现都是通过锁来完成的，思考以下为什么我们需要给数据加锁呢？</p></blockquote><p>实际上加锁是为了保证数据的一致性，这个思想在程序开发领域中同样很重要。在程序开发中也会存在多线程同步的问题。当多个线程并发访问某个数据的时候，尤其是针对一些敏感的数据（比如订单、金额等），我们就需要 保证这个数据在任何时候最多只有一个线程在进行访问，保证数据的完整性和一致性。</p><h3 id="按照锁的粒度进行划分"><a href="#按照锁的粒度进行划分" class="headerlink" title="按照锁的粒度进行划分"></a>按照锁的粒度进行划分</h3><p>锁用来对数据进行锁定，我们可以从锁定对象的力度大小来对锁进行划分，分别为<code>行锁</code>、<code>页锁</code> 和<code>表锁</code>。</p><p>顾名思义，行锁就是按照行的力度对数据进行锁定。锁定力度小，发生冲突概率低，可以实现的并发度高，但是对于锁的开销比较大，加锁会比较慢，容易出现死锁情况。</p><p>页锁就是在页的力度上进行锁定，锁定的数据资源比行要多，因为一个页中可以有多个行记录。当我们使用页锁的时候，会出现数据浪费的想象，但这样的浪费最多也就是一个页上的数据行。页锁的开销介于表锁和行锁之间，会出现死锁。锁定力度介于表锁和行锁之间，并发力度一般。</p><p>表锁就是对数据表进行锁定，锁定力度很大，同时发生锁冲突的概率也会较高，数据访问的并发度低。不过好处在于对锁的使用开销小，加锁会很快。</p><p>行锁、页锁和表锁是相对常见的三种锁，除此之外我们还可以在区和数据库的粒度上锁定数据，对应区锁和数据库锁。不同的数据库和存储引擎支持的锁粒度不同，InnoDB 和 Oracle支持行锁和表锁。而MyISAM只支持表锁，MySQL中的BDB存储引擎支持页锁和表锁。SQL Server 可以同时支持行锁、页锁和表锁，如下图所示：</p><p><img src="https://i.loli.net/2020/11/30/JXBUgqY3H8rAtwk.png"></p><p>这里需要说名一下，每个层级的锁数量是有限制，因为锁会占用内存空间，锁空间的大小是有限的。当某个层级的锁数量超过了这个层级的阈值时，就会进行锁升级。锁升级就是用更大力度的锁代替多个更小力度的锁，比如InnoDB中行锁升级为表锁，这样做的好处是占用的锁空间降低了，但同时数据的并发度也下降了。</p><h3 id="从和数据库管理的角度对锁进行划分"><a href="#从和数据库管理的角度对锁进行划分" class="headerlink" title="从和数据库管理的角度对锁进行划分"></a>从和数据库管理的角度对锁进行划分</h3><p>除了按照锁力度的大小对锁进行划分外，我们还可以从数据库管理的角度对锁进行划分。共享锁和排它锁，是我们经常接触到的两把锁。</p><p>共享锁也叫读锁或S锁，共享锁锁定的资源可以被其他用户读取，但不能修改。在进行SELECT 的时候，会将对象进行共享锁锁定，当数据读取完毕后，就会释放共享锁，这样就可以保证数据在读取时不被修改。</p><p>比如我们想给 product_comment 在表上加共享锁，可以使用下面这行命令：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">LOCK</span> <span class="keyword">TABLE</span> product_comment <span class="keyword">READ</span>;</span><br></pre></td></tr></table></figure><p>当数据表加上共享锁的时候，该数据表就变变成了只读模式，此时我们想要更新product_comment表中的数据，比如这样：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> product_comment <span class="keyword">SET</span> product_id = <span class="number">10002</span> <span class="keyword">WHERE</span> user_id = <span class="number">912178</span>;</span><br></pre></td></tr></table></figure><p>系统会做出如下提示：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">ERROR 1099 (HY000): Table &#x27;product_comment&#x27; was locked <span class="keyword">with</span> a <span class="keyword">READ</span> <span class="keyword">lock</span> <span class="keyword">and</span> can<span class="string">&#x27;t be updated </span></span><br></pre></td></tr></table></figure><p>也就是但共享锁没有释放时，不能对锁住的数据进行修改。</p><p>如果我们想要对表上的共享锁进行解锁，可以使用下面的命令：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UNLOCK</span> <span class="keyword">TABLE</span>;</span><br></pre></td></tr></table></figure><p>如果想要给某一行加上共享锁呢，比如想对user_id = 912178的数据行加上共享锁，可以像下面这样：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> comment_id,product_id,comment_text,user_id <span class="keyword">FROM</span> product_comment <span class="keyword">WHERE</span> user_id = <span class="number">912178</span> <span class="keyword">LOCK</span> <span class="keyword">IN</span> <span class="keyword">SHARE</span> <span class="keyword">MODE</span>;</span><br></pre></td></tr></table></figure><p>排它锁也叫独占锁、写锁或X锁。排它锁锁定的数据只允许进行锁定操作的事务使用，其他的事务无法对数据进行查询或修改。</p><p>如果我们想给product_comment数据表添加排它锁，可以使用下面这行命令：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">LOCK</span> <span class="keyword">TABLE</span> product_comment WRITE;</span><br></pre></td></tr></table></figure><p>这时我们释放掉排它锁，使用这个命令即可。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UNLOCK</span> <span class="keyword">TABLE</span>;</span><br></pre></td></tr></table></figure><p>同样的，如果我们想要在某个数据行上添加排它锁，比如针对user_id = 912178的数据行，则写成如下这样：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> comment_id,product_id,comment_text,user_id <span class="keyword">FROM</span> product_comment <span class="keyword">WHERE</span> user_id = <span class="number">912178</span> <span class="keyword">FOR</span> <span class="keyword">UPDATE</span>;</span><br></pre></td></tr></table></figure><p>另外当我们对数据进行更新的时候，也就是INSERT、DELETE 或者 UPDATE的时候，数据库也会自动使用排他锁，防止其他事务对该数据进行操作。</p><p>当我们想要获取某个数据表的排它锁的时候，需要看下这张数据表有没有上了排它锁。如果这个数据表中的某个数据行被上了行锁，我们就无法获取排它锁。这时需要对数据表中的行逐一排查，检查是否有行锁，如果没有，才可以获取这张数据表的排它锁。这个过程是不是有些麻烦？这里就需要用到意向锁。</p><p>意向锁（Intent Lock ），简单来说就是给更大一级别的空间示意里面是否已经上过锁。举个例子，你可以给整个房子设置一个标识。告诉它里面有人，即使你这时获取了房子中的某一个房间的锁。这样其他人如果想要获取这个房子的控制权，只需要看看这个房子的标识即可，不需要在对每个房间进行查找。这样是不是很方便？</p><p>返回数据表的场景，如果我们给某一行的数据加上了排他锁，数据库就会自动给更大一级别的空间，比如数据页或数据表上加意向锁，告诉其他人这个数据页或者数据表已经获取了这个数据表的意向排他锁即可。</p><p>如果事务想要获得数据表中某些记录的共享锁，就需要在数据表上添加意向共享锁。同理，事务想要获得数据表中某些记录的排他锁，就需要在数据表上添加意向排他锁。这时，意向锁会告诉其他事务已经有人锁定了表中的某些记录，不能对整个表进行全表扫描。</p><h3 id="为什么共享锁会发生死锁的情况？"><a href="#为什么共享锁会发生死锁的情况？" class="headerlink" title="为什么共享锁会发生死锁的情况？"></a>为什么共享锁会发生死锁的情况？</h3><p>当我们是用共享锁的时候就会出现死锁的风险，下面我们用两个MySQL客户端来模拟一下事务查询。</p><p>首先客户端1开启事务，然后采用读锁的方式对user_id = 912178的数据行进行查询，这时事务没有提交的时候，这两个数据行上了读锁。</p><p><img src="https://i.loli.net/2020/11/30/xaQtydlnTBDOk9g.png"></p><p>然后我们用客户端2开启事务，同样对user_id = 912178获取读锁，理论上获取读锁后还可以对数据进行修改，比如执行下面这两条语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> product_comment <span class="keyword">SET</span> product_i = <span class="number">10002</span> <span class="keyword">WHERE</span> user_id = <span class="number">912178</span>;</span><br></pre></td></tr></table></figure><p>当我们执行的时候客户端2会一直等待，因为客户端1也获取了该数据的读锁，不需要客户端2对该数据进行修改。这时客户端2会提示等待超时，重新执行事务。</p><p><img src="https://i.loli.net/2020/11/30/XJbGjq6EM4muB7i.png"></p><p>你能看到当有多个事务对同一数据获得读锁的时候，可能会出现死锁的情况。</p><h3 id="从程序员的角度对锁进行划分"><a href="#从程序员的角度对锁进行划分" class="headerlink" title="从程序员的角度对锁进行划分"></a>从程序员的角度对锁进行划分</h3><p>如果从程序员的视角来看锁的话，可以将锁分成乐观锁和悲观锁，从名字也可以看出这两种锁看待数据并发的思维方式。</p><p>乐观锁（Optimistic Locking） 认为对同一数据的并发操作不会总发生，属于小概率事件，不用每次都对数据上锁，也就是不采用数据库自身的锁机制，而是通过程序来实现。在程序上，我们可以采用版本号机制或者时间戳机制实现。</p><h4 id="乐观锁的版本号机制"><a href="#乐观锁的版本号机制" class="headerlink" title="乐观锁的版本号机制"></a>乐观锁的版本号机制</h4><p>在表中设计一个版本字段version，第一次读的时候，会获取version字段的取值。然后对数据进行更新或者删除操作时，会执行UPDATE … SET version = version+1 WHERE version = version。此时如果已经有事务对这条数据进行了修改，修改就不成功。</p><p>这种方式类似我们熟悉的 SVN、CVS 版本管理系统，当我们修改了代码进行提交时，首先会检查当前版本号与服务器上的版本号是否一致，如果一致就可以直接提交，如果不一致就需要更新服务器上的最新代码，然后再进行提交。</p><h4 id="乐观锁的时间戳机制"><a href="#乐观锁的时间戳机制" class="headerlink" title="乐观锁的时间戳机制"></a>乐观锁的时间戳机制</h4><p>时间戳和版本号机制一样，也是在更新提交的时候，将当前数据的时间戳和更新之前取得的时间戳进行比较，如果两者一致则更新成功，否则就是版本冲突。</p><p>你能看到乐观锁就是程序员自己控制数据并发操作的权限，基本是用过给数据行增加一个戳（版本号或者时间戳），从而证明自己拿到的数据是最新的。</p><p>悲观锁（Pessimistic Locking）也是一种思想，对数据被其他是事务的修改持保守态度，会通过数据库自身的锁机制来实现，从而保证操作的排他性。</p><p><img src="https://i.loli.net/2020/11/30/v23sWGLfmqTD7BV.png"></p><p>从这两种锁的设计思想中，能看出乐观锁适合读操作多的场景：</p><ol><li>乐观锁适合读操作多的场景，相对来说写的操作比较少。它的优点在于程序实现，不存在死锁问题，不过使用场景也会相对乐观，因为它阻止不了除了程序以外的数据库操作。</li><li>悲观锁适合写操作多的场景，因为写的操作具有排他性。采用悲观锁的方式，可以在数据库层面阻止了其他事务对该数据的操作权限，防止读-写和 写-写的冲突。</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://i.loli.net/2020/11/30/IdWVxn1ho37wL9r.png"></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL锁 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL视图</title>
      <link href="/2020/11/25/MySQL%E8%A7%86%E5%9B%BE/"/>
      <url>/2020/11/25/MySQL%E8%A7%86%E5%9B%BE/</url>
      
        <content type="html"><![CDATA[<blockquote><p>视图，也就是虚拟表，本身是不具有数据的，它是SQL中的一个重要概念。从下面这张图，能看到，虚拟表的创建连接了一个或多个数据表，不同的查询应用都可以建立在虚拟表之上。</p></blockquote><p><img src="https://i.loli.net/2020/11/30/Tyt2MpAIKUbYvme.jpg"></p><p>视图一方面可以帮我们使用表的一部分而不是所有的表，另一方面也可以针对不同的用户制定不同的查询试图。比如，针对一个公司的销售人员，我们只想给他看部分数据，而某些特殊的数据，比如采购的价格，则不会提供给他。</p><p>刚才讲的只是视图的一个使用场景，实际上视图还有很多作用。</p><h3 id="如何创建，更新和删除视图"><a href="#如何创建，更新和删除视图" class="headerlink" title="如何创建，更新和删除视图"></a>如何创建，更新和删除视图</h3><p>视图作为一张虚拟表，帮我们封装了底层与数据表的接口。它相当于是一张表或多张表的数据结果集。视图的这一特点，可以帮我们简化复杂的SQL查询，比如在编写视图后，我们就可以直接重用它，而不需要考虑视图中包含的基础查询的细节。同样，我们也可以根据需要更改数据格式，返回于底层数据表格式不同的数据。</p><p>通常情况下，小型项目的数据库可以不使用视图，但是在大型项目中，以及数据表比较 复杂的情况下，视图的价值就凸显出来了，它可以帮助我们把经常查询的结果集放到虚拟表中，提升使用效率。理解和使用起来就都非常方便了。</p><h3 id="创建视图：CREATE-VIEW"><a href="#创建视图：CREATE-VIEW" class="headerlink" title="创建视图：CREATE VIEW"></a>创建视图：CREATE VIEW</h3><p>创建视图的语法是：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> view_name <span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> column1,colum2</span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">table</span></span><br><span class="line"><span class="keyword">WHERE</span> codition</span><br></pre></td></tr></table></figure><p>实际上就是我们在SQL查询语句的基础上封装了视图VIEW，这样就会基于SQL语句的结果集形成一张虚拟表。其中view_name为视图名称，column1、column2代表列名，condition代表查询过滤条件。</p><p>我们想要查询比NBA球员平均身高高的球员都有哪些，显示他们的球员ID和身高。假设我们给这个视图起个名字player_above_avg_height，那么创建视图可以写成：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> player_above_avg_height <span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> player_id,height <span class="keyword">FROM</span> player</span><br><span class="line"><span class="keyword">WHERE</span>  height &gt; (<span class="keyword">SELECT</span> <span class="keyword">AVG</span>(height) <span class="keyword">FROM</span> player)</span><br></pre></td></tr></table></figure><p>视图查询结果（18条记录）：</p><p><img src="https://i.loli.net/2020/11/30/iM5pZcDyE4P3Xhq.png"></p><p>当视图创建后，他就相当于一个虚拟表，可以直接使用：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> player_above_avg_height</span><br></pre></td></tr></table></figure><p>运行结果和上面一样</p><h3 id="嵌套视图"><a href="#嵌套视图" class="headerlink" title="嵌套视图"></a>嵌套视图</h3><p>当我们创建好了一张视图之后，还可以在它的基础上继续创建视图，比如我们现在虚拟表 <code>player_above_avg_height</code> 的基础上，找到比这个表中的球员的平均身高高的球员，作为新的视图 <code> player_above_above_avg_height</code>，那么可以写成：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> player_above_above_avg_height <span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> player_id, height</span><br><span class="line"><span class="keyword">FROM</span> player</span><br><span class="line"><span class="keyword">WHERE</span> height &gt; (<span class="keyword">SELECT</span> <span class="keyword">AVG</span>(height) <span class="keyword">from</span> player_above_avg_height)</span><br></pre></td></tr></table></figure><p>视图查询结果（11条记录）：</p><p><img src="https://i.loli.net/2020/11/30/vmAaZV5XOh7TQIG.png"></p><p>你能看到这个视图的数据记录数为 11 个，比之前的记录少了 7 个。</p><h3 id="修改视图：ALTER-VIEW"><a href="#修改视图：ALTER-VIEW" class="headerlink" title="修改视图：ALTER VIEW"></a>修改视图：ALTER VIEW</h3><p>修改视图的语法是：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">ALTER</span> <span class="keyword">VIEW</span> view_name <span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> column1,column2</span><br><span class="line"><span class="keyword">FROM</span> <span class="keyword">table</span></span><br><span class="line"><span class="keyword">WHERE</span> codition</span><br></pre></td></tr></table></figure><p>你能看出来它的语法和创建视图一样，只是对原有视图的更新。比如我们想要更新视图player_above_avg_height，增加一个player_name字段，可以写成：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> player_above_avg_height <span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> player_id,height <span class="keyword">FROM</span> player</span><br><span class="line"><span class="keyword">WHERE</span>  height &gt; (<span class="keyword">SELECT</span> <span class="keyword">AVG</span>(height) <span class="keyword">FROM</span> player)</span><br></pre></td></tr></table></figure><p>这样的话，下次在对视图进行查询的时候，视图结果就进行了更新。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> player_above_avg_height</span><br></pre></td></tr></table></figure><p>运行结果（18条记录）：</p><p><img src="https://i.loli.net/2020/11/30/sAhdGQy6gqNc7nl.png"></p><h3 id="删除视图：DROP-VIEW"><a href="#删除视图：DROP-VIEW" class="headerlink" title="删除视图：DROP VIEW"></a>删除视图：DROP VIEW</h3><p>删除视图的语法是：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">VIEW</span> view_name</span><br></pre></td></tr></table></figure><p>比如我们想把刚才创建的视图删除，可以使用：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DROP</span> <span class="keyword">VIEW</span> player_above_avg_height</span><br></pre></td></tr></table></figure><p>需要说明的是，SQLit不支持修改视图，仅支持只读视图，也就是你只能使用CREATE VIEW 和 DROP VIEW，如果想要修改视图，就需要先DROP 然后 CREATE。</p><h3 id="如何使用视图简化SQL操作"><a href="#如何使用视图简化SQL操作" class="headerlink" title="如何使用视图简化SQL操作"></a>如何使用视图简化SQL操作</h3><p>从上面这个例子中，你能看出视图就是对SELECT语句进行了封装，方便我们重用它们。下面我们再来看几个视图使用的例子。</p><h3 id="利用视图完成复杂的连接"><a href="#利用视图完成复杂的连接" class="headerlink" title="利用视图完成复杂的连接"></a>利用视图完成复杂的连接</h3><p>再说SQL99标准连接操作的时候，举了一个NBA球员和身高等级连接的例子，有两张表，分别为player 和 height_grades。其中height_grades记录了不同身高对应的身高等级。我们这里可以通过创建视图，来完成球员以及对应身高等级的查询。</p><p>首先我们对player表和height_grades 表进行连接，关联条件是球员的身高height(在身高等级表规定的最低身高和最高身高)，这样就可以得到这个球员对应的身高等级，对应的字段为height_lever。然后我们通过SELECT 得到我们想要查询的字段，分别为球员姓名player_name、球员身高height，还有对应的身高等级height_lever。然后把取得的拆查询结果集放到视图player_height_grades中，即：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> player_height_grades <span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> player_name,height,height_level </span><br><span class="line"><span class="keyword">FROM</span> player p <span class="keyword">JOIN</span> height_grades h</span><br><span class="line"><span class="keyword">ON</span> height <span class="keyword">BETWEEN</span> h.height_lowest <span class="keyword">AND</span> h.height_highest</span><br></pre></td></tr></table></figure><p>运行结果（37条记录）：</p><p><img src="https://i.loli.net/2020/11/30/iIOS5lP1u26Z7eB.png"></p><p>以后我们进行查询的时候，可以直接通过视图查询，比如我们想要身高介于1.90m和2.08m之间的球员及它们对应的身高：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> player_grades <span class="keyword">WHERE</span> height &gt;= <span class="number">1.90</span> <span class="keyword">AND</span> height &lt;= <span class="number">2.08</span></span><br></pre></td></tr></table></figure><p>运行结果（26条记录）：</p><p><img src="https://i.loli.net/2020/11/30/WCZTYgEBnK34luD.png"></p><p>这样就把一个相对复杂的连接查询转化成了视图查询。</p><h3 id="利用视图对数据进行格式化"><a href="#利用视图对数据进行格式化" class="headerlink" title="利用视图对数据进行格式化"></a>利用视图对数据进行格式化</h3><p>我们经常需要输出某个格式的内容，比如我们想输出球员姓名和对应的球队，对应格式为player_name （team_name），就可以使用视图来完成数据格式化的操作：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> player_team <span class="keyword">AS</span> </span><br><span class="line"><span class="keyword">SELECT</span> <span class="keyword">CONCAT</span>(player_name, <span class="string">&#x27;(&#x27;</span> , team.team_name , <span class="string">&#x27;)&#x27;</span>) <span class="keyword">AS</span> player_team <span class="keyword">FROM</span> player <span class="keyword">JOIN</span> team <span class="keyword">WHERE</span> player.team_id = team.team_id</span><br></pre></td></tr></table></figure><p>首先我们将 player 表和 team 表进行连接，关联条件是相同的 team_id。我们想要的格式是<code>player_name(team_name)</code>，因此我们使用 CONCAT 函数，即<code>CONCAT(player_name, &#39;(&#39; , team.team_name , &#39;)&#39;)</code>，将 player_name 字段和 team_name 字段进行拼接，得到了拼接值被命名为 player_team 的字段名，将它放到视图 player_team 中。</p><p>这样的话，我们直接查询视图，就可以得到格式化后的结果：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SElECT</span> * <span class="keyword">FROM</span> player_team</span><br></pre></td></tr></table></figure><p>运行结果（37条记录）：</p><p><img src="https://i.loli.net/2020/11/30/r7FUyDIYVh1JOxC.png"></p><h4 id="使用视图与计算字段"><a href="#使用视图与计算字段" class="headerlink" title="使用视图与计算字段"></a>使用视图与计算字段</h4><p>我们在数据查询中，有很多统计的需求可以通过视图来完成。正确地使用视图可以帮我们简化复杂地数据处理。</p><p>player_score 表。这张表中一共有 19 个字段，它们代表的含义如下：</p><p><img src="https://i.loli.net/2020/11/30/tP7bi4cdVyoCxW1.png"></p><p>如果我想要统计每位球员在每场比赛中二分球、三分球和罚球的得分，可以通过创建试图完成：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">VIEW</span> game_player_score <span class="keyword">AS</span></span><br><span class="line"><span class="keyword">SELECT</span> game_id, player_id, (shoot_hits-shoot_3_hits)*<span class="number">2</span> <span class="keyword">AS</span> shoot_2_points, shoot_3_hits*<span class="number">3</span> <span class="keyword">AS</span> shoot_3_points, shoot_p_hits <span class="keyword">AS</span> shoot_p_points, score  <span class="keyword">FROM</span> player_score</span><br></pre></td></tr></table></figure><p>运行结果（19条记录）：</p><p><img src="https://i.loli.net/2020/11/30/dMAatCmze9YcfRJ.png"></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>使用视图有很多好处，比如安全、简单清晰。</p><ol><li>安全性：虚拟表是基于底层数据表的，我们在使用视图时，一般不会轻易通过视图对底层数据进行修改，即使是使用单表的视图，也会受到限制，比如计算字段，类型转换等是无法通过视图来对底层数据进行修改的，这也在一定程度上保证了数据表的数据安全性。同时，我们还可以针对不同用户开放不同的数据查询权限，比如人员薪酬是个敏感的字段，那么只给某个级别以上的人员开放，其他人的查询视图中则不提供这个字段。</li><li>简单清晰：视图是对 SQL 查询的封装，它可以将原本复杂的 SQL 查询简化，在编写好查询之后，我们就可以直接重用它而不必要知道基本的查询细节。同时我们还可以在视图之上再嵌套视图。这样就好比我们在进行模块化编程一样，不仅结构清晰，还提升了代码的复用率。</li></ol><p>另外，我们也需要了解到视图是虚拟表，本身不存储数据，如果想要通过视图对底层数据表的数据进行修改也会受到很多限制，通常我们是把视图用于查询，也就是对 SQL 查询的一种封装。那么它和临时表又有什么区别呢？在实际工作中，我们可能会见到各种临时数据。比如你可能会问，如果我在做一个电商的系统，中间会有个购物车的功能，需要临时统计购物车中的商品和金额，那该怎么办呢？这里就需要用到临时表了，临时表是真实存在的数据表，不过它不用于长期存放数据，只为当前连接存在，关闭连接后，临时表就会自动释放。</p><p><img src="https://i.loli.net/2020/11/30/7diaB56n4oNwFVx.png"></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL视图 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL事务隔离级别</title>
      <link href="/2020/11/25/MySQL%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/"/>
      <url>/2020/11/25/MySQL%E4%BA%8B%E5%8A%A1%E9%9A%94%E7%A6%BB%E7%BA%A7%E5%88%AB/</url>
      
        <content type="html"><![CDATA[<h3 id="事务并发处理可能存在的异常都有哪些？"><a href="#事务并发处理可能存在的异常都有哪些？" class="headerlink" title="事务并发处理可能存在的异常都有哪些？"></a>事务并发处理可能存在的异常都有哪些？</h3><p>在了解数据库隔离级别之前，需要了解设定事务的隔离级别都要解决哪些可能存在的问题，也就是事务并发处理时会存在哪些异常情况。实际上，SQL-92标准中已经对3种异常情况进行了定义，这些异常情况级别分别为<code>脏读（Dirty Read）</code>、<code>不可重复度（Nnrepeatable）</code>和 <code>幻读（Phantom Read）</code>。</p><p>脏读、不可重复读和幻读都代表了什么，比如有个英雄表heros_temp，如下所示：</p><p><img src="https://i.loli.net/2020/12/08/UeVPuWt1dwArmbN.png"></p><p>这张英雄表，我们会记录很多英雄的姓名，假设我们不对事务进行隔离操作，那么数据库在进行事务的并发处理时会出现怎样的情况？</p><p>第一天，小张访问数据库，正在进行事务操作，往里面写入一个新的英雄 “吕布”：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; BEGIN</span><br><span class="line">SQL&gt; INSERT INTO heros_temp values(4,&#x27;吕布&#x27;)</span><br></pre></td></tr></table></figure><p>当小张还有提交该事务的时候，小李又对数据表进行了访问，他想看下这张英雄表里都有哪些英雄：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; SELECT * FROM heros_temp;</span><br></pre></td></tr></table></figure><p>这时，小李看到的结果如下：</p><p><img src="https://i.loli.net/2020/12/08/z4bRUPTgqXyOrpV.png"></p><p>你有没有发现什么异常？这个时候小张还没有提交事务，但是小李却读到了小张还没有提交的数据，这种想象我们称之为 “<code>脏读</code>”。</p><p>那么什么时不可重复读呢？</p><p>第二天，小张想查看id =1 的英雄是谁，于是他进行了SQL查询：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; SELECT name FROM heros_temp WHERE id = 1;</span><br></pre></td></tr></table></figure><p>运行结果：</p><p><img src="https://i.loli.net/2020/12/08/9P5UxWzNpTrAt3o.png"></p><p>然而此时，小李开始了一个事务操作，他对id=1的英雄进行了修改，把原来的“张飞”改成了“张翼德”：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; BEGIN;</span><br><span class="line">SQL&gt; UPDATE heros_temp SET name = &#x27;张翼德&#x27; WHERE id = 1;</span><br></pre></td></tr></table></figure><p>然后小张再进行一次查询，同样也是查看id=1 的英雄是谁：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; SELECT name FROM heros_temp WHERE id = 1;</span><br></pre></td></tr></table></figure><p>运行结果：</p><p><img src="https://i.loli.net/2020/12/08/o3QYKycrwJ6sLVd.png"></p><p>这个时候你会发现，两次查询的结果并不一样。小张会想这是怎么回事呢？他明明刚执行了一次查询，马上又进行了一次查询，结果两次的查询结果不同。实际上小张遇到的情况我们称之为“<code>不可重复读</code>”。 也就是同一条记录，两次读取的结果不同。</p><p>什么时幻读？</p><p>第三天，小张想要看下数据表里都有哪些数据，他开始执行下面这条语句：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; SELECT * FROM heros_temp;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/08/HRTCGglhE3c6WnM.png"></p><p>这时当小张执行完之后，小李又开始一个事务，往数据库里插入一个新的英雄“吕布”：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; BEGIN;</span><br><span class="line">SQL&gt; INSERT INTO heros_temp values(4,&#x27;吕布&#x27;);</span><br></pre></td></tr></table></figure><p>不巧的是，小张这时忘记了英雄都有哪些，又重新执行了一遍查询：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SQL&gt; SELECT * FROM heros_temp;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/12/08/9rhzEAsOXV1uZRb.png"></p><p>他发现这一次查询多了一个英雄，原来只有3个，现在变成了4个。这种异常情况我们称之为 “<code>幻读</code>”。</p><p>我来总结下这三种异常情况的特点：</p><ol><li>脏读：读到了其他事务还没有提交的数据。</li><li>不可重复读：对某数据进行读取，发现两次读取的结果不同，也就是说没有读到相同的内容。这是因为有其他事务对这个数据同时进行了修改或删除。</li><li>幻读：事务 A 根据条件查询得到了 N 条数据，但此时事务 B 更改或者增加了 M 条符合事务 A 查询条件的数据，这样当事务 A 再次进行查询的时候发现会有 N+M 条数据，产生了幻读。</li></ol><h3 id="事务隔离的级别有哪些？"><a href="#事务隔离的级别有哪些？" class="headerlink" title="事务隔离的级别有哪些？"></a>事务隔离的级别有哪些？</h3><p>脏读、不可重复读、和幻读这三种异常情况，是在SQL-92标准中定义的，同时SQL-92标准还定义了4中隔离级别来解决这些异常情况。</p><p>解决异常数量从少到多的顺序决定了隔离级别的高低，这四种隔离级别从低到高分别是：<code>读未提交（READ UNCOMMITTED）</code>、<code>读已提交（READ COMMITTED）</code>、<code>可重复读（REPEATABLE REDAD）</code>和<code>可串行化（SERIALIZABLE）</code>。这些隔离级别能解决的异常情况如下表所示：</p><p><img src="https://i.loli.net/2020/12/08/53rF4yiBaQzK9wg.png"></p><ul><li>读未提交，也就是允许读到未提交的数据，这种情况下查询是不会使用锁的，可能会产生脏读、不可重复读、幻读等情况。</li><li>读已提交，也就是只能读到已经提交的内容，可以避免脏读的产生，属于RDBMS中常见的默认隔离级别，但如果想要避免不可重复度或者幻读，就需要我们在SQL查询的时候编写带加锁的SQL语句。</li><li>可重复读，保证了一个事务在相同条件下两次查询得到的数据结果数据结果是一致的，可以避免不可重复读和脏读，但无法避免幻读。MySQL默认隔离级别就是可重复度。</li><li>可串行化，将事务进行串行话，也就是在一个队列中按照顺序执行，可串行化是最高的隔离等级，可以解决事务读取中所有可能出现的异常情况，但是他牺牲了系统的并发性。</li></ul><p>隔离级别越低，意味着系统吞吐量（并发程度）越大，但同时也意味着出现异常问题的可能性会更大。在实际使用过程中我们往往需要在性能和正确性上进行权衡和取舍，没有完美的解决方案，只有适合与否。</p><p>不可重复读是对于同一条记录内容的“不可重复读”<br>幻读是对于某一范围的数据集，发现查询数据集的行数多了或者少了，从而出现的不一致。<br>所以不可重复读的原因是 对于要查询的那条数据进行了UPDATE或DELETE<br>而幻读是对于要查询的 那个范围的数据集，进行了INSERT。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://i.loli.net/2020/12/08/cMbuxoJT3adSH7z.png"></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL事务隔离级别 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL事务</title>
      <link href="/2020/11/25/MySQL%E4%BA%8B%E5%8A%A1/"/>
      <url>/2020/11/25/MySQL%E4%BA%8B%E5%8A%A1/</url>
      
        <content type="html"><![CDATA[<p>在SQL5.5版本之前，默认的存储引擎是MyISAM，在5.5版本之后默认存储引擎是InnoDB。InnoDB和MyISAM区别之一就是InnoDB支持事务，也可以以说这是InnoDB取代MyISAM的重要原因。那么什么是事务呢？事务的英文是tracsaction，从英文中你也能看出来它是进行一次处理的基本单元，要么完全执行，要么都不执行。</p><p>这么讲，你可能觉得有些抽象，换种方式讲。</p><p>比知道遇过这样的情况，你去家门口的小卖铺买东西，已经交了钱，但是老板比较忙接了个电话，忘记你是否交过钱，然后你重新付款，这是还要找之前的付款记录证明你已经完成了付款。</p><p>实际上如果我们线下的交易也能支持事务（满足事务的特性），就不会出现交了钱却拿不到商品的烦恼了，同样，对于小卖铺的老板来说，也不存在给出了商品但没有收到款的风险。总之，事务保证了一次处理的完整性，也保证了数据库中的数据一致性。它是一种高级的数据处理方式，如果我们在增加、删除、修改的时候某一个环节出了错，它允许我们回滚还原。正式因为这个特点，事务非常适合应用在安全性高的场景里，比如金融行业等。</p><h3 id="事务的特性：ACID"><a href="#事务的特性：ACID" class="headerlink" title="事务的特性：ACID"></a>事务的特性：ACID</h3><ol><li>A，也就是原子性（Atomicity）。原子的概念是不可分割，你可以把它理解为组成物质的基本单位，也是我们进行数据处理操作的基本单位。</li><li>C，就是一致性（Consistency）。一致性指的是事务库在进行事务操作后，会由原来的一致状态，变成另一种一致的状态。也就是说当事务提交后，或者当事务发生回滚后，数据库的完整性约束不能被破坏。</li><li>I，隔离性（Isolation），它值得是每个事务都是彼此独立的，不会受到其他事务的执行影响，也就是说一个事务在提交之前，对其他事务是不可见的。</li><li>D，指的是持久性（Durability）。事务提交后对数据的修改时持久性的，即使在系统出故障的情况下，比如系统崩溃或者存储介质发生故障，数据的修改依然是有效的。因为当事务完成，数据库的日志就会被更新，这时可以通过日志，让系统回复到最后一次成功的状态。</li></ol><p>ACID可以说事务的四大特性，在这四个特性中，原子性是基础，隔离性是手段，一致性是约束条件，而持久性是我们的目的。</p><p>这里指的一致性本身是由具体的业务定义的，也就是说，任何写入数据库中的数据都需要满足我们事先定义的约束规则。</p><p>比如说，在数据表中我们将姓名字段设置为唯一性约束，这时当事务进行提交或者事务发生回滚的时候，如果数据表中的姓名非唯一，就破坏了事务的一致性要求。所以说，事务操作会让数据表的状态变成另一种一致的状态，如果事务中的某个操作失败了，系统就会自动撤销当前正在执行的事务，返回事务操作之前的状态。</p><p>事务的另一个特点就是持久性，持久性是通过事务日志来保证的。日志包括了回滚日志和重做日志。但我们通过事务对数据进行修改的时候，首先会将数据库的变化信息记录到重做记录中，然后在对数据库中对应的行进行修改。这样做的好处是，既是数据库系统崩溃，数据库重启后也能找到没有更新到数据库系统系统中的重做日志，重新执行，从而使事务具有持久性。</p><h3 id="事务的控制"><a href="#事务的控制" class="headerlink" title="事务的控制"></a>事务的控制</h3><p>如果你使用的是MySQL，可以通过<code>SHOW ENGINES</code> 命令来查看当前MySQL支持的存储引擎都有哪些，以及这些存储引擎是否支持事务。</p><p><img src="https://i.loli.net/2020/12/08/uGOxPcStYWIn5wz.png"></p><p>你能看出在MySQL中，InnoDB是支持事务的，而MyISAM存储引擎不支持事务。</p><h3 id="事务的控制语句"><a href="#事务的控制语句" class="headerlink" title="事务的控制语句"></a>事务的控制语句</h3><ol><li>START TRANSACTION 或者 BEGIN，作用是显示开启一个事务。</li><li>COMMIT：提交事务。当提交事务后，对数据库的修改是永久性的。</li><li>ROLLBACK 或者 ROLLBACK TO [SAVEPOINT]，意为回滚事务。意思是撤销正在进行的所有没有提交的修改，或者将事务回滚到某个保存点。</li><li>SAVEPOINT：在事务中创建保存点，方便后续针对保存点进行回滚。一个事务中可以存在多个保存点。</li><li>RELEASE SAVEPOINT：删除某个保存点。</li><li>SET TRANSACTION ，设置事务的隔离级别。</li></ol><p>需要说明的是，使用事务有两种方式，分别为隐式事务和显示事务。隐式事务实际上就是自动提交，Oracle默认不自动提交，需要手写COMMIT命令，而MySQL默认自动提交，当然我们可以配置MySQL的参数：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set autocommit = 0 //关闭自动提交</span><br></pre></td></tr></table></figure><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; set autocommit &#x3D; 1 &#x2F;&#x2F;开启自动提交</span><br></pre></td></tr></table></figure><p>看下MySQL的默认状态下，下面这个事务最后的处理结果是什么：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">test</span>(<span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">255</span>), PRIMARY <span class="keyword">KEY</span> (<span class="keyword">name</span>)) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span>;</span><br><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">SELECT</span> <span class="string">&#x27;关羽&#x27;</span>;</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">SELECT</span> <span class="string">&#x27;张飞&#x27;</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">SELECT</span> <span class="string">&#x27;张飞&#x27;</span>;</span><br><span class="line"><span class="keyword">ROLLBACK</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="keyword">test</span>;</span><br></pre></td></tr></table></figure><p>运行结果（1行记录）：</p><p><img src="https://i.loli.net/2020/12/08/SHPveRu4KpA5Tin.png"></p><p>在这个事务中，整个SQL一共执行了2个事务，第一个是插入“关羽”，提交后执行成功，第二个是插入两次“张飞”，这里需要注意的是，我们将name设置为了主键，也就是说主键的值是唯一的，那么第二次插入“张飞”时就会产生错误，然后执行<code>ROLLBACK</code> 相当于对事务进行了回滚，所以我们看到最终结果就只有一行数据，也就是第一个事务执行之后的结果，即 “关羽“、</p><p>那么下面的操作又会怎样呢？</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">test</span>(<span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">255</span>), PRIMARY <span class="keyword">KEY</span> (<span class="keyword">name</span>)) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span>;</span><br><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">SELECT</span> <span class="string">&#x27;关羽&#x27;</span>;</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">SELECT</span> <span class="string">&#x27;张飞&#x27;</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">SELECT</span> <span class="string">&#x27;张飞&#x27;</span>;</span><br><span class="line"><span class="keyword">ROLLBACK</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="keyword">test</span>;</span><br></pre></td></tr></table></figure><p>运行结果（2行数据）：</p><p><img src="https://i.loli.net/2020/12/08/1E6RpU8JcWj2Ooq.png"></p><p>你能看到这次数据时两行，上一次操作我把两次插入”张飞“ 放到一个事务里，而这次操作它们不在同一个事务里，那么对于MySQL来说，默认情况下这就是两个事务，因此在atuocommit =1 的情况下，MySQL会进行隐式事务，也就是自动提交，因此在进行第一次插入”张飞“ 后，数据表里就存在了两行数据，而第二次插入 ”张飞“ 就会报错：<code>1062 - Dup licate entry ‘张飞’ for key &#39;PRIMARY&#39;</code>。</p><p>最后我们在执行ROLLBACK的时候，实际上事务已经自动提交了，就没法进行回滚了。</p><p>同样我们再来看下这段代码，你又会发现什么不同呢？</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> <span class="keyword">TABLE</span> <span class="keyword">test</span>(<span class="keyword">name</span> <span class="built_in">varchar</span>(<span class="number">255</span>), PRIMARY <span class="keyword">KEY</span> (<span class="keyword">name</span>)) <span class="keyword">ENGINE</span>=<span class="keyword">InnoDB</span>;</span><br><span class="line"><span class="keyword">SET</span> @@completion_type = <span class="number">1</span>;</span><br><span class="line"><span class="keyword">BEGIN</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">SELECT</span> <span class="string">&#x27;关羽&#x27;</span>;</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">SELECT</span> <span class="string">&#x27;张飞&#x27;</span>;</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">test</span> <span class="keyword">SELECT</span> <span class="string">&#x27;张飞&#x27;</span>;</span><br><span class="line"><span class="keyword">ROLLBACK</span>;</span><br><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> <span class="keyword">test</span>;</span><br></pre></td></tr></table></figure><p>运行结果（1行记录）：</p><p><img src="https://i.loli.net/2020/12/08/iWu7Kfy3pIcGOaC.png"></p><p>你能看到还是相同的SQL代码，只是我在事务开始之前设置了<code>SET @@completion_type = 1;</code>，记过就和第一次处理的一样，只有一个”关羽“。这是为什么呢？</p><p>completion_type参数的作用，实际上这个参数有三种可能：</p><ol><li>completion = 0，这是默认情况。也就是说当我们执行COMMIT的时候会自动提交事务，在执行下一个事务时，还需要我们使用<code>START TRANSACTION</code> 或者 <code>BEGIN</code> 来开启。</li><li>completion = 1，这种情况下，当我们提交事务后，相当于执行了<code>COMMIT AND CHAIN</code>，也就时开启了一个链式事务，即当我们提交事务之后会开启一个相同的隔离级别的事务。</li><li>completion = 2，这种情况下<code>COMMIT=COMMIT AND RELEASE</code>，也就是当我们提交后，会自动与服务器断开连接。</li></ol><p>在上面这段代码里，我使用了<code>completion = 1</code>，也就是说当我提交之后，相当于在下一行写了一个<code>START TRANSACTION 或 BEGIN</code>。这时两次插入”张飞“ 会被认为是在同一个事务之内的操作，那么第二次插入”张飞“ 就会导致事务失败，而回滚也将这次事务进行了撤销，所以你能看到的结果就只有一个”关羽“。</p><p>当我们设置 autocommit=0 时，不论是否采用 START TRANSACTION 或者 BEGIN 的方式来开启事务，都需要用 COMMIT 进行提交，让事务生效，使用 ROLLBACK 对事务进行回滚。</p><p>当我们设置 autocommit=1 时，每条 SQL 语句都会自动进行提交。<br>不过这时，如果你采用 START TRANSACTION 或者 BEGIN 的方式来显式地开启事务，那么这个事务只有在 COMMIT 时才会生效，在 ROLLBACK 时才会回滚。</p><p><strong>在MySQL中，如果是连续BEGIN，开启了第一个事务，还没有进行COMMIT提交，而直接进行第二个事务的BEGIN，数据库会隐式的帮助COMMIT第一个事务，然后进入到第二个事务</strong></p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://i.loli.net/2020/12/08/YtPGrLXiQv2F7hk.png"></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL事务 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>从磁盘角度理解SQL查询成本</title>
      <link href="/2020/11/24/%E4%BB%8E%E7%A3%81%E7%9B%98IO%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3SQL%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%88%90%E6%9C%AC/"/>
      <url>/2020/11/24/%E4%BB%8E%E7%A3%81%E7%9B%98IO%E8%A7%92%E5%BA%A6%E7%90%86%E8%A7%A3SQL%E6%9F%A5%E8%AF%A2%E7%9A%84%E6%88%90%E6%9C%AC/</url>
      
        <content type="html"><![CDATA[<p>数据库存储的基本单位是页，对于一颗B+树的索引来说，是先从根节点找到叶子节点，也就是先查找数据行所在的页，再将页读入到内存中，在内存中对页的记录进行查找，从而得到想要的数据。你看，虽然我们想要查找到的，只是一行记录，但是对于磁盘I/O来说却需要加载一页的信息，因为页是最小的存储单位。</p><p>那么对于数据库来说，如果我们想要查找多行记录，查询时间是否会成倍的提升呢？其实数据库会采用缓冲池的方式提升页的查询效率。</p><h3 id="数据库缓冲池"><a href="#数据库缓冲池" class="headerlink" title="数据库缓冲池"></a>数据库缓冲池</h3><p>磁盘I/O需要消耗的时间很多，而在内存中进行操作，效率则会高很多，为了能让数据表或者索引中的数据随时被我们所用，DBMS会申请占用内存来作为数据库缓冲池，这样做的好处是可以让磁盘活动最小化，从而减少磁盘直接进行I/O的时间。要知道，这种策略对提升SQL语句的查询性能来说至关重要。如果索引的数据在缓冲池里，那么访问的成本就会降低很多。</p><p>那么缓冲池如何读取数据呢？</p><p>缓冲池管理器会尽量将经常使用的数据保存起来，在数据库进行页面读取操作的时候，首先会判断该页面是否在缓冲池中，如果存在就直接读取，如果不存在，就会通过内存或磁盘将页面存放到缓冲池中在进行读取。</p><p>缓存在数据库中的结构和作用如下图所示：</p><p><img src="https://i.loli.net/2020/11/27/Tg9ykuSjlKOXZtq.png"></p><p>如果我们执行SQL语句的时候更新了缓存池中的数据，那么这些数据会马上同步到磁盘上吗？</p><p>实际上，当我们对数据库中的记录进行修改的时候，首先会修改缓冲池中叶里面的记录信息，然后数据库以一定的频率刷新到磁盘。注意并不是每次发生更新操作，都会立刻进行磁盘回写。缓冲此采用一种叫做checkpoint的机制将数据回写道磁盘上，这样做的好处就是提升了数据库的整体性能。</p><p>比如，但缓冲池不够用时，需要释放掉一些不常用的页，就是可以采用强行采用checkpoing的方式，将不常用的脏页回写到磁盘上，然后再从缓冲池中将这些页释放掉。这里的脏页（dirty page）指的是缓冲池被修改过的页，与磁盘上的数据页不一致。</p><h3 id="查看缓存池的大小"><a href="#查看缓存池的大小" class="headerlink" title="查看缓存池的大小"></a>查看缓存池的大小</h3><p>了解完缓冲池的工作远离后，你可能想问，我们如何判断缓冲池的大小？</p><p>如果你使用的时MySQL MyISAM存储运行，他只缓存索引，不缓存数据，对应的键缓存参数位key_buffer_size，你可以用它进行查看。</p><p>如果你使用的是InnoDB存储引擎，可以通过查看innodb_buffer_pool_size变量来查看缓冲池的大小，命令如下：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#x27;innodb_buffer_pool_size&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/11/27/sVy8knjKzHw2BSl.png"></p><p>你能看到此时InnoDB的缓冲池只有83886088/1024/1024 = 8MB，我们可以修改缓冲池大小位128MB，方法如下：</p><p><img src="https://i.loli.net/2020/11/27/7NMq5meuyspFbnE.png"></p><p>然后再来看下修改后的缓冲池大小，此时已经成功修改成了128MB：</p><p><img src="https://i.loli.net/2020/11/27/Czoxb7LHgATNfUu.png"></p><p>在InnoDB存储引擎中，我们可以同时开启多个缓冲池，这里我们看下如何查看缓冲池的个数，使用命令：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; show variables like &#x27;innodb_buffer_pool_instances&#x27;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/11/27/EANgjOrakeSpoFV.png"></p><p>你能看到当前只有一个缓冲池。实际上innodb_buffer_pool_instances默认情况下为8，为什么只显示一个呢？这里需要说明的是，如果想要开启多个缓冲池，你首先需要将innodb_buffer_pool_size参数设置为大于等于1GB，这时innodb_buffer_pool_instances才会大于1。你可以在MySQL的配置文件中对innodb_buffer_pool_size进行设置，大于等于1GB，然后在针对innodb_buffer_pool_instances参数进行修改。</p><h3 id="数据页加载的三种方式"><a href="#数据页加载的三种方式" class="headerlink" title="数据页加载的三种方式"></a>数据页加载的三种方式</h3><p>如果缓冲池中没有该页的数据，那么缓冲池有以下三种读取数据的方式，每种方式的读取效率都是不同的：</p><h4 id="1-内存读取"><a href="#1-内存读取" class="headerlink" title="1.内存读取"></a>1.内存读取</h4><p>如果该数据存在于内存中，基本上执行时间在1ms左右，效率还是很高的。</p><p><img src="https://i.loli.net/2020/11/27/AmfdIiDpRFLhcQN.png"></p><h4 id="2-随机读取"><a href="#2-随机读取" class="headerlink" title="2.随机读取"></a>2.随机读取</h4><p>如果数据没有在内存中，就需要在磁盘上对该页进行查找，整体时间预估在10ms左右，这10ms中有6ms是磁盘的实际繁忙时间（包括了寻道和半圈旋转时间），有3ms是对可能发生的排队时间的估计值，另外还有1ms的传输时间，将页从此磁盘服务器缓冲区传输到数据库缓冲区中。这10ms看起来很快，但实际上对于数据来说消耗的时间已经非常长了，因为这还只是一个页的读取时间。</p><p><img src="https://i.loli.net/2020/11/27/Mgq2njwu4ACslL8.png"></p><h4 id="3-顺序读取"><a href="#3-顺序读取" class="headerlink" title="3.顺序读取"></a>3.顺序读取</h4><p>顺序读取其实是一种批量读取的方式，因为我们请求的数据在磁盘上往往都是相邻存储的，顺序读取可以帮我们批量读取页面，这样的话，一次性加载到缓冲池终究不需要在对其他页面单独进行磁盘I/O操作了。如果一个磁盘的吞吐量时40MB/s，那么对一个16KB大小的页来说，一次可以顺序读2560（40MB/16KB）个页，相当于一个页的读取时间为0.4ms。采用批量读取的方式，即使是从磁盘上进行读取，效率也比从内存中只单独读取一个页的效率要高。</p><h3 id="通过last-query-cost统计SQL语句的查询成本"><a href="#通过last-query-cost统计SQL语句的查询成本" class="headerlink" title="通过last_query_cost统计SQL语句的查询成本"></a>通过last_query_cost统计SQL语句的查询成本</h3><p>一条SQL查询语句在执行前需要确定查询计划，如果存在多种查询计划的话，MySQL就计算每个查询计划所需要的成本，从中选择最小的一个作为最终执行的查询计划。</p><p>如果我们想要查看某条SQL语句的查询成本，可以在执行完这条SQL语句之后，通过查看当前会话中的last_query_cost变量值来得到当前查询的成本。这个查询成本对应的是SQL语句所需要读取的页的数量。</p><p>我以 product_comment 表为例，如果我们想要查询 comment_id=900001 的记录，然后看下查询成本，我们可以直接在聚集索引上进行查找：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT comment_id,product_id,comment_text,user_id FROM product_comment WHERE comment_id = 900001;</span><br></pre></td></tr></table></figure><p>运行结果（1条记录，运行时间为0.042s）：</p><p><img src="https://i.loli.net/2020/11/27/viT2g5quaZhdlGW.png"></p><p>然后再看下查询优化器的成本，实际上我们只需要检索一个页即可：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW STATUS LIKE &#x27;last_query_cost&#x27;;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/11/27/w6EAj3q8l7YImRK.png"></p><p>如果我们想要查询comment_id在900001到9000100之间的评论记录呢？</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SELECT comment_id, product_id, comment_text, user_id FROM product_comment WHERE comment_id BETWEEN 900001 AND 900100;</span><br></pre></td></tr></table></figure><p>运行结果（100 条记录，运行时间为 0.046s）：</p><p><img src="https://i.loli.net/2020/11/27/hxYS39QkN6tBui8.png"></p><p>然后再看一下查询优化器的成本，这时我们大概需要进行20页的查询。</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">mysql&gt; SHOW STATUS LIKE &#x27;last_query_cost&#x27;;</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/11/27/4Bl3rusdTARzZ5n.png"></p><p>你能看到页的数量是刚才的 20 倍，但是查询的效率并没有明显的变化，实际上这两个 SQL 查询的时间基本上一样，就是因为采用了顺序读取的方式将页面一次性加载到缓冲池中，然后再进行查找。虽然页数量（last_query_cost）增加了不少，但是通过缓冲池的机制，并没有增加多少查询时间。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><ol><li><p>位置决定效率。如果页就在数据库缓冲池中，那么效率是最高的，否在还需要从内存或者磁盘中进行读取，当然针对单个页的读取来说，如果页在内存中，会比在磁盘中读取效率高很多。</p></li><li><p>批量决定效率。如果我们从磁盘中对单一页进行随机读，那么效率很低的（差不多10ms），而采用顺序读取的方式，批量对页进行读取，平均一页的读取效率就会提升很多，甚至还有快于单个页面在内存中的随机读取。</p></li></ol><p>所以说，遇到 I/O 并不用担心，方法找对了，效率还是很高的。我们首先要考虑数据存放的位置，如果是经常使用的数据就要尽量放到缓冲池中，其次我们可以充分利用磁盘的吞吐能力，一次性批量读取数据，这样单个页的读取效率也就得到了提升。</p><p><img src="https://i.loli.net/2020/11/27/yTQFiuI8b4tULz5.png"></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>MySQL基础</title>
      <link href="/2020/11/24/MySQL%E5%9F%BA%E7%A1%80/"/>
      <url>/2020/11/24/MySQL%E5%9F%BA%E7%A1%80/</url>
      
        <content type="html"><![CDATA[<h3 id="SELECT-查询的基础语法"><a href="#SELECT-查询的基础语法" class="headerlink" title="SELECT 查询的基础语法"></a>SELECT 查询的基础语法</h3><p>SELECT 可以帮助我们从一个表或多个表中进行数据查询。我们知道一个数据表是由列（字段名）和行（数据行）组成的，我们要返回满足条件的数据行，就需要在SELECT 后面加上我们想要查询的列名，可以是一列，也可以时多个列。如果你不知道所有列名都有什么，也可以检索所有列。</p><h4 id="查询列"><a href="#查询列" class="headerlink" title="查询列"></a>查询列</h4><p>如果我们想要对数据表中的某一列进行检索，在SELECT后面加上这个列的字段名即可。比如我们想要检索数据表中都有那些英雄。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SQL：<span class="keyword">SELECT</span> <span class="keyword">name</span> <span class="keyword">FROM</span> heros</span><br></pre></td></tr></table></figure><p>运行结果（69条记录）见下图，你可以看到这样就等于单独输出了name这一列。</p><p><img src="https://i.loli.net/2020/11/28/sFQ5rmH3f2uK1O4.png"></p><p>我们也可以对多个列进行检索，在列名之间用逗号（，）风分割即可。比如我们想要检索有哪些英雄，他们的最大生命、最大法力、最大物攻和最大物防分别是多少。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span>, hp_max, mp_max, attack_max, defense_max <span class="keyword">FROM</span> heros</span><br></pre></td></tr></table></figure><p>运行结果（69条记录）：</p><p><img src="https://i.loli.net/2020/11/28/dmanXwL9qIEl413.png"></p><p>这个表中一共有25个字段，除了id和英雄名name以外，还存在23个属性值，如果我们记不住说有字段，还可以使用SELECT * 帮助我们检索出所有的列：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> * <span class="keyword">FROM</span> heros</span><br></pre></td></tr></table></figure><p>运行结果（69条记录）：</p><p><img src="https://i.loli.net/2020/11/28/Uo2xlC3PYXaNDEK.png"></p><p>我们在做数据探索的时候，SELECT * 还是很有用的，这样我们就不需要写很长的SELECT 语句了。但是在生产环境时要尽量避免使用SELECT * ，具体原因后面讲。</p><h3 id="起别名"><a href="#起别名" class="headerlink" title="起别名"></a>起别名</h3><p>我们在使用SELECT查询的时候，还有一些技巧可以使用，比如你可以给列名起别名。我们在进行检索的时候，可以给英雄名、最大生命、最大物攻、和最大物防等取别名：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span> <span class="keyword">AS</span> n,hp_max <span class="keyword">AS</span> hm,mp_max <span class="keyword">AS</span> mm,attack_max <span class="keyword">AS</span> am,defense_max <span class="keyword">AS</span> dm <span class="keyword">FROM</span> <span class="string">`heros`</span></span><br></pre></td></tr></table></figure><p>运行结果和上面多列检索的运行结果是一样，只是将列名改成了n、hm、mm、am 和 dm。当然这里的列别名只是举例，一般来说起别名的作用是对原有名称进行简化，从而让SQL语句看起来更简单。同样我们也可以对表名称起别名，这样再多表连接查询的时候会用到。</p><h3 id="查询常数"><a href="#查询常数" class="headerlink" title="查询常数"></a>查询常数</h3><p>SELECT 查询还可以对常数进行查询。对的，就是在SELECT查询结果中增加一列固定的常数列。这列的取值是我们指定的，而不是从数据表中动态取出的。你可能会问为什么我们还要对常数进行查询呢？SQL中的SELECT语法的确提供了这个功能，一般来说我们只从一个表中查询数据，通常不需要增加一个固定的常数列，但如果我们想整合不同的数据源，用常数列作为这个表的标记，就需要查询常数。</p><p>比如说，我们想对heros 数据表中的英雄进行查询，同时增加一列字段platform，这个字段固定为 “王者荣耀”，可以这样写：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="string">&#x27;王者荣耀&#x27;</span> <span class="keyword">as</span> platform,<span class="keyword">name</span> <span class="keyword">from</span> heros;</span><br></pre></td></tr></table></figure><p>运行结果：（69条记录）</p><p><img src="https://i.loli.net/2020/11/28/wWop3x7lJ2hqE6v.png"></p><p>在这个SQL语句中，我们虚构了一个platform字段，并且把它设置成固定值“王者荣耀”。</p><p>需要说明的是，如果常数是个字符串，那么使用单引号（‘’）就非常重要了，比如 ‘王者荣耀’。单引号说明引号中的字符串是个常数，否则SQL会把王者荣耀当成列名进行查询，但实际上数据表里没有这个列名，就会引起错误。如果常数是英文字母，比如 ‘WZRY’ 也需要加引号。如果常数是个数字，就可以直接写数字，不需要单引号，比如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="number">123</span> <span class="keyword">as</span> platform,<span class="keyword">name</span> <span class="keyword">FROM</span> heros</span><br></pre></td></tr></table></figure><p>运行结果：（69条记录）</p><p><img src="https://i.loli.net/2020/11/28/v3AV6TuSpBgMnIh.png"></p><h3 id="去处重复行"><a href="#去处重复行" class="headerlink" title="去处重复行"></a>去处重复行</h3><p>关于单个表的SELECT 查询，还有一个非常使用的操作，就是从结果中去掉重复的行。使用的关键字是DISTINCT。比如我们想要看下heros表中关于攻击范围的取值都有哪些：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> attack_range <span class="keyword">FROM</span> heros</span><br></pre></td></tr></table></figure><p>这是运行结果（2条记录），这样我们就能直观的看到攻击范围其实就两个值，那就是近战和远战。</p><p><img src="https://i.loli.net/2020/11/28/RGEIpnXOo5BQfaw.png"></p><p>如果我们带上英雄名称，会是怎样呢：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> attack_range,<span class="keyword">name</span> <span class="keyword">FROM</span> heros</span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/11/28/CWxM5pewzUhIcf4.png"></p><p>这里有两点需要主要：</p><ol><li>DISTINCT 需要放到所有列名的前面，如果写成SELECT name，DISTINCT attack_range FROM heros 会报错。</li><li>DISTINCT 其实是对后面所有列名的组合进行去重，你能看到最后的结果是69条，因为这69个英雄名称不同，都有攻击范围（attack_range）这个属性。如果你想要看都有哪些不同的攻击范围（attck_range），只需要写DISTINCT attack_range即可，后面不需要在加其他的列名了。</li></ol><h4 id="如何排序检索数据"><a href="#如何排序检索数据" class="headerlink" title="如何排序检索数据"></a>如何排序检索数据</h4><p>但我们检索数据的时候，又是后需要按照某种顺序进行结果的返回，比如我们想要查询所有的英雄，按照最大生命从高到低的顺序进行排列，就需要使用ORDER BY 字句。使用ORDER BY 有以下几个点需要掌握：</p><ol><li>排序的列名：ORDER BY 后面可以有一个或多个列名，如果多个列名进行排序，会按照后面第一个列先进行排序，当第一列值相同的时候，再按照第二列进行排序，一次类推。</li><li>排序的顺序：ORDER BY 后面可以注明排序规则，ASC代表递增排序，DESC代表递减排序。如果没有注明排序规则，但如果排序字段类型为文本数据，就需要参考数据库的设计方式了，这样才能判断A是在B之前，还是在B之后。比如使用MySQL在创建字段的时候设置为BINARY属性，就代表区分大小写。</li><li>非选择列排序：ORDER BY可以使用非选择列进行排序，所以即使在SELECT 后面没有这个列名，你同样可以放到ORDER BY后面进行排序。</li><li>ORDER BY的位置：ORDER BY 通常位于SELECT 语句的最后一条字句，否则会报错。</li></ol><p>在了解了ORDER BY的使用语法之后，我们来看下如何对heros 数据表进行排序。</p><p>假设我们想要显示英雄名称及最大生命值，按照最大生命值从高到低的方式进行排序：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span>,hp_max <span class="keyword">FROM</span> heros <span class="keyword">ORDER</span> <span class="keyword">BY</span> hp_max <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure><p>运行结果（69条记录）：</p><p><img src="https://i.loli.net/2020/11/28/HkWRaFZlfdAuOsn.png"></p><p>如果想要显示英雄名称及最大生命值，按照第一排序最大法力从高到低，当最大法力值相等的时候则按照第二排序进行，即最大生命值从高到底的方式进行排序：</p><p>运行结果：（69条记录）</p><p><img src="https://i.loli.net/2020/11/28/v58aVWFctZKfpPg.png"></p><h3 id="约束返回结果的数量"><a href="#约束返回结果的数量" class="headerlink" title="约束返回结果的数量"></a>约束返回结果的数量</h3><p>另外在查询过程中，我们可以约束返回结果的数量，使用LIMIT关键字。比如我们想要返回英雄名称及最大生命值，按照生命值从高到低排序，返回5条记录即可。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span>,hp_max <span class="keyword">FROM</span> heros <span class="keyword">ORDER</span> <span class="keyword">BY</span> hp_max <span class="keyword">DESC</span> <span class="keyword">LIMIT</span> <span class="number">5</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/11/28/Xl2qBYZAGm7Mcbt.png"></p><p>约束返回结果的数量可以减少数据表的网络传输量，也可以提升查询效率。如果我们知道返回结果只有一条，就可以是使用LIMIT 1，告诉SELCT 语句只需要返回一条记录即可。这样的好处就是SELECT 不需要扫描完整的表，只需要检索到一条符合条件的记录即可返回。</p><h3 id="SELECT-的执行顺序"><a href="#SELECT-的执行顺序" class="headerlink" title="SELECT 的执行顺序"></a>SELECT 的执行顺序</h3><p>查询时RDBMS中最频繁的操作。我们在理解SELECT语法的时候，还需要了解SELECT 执行时的底层原理。只有这样，才能让我们对SQL有更深刻的认识。</p><p>其中你需要记住SELECT查询时的两个顺序：</p><ol><li><p>关键字的顺序时不能颠倒的：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> ... <span class="keyword">FROM</span> ... <span class="keyword">WHERE</span> ... <span class="keyword">GROUP</span> <span class="keyword">BY</span> <span class="keyword">HAVING</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> ...</span><br></pre></td></tr></table></figure></li><li><p>SELECT 语句的执行顺序：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">FROM &gt; WHERE &gt; GROUP BY &gt; HAVING &gt; SELECT 的字段 &gt; DISTINCT &gt; ORDER BY &gt; LIMIT</span><br></pre></td></tr></table></figure><p>完整的顺序：</p><blockquote><ol><li>FROM 子句组装数据（包括通过 ON 进行连接）；</li><li>WHERE 子句进行条件筛选；</li><li>GROUP BY 分组 ；</li><li>使用聚集函数进行计算；</li><li>HAVING 筛选分组；</li><li>计算所有的表达式；</li><li>SELECT 的字段；</li><li>ORDER BY 排序；</li><li>LIMIT 筛选。</li></ol></blockquote></li></ol><p>   比如你写了一个SQL语句，那么它的关键字顺序和执行顺序时下面这样的：</p>   <figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span> player_id, player_name, <span class="keyword">count</span>(*) <span class="keyword">as</span> <span class="keyword">num</span> <span class="comment"># 顺序 5</span></span><br><span class="line">   <span class="keyword">FROM</span> player <span class="keyword">JOIN</span> team <span class="keyword">ON</span> player.team_id = team.team_id <span class="comment"># 顺序 1</span></span><br><span class="line"><span class="keyword">WHERE</span> height &gt; <span class="number">1.80</span> <span class="comment"># 顺序 2</span></span><br><span class="line">   <span class="keyword">GROUP</span> <span class="keyword">BY</span> player.team_id <span class="comment"># 顺序 3</span></span><br><span class="line"><span class="keyword">HAVING</span> <span class="keyword">num</span> &gt; <span class="number">2</span> <span class="comment"># 顺序 4</span></span><br><span class="line">   <span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="keyword">num</span> <span class="keyword">DESC</span> <span class="comment"># 顺序 6</span></span><br><span class="line"><span class="keyword">LIMIT</span> <span class="number">2</span> <span class="comment"># 顺序 7</span></span><br></pre></td></tr></table></figure><p>   在SELECT语句执行这些步骤的时候，每个步骤都会产生一个虚拟表，然后将这个虚拟表传入下一个步骤中作为输入。需要注意的是，这些步骤隐含在SQL的执行过程中，对于我们来说是不可见的。</p><p>   我来详细解释以下SQL的执行原理。</p><p>   首先，你可以注意到，SELECT 是先执行FROM 这一步的。在这个阶段，如果是多张表联查，还会经历下面的几个步骤：</p><ol><li><p>首先先通过CROSS JOIN 求笛卡尔积，相当于得到虚表vt（virtual table）1-1；</p></li><li><p>通过ON进行筛选，在虚拟表vt1-1的基础上进行筛选，得到虚拟表vt1-2;</p></li><li><p>添加外部行。如果我们使用的是左连接，右连接或者全连接，就会涉及到外部行，也就是在虚拟表vt1-2的基础上增加外部行，得到虚拟表vt1-3。</p><p>当然如果我们操作的是两张以上的表，还会重复上面的步骤，知道所有表都被处理完为止。这个过程得到是我们的原始数据。</p><p>当我们拿到了查询数据表的原始数据，也就是最终的虚拟表vt1，就可以在此基础上再进行WHERE 阶段。在这个阶段中，会根据vt1表中的结果进行筛选过滤，得到虚拟表vt2。</p><p>然后进入第三步和第四步，也就是GROUP 和 HAVING 阶段。再这个阶段中，实际上是再虚拟表vt2的基础上进行分组和分组过滤，得到中间的虚拟表vt3和vt4。</p><p>当我们完成了条件筛选部分之后，就可以筛选表中提取的字段，也就是进入到SELECT 和 DISTINCT阶段，</p><p>首先再SELECT 阶段会提取想要的字段，然后再DISTINCT阶段过滤掉重复的行，分别得到中间的虚拟表vt5-1和 vt 5-2。</p><p>当我们提取了想要的字段数据之后，就可以按照自定的字段进行排序，也就是ORDER BY字段，得到了虚拟表vt6。</p><p>最后在vt6的基础上，取出指定行的记录，也就是LIMIT阶段，得到最终的结果，对应的是虚拟表vt7。</p><p>当然我们在写SELECT语句时候，不一定存在所有的关键字，相应的阶段就会省略。</p><p>同时因为SQL是一门类似英语的结构化查询语言，所以我们在写SELECT语句的时候，还要注意相应的关机键字顺序，所谓底层运行的原理，就是我们刚才讲到的执行顺序。</p><h3 id="什么情况下用SELECT-，如何提升SELECT-查询效率？"><a href="#什么情况下用SELECT-，如何提升SELECT-查询效率？" class="headerlink" title="什么情况下用SELECT *，如何提升SELECT 查询效率？"></a>什么情况下用SELECT *，如何提升SELECT 查询效率？</h3><p>当初我们初学SELECT 语法的时候，经常会使用<code>SELECT *</code> ，因为使用方便。实际上这样也增加了数据库的负担。所以我们不需要把所有的列都检索出来，还是先指定出所需的列名，因为写清列名，可以减少数据表查询的网络传输量，而且考虑到在实际的工作中，我们往往不需要全部列名，因此你需要养成良好的习惯，写出所需的列名。</p><p>如果我们只是练习，或者对数据表进行探索，那么是可以使用<code>SELECT *</code>的。它的查询效率和把所有列名都写出来再进行查询的效率相差并不大。这样可以方便你对数据表有个整体的认知。但是在生产环境下，不推荐你直接使用<code>SELECT *</code>进行查询</p></li></ol><h3 id="比较运算符"><a href="#比较运算符" class="headerlink" title="比较运算符"></a>比较运算符</h3><p>在SQL中，我们可以使用WHERE 字句对条件进行筛选，在此之前，你需要了解WHERE字句中的比较运算符。这些比较运算符的含义你可以参见下面这张表格：</p><p><img src="https://i.loli.net/2020/11/28/r1kvnU5XO6daKST.png"></p><p>实际上你能看到，同样的含义可能有多种表达方式，比如小于等于，可以是（&lt;=），也可以是不大于（!&gt;）。同样不等于，可以用（&lt;&gt;），也可以用（!=），它们的含义都是相同的，但是这些符号的顺序都不能颠倒，比如你不能写（=&lt;）。需要注意的是，你需要查看使用的DBMS是否支持，不同的DBMS支持的运算符可能是不同的。</p><p>WHERE 字句的基本格式是：<code>SELECT .... (列名) FROM ... (表名) WHERE ... (字句条件)</code></p><p>比如我们想要查询所有最大生命值大于6000的英雄：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span>,hp_max <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> hp_max &gt; <span class="number">6000</span></span><br></pre></td></tr></table></figure><p>运行结果（41条记录）:</p><p><img src="https://i.loli.net/2020/11/28/jxDh1vno3pSeBmI.png"></p><p>想要查询所有最大生命值在5399到6811之间的英雄：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span>,hp_max <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> hp_max <span class="keyword">BETWEEN</span> <span class="number">5399</span> <span class="keyword">AND</span> <span class="number">6811</span></span><br></pre></td></tr></table></figure><p>运行结果（41条记录）：</p><p><img src="https://i.loli.net/2020/11/28/sEm14raHzw5SVGQ.png"></p><p><code>需要注意的是hp_max可以取到最小值和最大值，即5399 和 6811。</code></p><p>我们也可以对heros 表中的hp_max字段进行空值检查。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span>,hp_max <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> hp_max <span class="keyword">IS</span> <span class="literal">NULL</span></span><br></pre></td></tr></table></figure><p>运行结果为空，说明heros表中的hp_max字段没有存在空值的数据行。</p><h3 id="逻辑运算符"><a href="#逻辑运算符" class="headerlink" title="逻辑运算符"></a>逻辑运算符</h3><p>刚才介绍了比较运算符，如果我们存在多个WHERE 条件字句，可以使用逻辑运算符：</p><p>![](C:\Users\22520\Desktop\mysql\img\下载 (14).png)</p><p>假设想要筛选最大生命大于6000，最大法力大于1700的英雄，然后按照最大生命值和最大法力值之和从高到底进行排序。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span>,mp_max,hp_max <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> hp_max &gt; <span class="number">6000</span> <span class="keyword">AND</span> mp_max &gt; <span class="number">1700</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> (mp_max+hp_max) <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure><p>运行结果：（23条记录）</p><p><img src="https://i.loli.net/2020/11/28/TCWXh6YgbHEmLVA.png"></p><p>如果AND和OR同时存在WHERE子句中会是怎样的呢？假设我们想要查询最大生命值加最大法力值大于8000的英雄，或者最大生命值大于6000并且最大法力值大于1700的英雄。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span>,hp_max,mp_max <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> (hp_max + mp_max) &gt; <span class="number">8000</span> <span class="keyword">OR</span> hp_max &gt; <span class="number">6000</span> <span class="keyword">AND</span> mp_max &gt; <span class="number">1700</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> (hp_max + mp_max) <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure><p>运行结果：（33条记录）</p><p><img src="https://i.loli.net/2020/11/28/wAlBVMUnLzjGq5K.png"></p><p>你能看出来相比于上一个条件查询，这次的条件查询多出来了 10 个英雄，这是因为我们放宽了条件，允许最大生命值 + 最大法力值大于 8000 的英雄显示出来。另外你需要注意到，当 WHERE 子句中同时存在 OR 和 AND 的时候，AND 执行的优先级会更高，也就是说 SQL 会优先处理 AND 操作符，然后再处理 OR 操作符。</p><p>如果我们对这条查询语句OR两边的条件增加一个括号，结果会是怎样的呢？</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span>,hp_max,mp_max <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> ((hp_max + mp_max) &gt; <span class="number">8000</span> <span class="keyword">OR</span> hp_max &gt; <span class="number">6000</span>) <span class="keyword">AND</span> mp_max &gt; <span class="number">1700</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> (hp_max + mp_max) <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure><p>运行结果：</p><p><img src="https://i.loli.net/2020/11/28/HjqN4o13IkDJPXQ.png"></p><p>所以在WHERE字句中同是出现AND和OR操作符的时候，你需要考虑到执行的先后顺序，也就是两个操作符执行的优先级。一般来说（）优先级最高，其次优先级是AND，然后是OR。</p><p>如果我想要查询主要定位或次要定位是法师或是射手的英雄，同时英雄的上线时间不在2016-01-01到2017-01-01之间。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span>,role_main,role_assist,birthdate </span><br><span class="line"><span class="keyword">FROM</span> heros </span><br><span class="line"><span class="keyword">WHERE</span> (role_main <span class="keyword">IN</span> (<span class="string">&#x27;法师&#x27;</span>,<span class="string">&#x27;射手&#x27;</span>) <span class="keyword">OR</span> role_assist <span class="keyword">IN</span> (<span class="string">&#x27;法师&#x27;</span>,<span class="string">&#x27;射手&#x27;</span>)) </span><br><span class="line"><span class="keyword">AND</span> <span class="built_in">DATE</span>(birthdate) <span class="keyword">NOT</span> <span class="keyword">BETWEEN</span> <span class="string">&#x27;2016-01-01&#x27;</span> <span class="keyword">AND</span> <span class="string">&#x27;2017-01-01&#x27;</span> </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> (hp_max + mp_max) <span class="keyword">DESC</span> </span><br></pre></td></tr></table></figure><p>你能看到我把 WHERE 子句分成了两个部分。第一部分是关于主要定位和次要定位的条件过滤，使用的是<code>role_main in (&#39;法师&#39;, &#39;射手&#39;) OR role_assist in (&#39;法师&#39;, &#39;射手&#39;)</code>。这里用到了 IN 逻辑运算符，同时<code>role_main</code>和<code>role_assist</code>是 OR（或）的关系。</p><p>第二部分是关于上线时间的条件过滤。NOT 代表否，因为我们要找到不在 2016-01-01 到 2017-01-01 之间的日期，因此用到了<code>NOT BETWEEN &#39;2016-01-01&#39; AND &#39;2017-01-01&#39;</code>。同时我们是在对日期类型数据进行检索，所以使用到了 DATE 函数，将字段 birthdate 转化为日期类型再进行比较。</p><p>运行结果（6条记录）：</p><p><img src="https://i.loli.net/2020/11/28/gokmDhMv7NpldZR.png"></p><h3 id="使用通配符进行过滤"><a href="#使用通配符进行过滤" class="headerlink" title="使用通配符进行过滤"></a>使用通配符进行过滤</h3><p>刚才讲解的条件过滤都是已知值进行的过滤，还有一种情况是我们要检索文本中包含某个词的所有数据，这里就需要使用通配符。通配符就是我们用来匹配值的一部分的特殊字符。这里我们需要使用到<code>LIKE</code>操作符。</p><p>如果我们想要匹配任意字符串出现的任意次数，需要使用（%）通配符。比如我们想要查找英雄名中包含“太” 字的英雄都有哪些：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span> <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> <span class="keyword">name</span> <span class="keyword">LIKE</span> <span class="string">&#x27;% 太 %&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果：（两条记录）</p><p><img src="https://i.loli.net/2020/11/28/CBshTzjPENYndul.png"></p><p>如果我们想要匹配单个字符，就需要使用下划线（_）通配符。（%）和（ _ ）的区别在于，（%）代表一个或多个字符，而（ _ ）只代表一个字符。比如我们想要查找英雄名除了第一个字以外，包含 “太”的英雄有哪些。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">name</span> <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> <span class="keyword">name</span> <span class="keyword">LIKE</span> <span class="string">&#x27;_%太%&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果（1条记录）：</p><p><img src="https://i.loli.net/2020/11/28/6qPhDNJlzxve7oL.png"></p><p>因为太乙真人的太是第一个字符，而_%太%中的太不是在第一个字符，所以匹配不到 “太乙真人”，只能匹配上 “东皇太一”。</p><p>你能看出来通配符还是很有用的，尤其是在进行字符串匹配的时候。不过在实际操作中，我还是建议尽量少用通配符，因为他需要消耗数据库更长的时间来进行匹配。即使你对LIKE检索的字段进行了索引，索引的价值也可能会失效。如果要让索引生效，那么LIKE后面就不能以（%）开头，比如使用<code>LIKE &#39;%太%&#39;</code> 或 <code>LIKE &#39;%太&#39;</code>   的时候就会对全表进行扫描。如果使用 <code>LIkE &#39;太%</code> ,同时检索的字段进行了索引的时候，则不会进行全表扫描。</p><h3 id="什么是SQL函数"><a href="#什么是SQL函数" class="headerlink" title="什么是SQL函数"></a>什么是SQL函数</h3><p>SQL中的函数一般是在数据上执行的，可以很方便地转换和处理数据。一般来说，当我们从数据表中检索出数据之后，就可以进一步对这些数据进行操作，得到更有意义地结果，比如返回指定条件的函数，或者求摸个字段地平均值等。</p><h4 id="聚集函数都有哪些"><a href="#聚集函数都有哪些" class="headerlink" title="聚集函数都有哪些"></a>聚集函数都有哪些</h4><p>SQL中地聚集函数一共包括5中，可以帮我们求某列地最大值、最小值、和平均值等，他们分别是：</p><p><img src="https://i.loli.net/2020/11/28/oYqNJmiLP3Gjz8A.png"></p><p>这些函数你可能已经接触过，我们再来简单地复习一遍。</p><p>如果想要查询最大生命值大于6000的英雄数量。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*) <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> hp_max &gt; <span class="number">6000</span></span><br></pre></td></tr></table></figure><p>运行结果为41。</p><p>如果想要查询最大生命值大于6000，且有次要定位的英雄数量，需要使用COUNT函数。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(role_assist) <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> hp_max &gt; <span class="number">6000</span></span><br></pre></td></tr></table></figure><p>运行结果是23。</p><p>*<em>需要说明的是，有些英雄有次要定位，即role_assist为NULL，这时COUNT(role_assist) 会忽略值为NULL的数据行，而COUNT(</em>) 只是统计数据行数，不管某个字段是否为NULL。**</p><p>如果我们想要查询射手（主要定位或者次要定位是射手）的最大生命值的最大值是多少，需要使用MAX函数。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">MAX</span>(hp_max) <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> role_main = <span class="string">&#x27;射手&#x27;</span> <span class="keyword">OR</span> role_assist = <span class="string">&#x27;射手&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果为6014。</p><p>你能看到，上面的例子里，都是在一条SELECT 语句中使用了一次聚集函数，实际上我们可以在一条SELECT 语句中进行多项聚集函数的查询，比如我们想知道射手（主要定位或者次要定位是射手） 的英雄数，平均最大生命值、法力最大值的最大值、攻击最大值的最小值，以及这些英雄总的防御最大值等汇总数据。</p><p>如果想要知道英雄数量，我们使用的是COUNT（*）函数，求平均值、最大值、最小值，以及总的防御最大值，我们分别使用的是AVG、MAX和SUM函数。我外我们还需要对英雄的主要定位和次要定位进行筛选，使用的是<code>WHERE role_main = &#39;射手&#39; or role_assist = &#39;射手&#39; </code>。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*), <span class="keyword">AVG</span>(hp_max), <span class="keyword">MAX</span>(mp_max), <span class="keyword">MIN</span>(attack_max), <span class="keyword">SUM</span>(defense_max) <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> role_main = <span class="string">&#x27;射手&#x27;</span> <span class="keyword">or</span> role_assist = <span class="string">&#x27;射手&#x27;</span></span><br><span class="line"></span><br></pre></td></tr></table></figure><p>运行结果：</p><p><img src="https://i.loli.net/2020/11/28/YgdMZx5D1fKHIvP.png"></p><p>需要说明的是 AVG、MAX、MIN 等聚集函数会自动忽略值为 NULL 的数据行，MAX 和 MIN 函数也可以用于字符串类型数据的统计，如果是英文字母，则按照 A—Z 的顺序排列，越往后，数值越大。如果是汉字则按照全拼拼音进行排列。比如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">MIN</span>(<span class="keyword">CONVERT</span>(<span class="keyword">name</span> <span class="keyword">USING</span> gbk)), <span class="keyword">MAX</span>(<span class="keyword">CONVERT</span>(<span class="keyword">name</span> <span class="keyword">USING</span> gbk)) <span class="keyword">FROM</span> heros</span><br></pre></td></tr></table></figure><p>运行结果：</p><p><img src="https://i.loli.net/2020/11/28/mCFfU3oWuTnOgSa.png"></p><p>需要说明的是，我们需要先把 name 字段统一转化为 gbk 类型，使用<code>CONVERT(name USING gbk)</code>，然后再使用 MIN 和 MAX 取最小值和最大值。</p><p>我们也可以对数据行中不同的取值进行聚集，先使用DISTINCT函数取不同的数据，然后再使用聚集函数，比如我们想要查询不同的生命最大值的英雄数量是多少。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(<span class="keyword">DISTINCT</span> hp_max) <span class="keyword">FROM</span> heros</span><br></pre></td></tr></table></figure><p>运行结果为61。</p><p>假如我们想要统计不同生命最大值英雄的平均生命最大值，保留小数点后两位。首先需要取不同生命最大值，即<code>DISTINCT hp_max</code>，然后针对它们取平均值，即<code>AVG(DISTINCT hp_max)</code>，最后再针对这个值保留小数点两位，也就是<code>ROUND(AVG(DISTINCT hp_max), 2)</code>。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">ROUND</span>(<span class="keyword">AVG</span>(<span class="keyword">DISTINCT</span> hp_max), <span class="number">2</span>) <span class="keyword">FROM</span> heros</span><br></pre></td></tr></table></figure><p>运行结果为 6653.84。</p><p>你能看到，如果我们不使用 DISTINCT 函数，就是对全部数据进行聚集统计。如果使用了 DISTINCT 函数，就可以对数值不同的数据进行聚集。一般我们使用 MAX 和 MIN 函数统计数据行的时候，不需要再额外使用 DISTINCT，因为使用 DISTINCT 和全部数据行进行最大值、最小值的统计结果是相等的。</p><h3 id="如何对数据进行分组，并进行聚集统计"><a href="#如何对数据进行分组，并进行聚集统计" class="headerlink" title="如何对数据进行分组，并进行聚集统计"></a>如何对数据进行分组，并进行聚集统计</h3><p>我们在做统计的时候，可能需要先对数据按照不同的数值进行分组，然后对这些分好的组进行聚集统。对数据进行分组，需要使用GROUP BY字句。</p><p>比如我们想按照英雄的主要定位进行分组，并统计每组的英雄数量。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*),role_main <span class="keyword">FROM</span> heros <span class="keyword">GROUP</span> <span class="keyword">BY</span> role_main</span><br></pre></td></tr></table></figure><p>运行结果（6条记录）：</p><p><img src="https://i.loli.net/2020/11/28/OUi4HueyJw67CjW.png"></p><p>如果我们想要对英雄按照次要定位进行分组，并且统计每组英雄的数量。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*), role_assist <span class="keyword">FROM</span> heros <span class="keyword">GROUP</span> <span class="keyword">BY</span> role_assist</span><br></pre></td></tr></table></figure><p>运行结果：（6条记录）</p><p><img src="https://i.loli.net/2020/11/28/vSxyOg8rXjB6bQm.png"></p><p>你能看出如果字段为NULL，也会被列为一个分组。在这个查询统计中，次要定位为NULL，即只有一个主要定位的英雄是40个。</p><p>我们也可以使用多个字段进行分组，这就相当于把这些字段可能出现的所有的取值情况都进行分组。比如，我们想要按照英雄的主要定位、次要定位进行分组，查看这些英雄的数量，并按照这些分组的英雄数量从高到低进行排序。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*) <span class="keyword">as</span> <span class="keyword">num</span>, role_main, role_assist <span class="keyword">FROM</span> heros <span class="keyword">GROUP</span> <span class="keyword">BY</span> role_main, role_assist <span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="keyword">num</span> <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure><p>运行结果：（19条记录）</p><p><img src="https://i.loli.net/2020/11/28/9vjx7PnWMGJ2T3d.png"></p><h3 id="如何使用HAVING过滤分组，它与WHERE的区别是什么？"><a href="#如何使用HAVING过滤分组，它与WHERE的区别是什么？" class="headerlink" title="如何使用HAVING过滤分组，它与WHERE的区别是什么？"></a>如何使用HAVING过滤分组，它与WHERE的区别是什么？</h3><p>当我们创建出很多分组的时候，有时候就需要对分组进行过滤。你可能首先会想到WHERE字句，实际上过滤分组我们使用的是HAVING。HAVING的作用和WHERE一样，都是起到过滤的作用，只不过WHERE是用于数据行，而HAVING则作用于分组。</p><p>比如我们想要按照英雄的主要定位、次要定位进行分组，并且筛选分组中数量大于5的组，最后按照分组中的英雄数量从高到底进行排序。</p><p>首先我们需要获取的是英雄的数量、主要定位和次要定位，即<code>SELECT COUNT(*) as num, role_main, role_assist</code>。然后按照英雄的主要定位和次要定位进行分组，即<code>GROUP BY role_main, role_assist</code>，同时我们要对分组中的英雄数量进行筛选，选择大于 5 的分组，即<code>HAVING num &gt; 5</code>，然后按照英雄数量从高到低进行排序，即<code>ORDER BY num DESC</code>。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*) <span class="keyword">as</span> <span class="keyword">num</span>, role_main, role_assist <span class="keyword">FROM</span> heros <span class="keyword">GROUP</span> <span class="keyword">BY</span> role_main, role_assist <span class="keyword">HAVING</span> <span class="keyword">num</span> &gt; <span class="number">5</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="keyword">num</span> <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure><p>运行结果：（4条记录）</p><p>![](C:\Users\22520\Desktop\mysql\img\下载 (28).png)</p><p>你能看到还是上面这个分组，只不过我们按照数量进行了过滤，筛选了数量大于5的分组进行输出。如果把HAVING替换成了WHERE，SQL则会报错。对于分组的筛选，我们一定要用HAVING，而不是WHERE。另外你需要知道的是，HAVING支持所有WHERE的操作，因此所有需要WHERE字句实现的功能，你都可以使用HAVING队分组进行筛选。</p><p>我们再来看个例子，通过这个例子查看一下 WHERE 和 HAVING 进行条件过滤的区别。筛选最大生命值大于 6000 的英雄，按照主要定位、次要定位进行分组，并且显示分组中英雄数量大于 5 的分组，按照数量从高到低进行排序。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">COUNT</span>(*) <span class="keyword">as</span> <span class="keyword">num</span>, role_main, role_assist <span class="keyword">FROM</span> heros <span class="keyword">WHERE</span> hp_max &gt; <span class="number">6000</span> <span class="keyword">GROUP</span> <span class="keyword">BY</span> role_main, role_assist <span class="keyword">HAVING</span> <span class="keyword">num</span> &gt; <span class="number">5</span> <span class="keyword">ORDER</span> <span class="keyword">BY</span> <span class="keyword">num</span> <span class="keyword">DESC</span></span><br></pre></td></tr></table></figure><p>运行结果：（2条记录）</p><p><img src="https://i.loli.net/2020/11/28/CQ5p1nxGrlqc29V.png"></p><p>你能看到，还是针对上一个例子的查询，只是我们先增加了一个过滤条件，即筛选最大生命值大于 6000 的英雄。这里我们就需要先使用 WHERE 子句对最大生命值大于 6000 的英雄进行条件过滤，然后再使用 GROUP BY 进行分组，使用 HAVING 进行分组的条件判断，然后使用 ORDER BY 进行排序。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p><img src="https://i.loli.net/2020/11/28/y2IbrPASHhmg56L.png"></p><p><img src="https://i.loli.net/2020/11/28/z82sLCJQjpriEV7.png"></p><p><img src="https://i.loli.net/2020/11/28/L7AuxqQ2svpZiWK.png"></p>]]></content>
      
      
      <categories>
          
          <category> 数据库 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据库 </tag>
            
            <tag> MySQL </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL索引原理</title>
      <link href="/2020/11/23/%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8E%9F%E7%90%86/"/>
      <url>/2020/11/23/%E7%B4%A2%E5%BC%95%E7%9A%84%E5%8E%9F%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="如何评价索引的数据结构设计的好坏"><a href="#如何评价索引的数据结构设计的好坏" class="headerlink" title="如何评价索引的数据结构设计的好坏"></a>如何评价索引的数据结构设计的好坏</h3><p>数据库服务器有两种存储介质，分别为硬盘和内存。内存属于临时存储，容量有限，而且当发生意外时（比如断电或者发生故障重启）会造成数据丢失；硬盘相当于永久存储介质，这也是为什么我们需要把数据保存到硬盘上。</p><p>虽然内存的读取速度很快，当我们还是需要将索引存放到硬盘上，这样的话，当我们在硬盘上进行查询时，也就产生了硬盘的I/O操作。相比与内存的存取来说，硬盘的I/O存取消耗的时间要高很多。我们通过索引来查找某行数据的时候，需要计算产生磁盘的I/O次数，当磁盘I/O次数越多，所消耗的时间也就越大。如果我们能让索引的数据结构尽量减少硬盘的I/O操作，所消耗的时间也就越小。</p><h3 id="二叉树的局限性"><a href="#二叉树的局限性" class="headerlink" title="二叉树的局限性"></a>二叉树的局限性</h3><p>二分查找法是一种高效的数据检索方式，时间复杂度为 O(log2n)，是不是采用二叉树就合适作为索引的数据结构呢？</p><p>我们先来看下最基础的二叉搜素数（Binary Search Tree），搜索某个结点和插入结点的规则一样，我们假设搜索插入的数值为key：</p><ol><li>如果key大于根节点，则在右子树中进行查找；</li><li>如果key小于根节点，则在左子树中进行查找；</li><li>如果key等于根节点，也就是找到了这个结点，返回根节点即可。</li></ol><p>举个例子，我们对数列（34，22，89，5，23，77，91）创造出来的二分查找树如下图所示：</p><p><img src="https://i.loli.net/2020/11/26/5MqPdyHWJeXnVR2.jpg"></p><p>但是存在特殊情况，就是有时候二叉树的深度非常大。比如我们给出的数据顺序时（5，22，23，34，77，89，91），创造出来的二分搜索树如下图所示：</p><p><img src="https://i.loli.net/2020/11/26/QfrTHg1RmODc5El.jpg"></p><p>你能看出来第一个数的深度时3，也就是最多只需要三次比较，就可以找到节点，而第二个树的深度是7，最多需要7次比较才能找到节点。</p><p>第二棵树也属于二分查找树，但是性能上已经退化成了一条链表，查找数据的时间复杂度变成了O(n)。为了解决这个问题，人们提出了<strong>平衡二叉搜索树（AVL树）</strong>，它在二分搜索树的基础上增加了约束，每个节点的左子树和右子树的高度差不能超过1，也就是说节点的左子树和右子树仍然为平衡二叉树。</p><p>在这里说一下，常见的平衡二叉树有很多种，包括了平衡二叉搜索树、红黑树、数堆、伸展树。</p><p>平衡二叉树搜索树是最早提出来的自平衡二叉搜索树，当我们提到平衡二叉树时一般指的就是平衡二叉搜索树。事实上，第一颗树就属于平衡二叉搜索树，搜索的时间复杂度就是 O(log2n)。</p><p>我刚才提到过，数据查询的时间主要依赖于磁盘I/O的次数，如果我们采用二叉树的形式，即时通过平衡二叉搜索树进行了改进，树的深度也是 O(log2n)，当n比较大时，深度也是比较高的，比如下图的情况：</p><p><img src="https://i.loli.net/2020/11/26/5MVRpPsyh8fFa2G.jpg"></p><p>每访问一次就需要进行一次磁盘I/O操作，对于上面的树来说，我们需要进行5次I/O操作。虽然平衡二叉树比较的效率高，但是树的深度也同样高，这就意味着磁盘I/O次数多，会影响整体数据的查询效率。</p><p>针对同样的数据，如果我们把二叉树改成M叉数（M&gt;2）呢？当M=3时，同样的31个节点可以由下面的三叉树来进行存储：</p><p><img src="https://i.loli.net/2020/11/26/dRtacSOKhZCHTpJ.jpg"></p><p>你能看到此时树的高度降低了，当数据量 N 大的时候，以及树的分叉数 M 大的时候，M 叉树的高度会远小于二叉树的高度。</p><h3 id="什么是B树"><a href="#什么是B树" class="headerlink" title="什么是B树"></a>什么是B树</h3><p>如果用二叉树作为索引的实现结构，会让树变得很高，增加硬盘的I/O次数，影响数据查询的时间。因此一个节点就不能只有由两个子节点，而应该允许有M个子节点（M &gt; 2 ）。</p><p>B树的出现就是为了解决这个问题，B是的英文是Balance Tree，也就是平衡的多路搜索树，它的高度远小于平衡二叉搜索树的高度。在文件系统和数据库系统中的索引结构经常采用B树来实现。</p><p>B树的结构如下图所示：</p><p><img src="https://i.loli.net/2020/11/26/9UFzPKy2Tq5Cu8H.jpg"></p><p>B树作为平衡的多路搜索树，它的每个节点最多可以包括M个子节点，M称为B树的阶。同时你能看到，每个磁盘块中包括了关键字和子节点的指针。如果一个磁盘块中包含了x个关键字，那么指针数就是x+1.对于一个100阶的B树来说，如果由三层的话最多可以存储约100万的索引数据。对于大量的索引数据来说，采用B树的结构是非常合适的，因为树的高度要远小于二叉树的高度。</p><p>一个M阶的B树（M&gt;2）有以下的特征：</p><ol><li>根节点的儿子书的范围是[2,M]。</li><li>每个中间节点包含k-1个关键字和k个孩子，孩子的数量=关键字的数量+1，k的取值范围为[ceil(M/2),M]。</li><li>叶子节点包括k-1个关键字（叶子节点没有孩子），k的取值范围为[ceil(M/2),M]。</li><li>假设中间节点节点的关键字为：Key[1], Key[2], …, Key[k-1]，且关键字按照升序排序，即 Key[i]&lt;Key[i+1]。此时 k-1 个关键字相当于划分了 k 个范围，也就是对应着 k 个指针，即为：P[1], P[2], …, P[k]，其中 P[1] 指向关键字小于 Key[1] 的子树，P[i] 指向关键字属于 (Key[i-1], Key[i]) 的子树，P[k] 指向关键字大于 Key[k-1] 的子树。</li><li>所有叶子节点位于同一层。</li></ol><p>上面那张图所表示的B树就是一个3阶的B树。我们可以看到下面磁盘块2，里面的关键字为（8，12），它有3个孩子（3，5），（9，10）和（13，15），你能看到（3，5）小于8，（9，10）在8和12之间，而（13，15）大于12 ，刚好符合刚才给出的特征。</p><p>然后我们来看下如何用 B 树进行查找。假设我们想要查找的关键字是 9，那么步骤可以分为以下几步：</p><ol><li>我们与根节点的关键字 (17，35）进行比较，9 小于 17 那么得到指针 P1；</li><li>按照指针 P1 找到磁盘块 2，关键字为（8，12），因为 9 在 8 和 12 之间，所以我们得到指针 P2；</li><li>按照指针 P2 找到磁盘块 6，关键字为（9，10），然后我们找到了关键字 9。</li></ol><p>你能看出来在 B 树的搜索过程中，我们比较的次数并不少，但如果把数据读取出来然后在内存中进行比较，这个时间就是可以忽略不计的。而读取磁盘块本身需要进行 I/O 操作，消耗的时间比在内存中进行比较所需要的时间要多，是数据查找用时的重要因素，B 树相比于平衡二叉树来说磁盘 I/O 操作要少，在数据查询中比平衡二叉树效率要高。</p><h3 id="什么是B-树"><a href="#什么是B-树" class="headerlink" title="什么是B+树"></a>什么是B+树</h3><p>B+树基于B树做出了改进，主流的DBMS都支持B+树的索引方式，比如MySQL。B+树和B树的差异在于以下几点：</p><ol><li>有k个孩子的节点就有k个关键字。也就是孩子数量=关键字数，而B树种，孩子数量=关键字树+1.</li><li>非叶子节点的关键字也会同时存在在子节点中，并且是在子节点中所有关键字的最大（或最小）。</li><li>非叶子节点仅用于索引，不保存数据记录，跟记录有关的信息都放在叶子节点中。而B树中，非叶子节点及保存索引，也保存数据记录。</li><li>所有关键字都在叶子节点出现，叶节点构成一个有序的链表，而且叶子节点本身按照关键子的大小进行从小到大的顺序连接。</li></ol><p>整个过程一共进行了 3 次 I/O 操作，看起来 B+ 树和 B 树的查询过程差不多，但是 B+ 树和 B 树有个根本的差异在于，B+ 树的中间节点并不直接存储数据。这样的好处都有什么呢？</p><p>首先，B+ 树查询效率更稳定。因为 B+ 树每次只有访问到叶子节点才能找到对应的数据，而在 B 树中，非叶子节点也会存储数据，这样就会造成查询效率不稳定的情况，有时候访问到了非叶子节点就可以找到关键字，而有时需要访问到叶子节点才能找到关键字。</p><p>其次，B+ 树的查询效率更高，这是因为通常 B+ 树比 B 树更矮胖（阶数更大，深度更低），查询所需要的磁盘 I/O 也会更少。同样的磁盘页大小，B+ 树可以存储更多的节点关键字。</p><p>不仅是对单个关键字的查询上，在查询范围上，B+ 树的效率也比 B 树高。这是因为所有关键字都出现在 B+ 树的叶子节点中，并通过有序链表进行了链接。而在 B 树中则需要通过中序遍历才能完成查询范围的查找，效率要低很多。</p><h3 id="Hash索引"><a href="#Hash索引" class="headerlink" title="Hash索引"></a>Hash索引</h3><p>Hash算法是通过某种确定性的算法（比如MD5、SHA1、SHA2、SHA3）将输入转变为输出。相同的输入永远可以得到相同的输出，假设输入内容有微小偏差，在输出中通常会有不同的结果。如果你想要验证两个文件是否相同，那么你不需要把两份文件直接拿来对比，只需要让对方把Hash函数计算得到的结果告诉你即可，然后在本地同样对文件进行Hash函数的运算，最后通过比较两个Hash函数的结果是否相同，就可以知道这两个文件是否相同。</p><h3 id="动手统计Hash检索的效率"><a href="#动手统计Hash检索的效率" class="headerlink" title="动手统计Hash检索的效率"></a>动手统计Hash检索的效率</h3><p>我们知道Python的数据结构中有数组和字典两种，其中数组检索数据类似于全表扫描，需要对整个数组进行检索；而字典是由Hash实现的，存储的是key-value值，对于数据检索来说效率非常快。</p><p>对于Hash的检索效率，我们来个更直观的认知。下面我们分别看一下采用数组检索数据和采用字典（Hash）检索数据的效率到底有怎样的差别。</p><p>实验1：在数组中添加10000个元素，然后分别对这10000个元素进行检索，最后统计检索时间。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> time</span><br><span class="line">result = []</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    result.append(i)</span><br><span class="line"></span><br><span class="line">time_start = time.time()</span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">10000</span>):</span><br><span class="line">    temp = result.index(i)</span><br><span class="line">time_end = time.time();</span><br><span class="line">print(<span class="string">&#x27;检索时间&#x27;</span>,time_end-time_start)</span><br></pre></td></tr></table></figure><p>运行结果：</p><p>检索时间为 1.2436728477478027 秒</p><p>实验2：采用Hash表的形式存储数据，即在Python中采用字典方式添加10000个元素，然后检索这10000个元素，最后在统计以下时间。代码如下：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">import time </span><br><span class="line">result = &#123;&#125;</span><br><span class="line">for i in range(10000):</span><br><span class="line">result[i] = i</span><br><span class="line"></span><br><span class="line">time_start = time.time()</span><br><span class="line">for i in range(10000):</span><br><span class="line">temp = result[i]</span><br><span class="line">time_end = time.time()</span><br><span class="line">print(&#x27;检索时间&#x27;,time_end-time-<span class="keyword">start</span>)</span><br></pre></td></tr></table></figure><p>运行结果：</p><p>检索时间为 0.0019941329956054688 秒。</p><p>你能看到Hash方式检索差不多用了2毫秒的时间，检索效率提升的非常明显。这是因为Hash只需要一步就可以找到对应的取值，算法复杂度为O(1)，而数组检索所数据的算法复杂度为O(n)。</p><h3 id="MySQL中的Hash索引"><a href="#MySQL中的Hash索引" class="headerlink" title="MySQL中的Hash索引"></a>MySQL中的Hash索引</h3><p>采用Hash进行检索效率非常高，基本上一次检索就可以找到数据，而B+树需要自顶向下依次查找，多次访问节点才能找到数据，中间需要多次I/O操作，从效率来说Hash比B+树更快。</p><p>看下Hash索引的示意图：</p><p><img src="https://i.loli.net/2020/11/27/pfEhHS18syTqYQj.png"></p><p>键值key通过Hash映射找到桶bucket。这里桶（bucket）指的是一个能存储一条或多条记录的存储单位。一个桶的结构包含了一个内存指针数组，桶中的每行数据都会指向下一行，形成链表，当遇到Hash冲突时，会在桶中进行键值的查找。</p><p>那么为什么是Hash冲突呢？</p><p>如果桶的空间小于输入的空间，不同的输入可能会映射到同一个桶中，这时就会产生Hash冲突，如果Hash冲突的量很大，就会影响读取的性能。</p><p>通常Hash值的字节数比较少，简单的4个字节就够了。在Hash值相同的情况下，就会进行一步比较桶中的键值，从而找到最终的数据行，</p><p>Hash值的字节数多的话可以是16位、32位等，比如采用MD5函数就可以得到一个16位或者32位的数组，32位的MD5已经足够安全，重复率非常低。</p><h3 id="Hash索引与B-树索引的区别"><a href="#Hash索引与B-树索引的区别" class="headerlink" title="Hash索引与B+树索引的区别"></a>Hash索引与B+树索引的区别</h3><p>Hash索引结构和B+树的不同，因此在索引使用上也会有差别。</p><ol><li>Hash索引不能进行范围查询，而B+树可以。这时因为Hash索引指向的数据是无序的，而B+树的叶子节点是个有序的链表。</li><li>Hash索引不支持联合索引的最左侧原则（即联合索引的部分索引无法使用），而B+树可以。对于与联合索引来说，Hash索引在计算Hash指的时候是将索引键合并在一起计算Hash值，所以不会针对每个索引单独计算Hash值。因此如果用到联合索引的一个或者几个索引时，两个索引无法被利用。</li><li>Hash索引不支持ORDER BY查询，因此Hash索引指向的数据是无需的，因此无法起到排序优化的作用，而B+树索引数据是有序的，可以起到对该字段ORDER BY排序优化的作用。同理，我们无法使用Hash索引进行模糊查询，而B+树使用LIKE进行模糊查询的时候，LIKE后面前模糊查询的话就可以起到优化作用。</li></ol><p>对于等值查询来说，通常 Hash 索引的效率更高，不过也存在一种情况，就是索引列的重复值如果很多，效率就会降低。这是因为遇到 Hash 冲突时，需要遍历桶中的行指针来进行比较，找到查询的关键字，非常耗时。所以，Hash 索引通常不会用到重复值多的列上，比如列为性别、年龄的情况等。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>磁盘的 I/O 操作次数对索引的使用效率至关重要。虽然传统的二叉树数据结构查找数据的效率高，但很容易增加磁盘 I/O 操作的次数，影响索引使用的效率。因此在构造索引的时候，我们更倾向于采用“矮胖”的数据结构。</p><p>B 树和 B+ 树都可以作为索引的数据结构，在 MySQL 中采用的是 B+ 树，B+ 树在查询性能上更稳定，在磁盘页大小相同的情况下，树的构造更加矮胖，所需要进行的磁盘 I/O 次数更少，更适合进行关键字的范围查询。</p><p>另外 MySQL 中的 Memory 存储引擎支持 Hash 存储，如果我们需要用到查询的临时表时，就可以选择 Memory 存储引擎，把某个字段设置为 Hash 索引，比如字符串类型的字段，进行 Hash 计算之后长度可以缩短到几个字节。当字段的重复度低，而且经常需要进行等值查询的时候，采用 Hash 索引是个不错的选择。</p><p>另外 MySQL 的 InnoDB 存储引擎还有个“<strong>自适应 Hash</strong> 索引”的功能，就是当某个索引值使用非常频繁的时候，它会在 B+ 树索引的基础上再创建一个 Hash 索引，这样让 B+ 树也具备了 Hash 索引的优点。</p><p><img src="https://i.loli.net/2020/11/26/ejDuP6FTC54UwBq.png"></p><p><img src="https://i.loli.net/2020/11/27/HhOV51RdrSQMkFo.png"></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL索引原理 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数据表范式</title>
      <link href="/2020/11/23/%E6%95%B0%E6%8D%AE%E8%A1%A8%E8%8C%83%E5%BC%8F/"/>
      <url>/2020/11/23/%E6%95%B0%E6%8D%AE%E8%A1%A8%E8%8C%83%E5%BC%8F/</url>
      
        <content type="html"><![CDATA[<h3 id="数据库的设计范式都包括哪些"><a href="#数据库的设计范式都包括哪些" class="headerlink" title="数据库的设计范式都包括哪些"></a>数据库的设计范式都包括哪些</h3><p>我们在设计关系型数据库模型的时候，需要对关系内部各个属性之间联系的合理化程度进行定义，这就有了不同等级的范式要求，这些规范要求被称为<code>范式（NF）</code>。你可以把方式理解为，一张数据表的设计结构需要满足的某种设计标准的级别。</p><p>目前关系型数据库一共有6中范式，按照范式级别，从低到高分别是：1NF（第一范式）、2NF（第二范式）、3NF（第三范式）、BCNF（巴斯-科德范式）、4NF（第四范式）和 5NF（第五范式，又叫做完美范式）。</p><p>数据库的范式设计越高阶，冗余度就越低，同时高阶的范式一定符合低阶范式的要求，比如满足2NF的一定满足1NF，满足3NF的一定满足2NF，依次类推。</p><p>一般来说数据表的设计应尽量满足3NF。但也不绝对，有时候为了提高某些查询性能，我们还需要破坏范式的规则，也就是放规范化。</p><p><img src="C:\Users\22520\Desktop\mysql\img\下载(69).png"></p><h3 id="数据表中的那些键"><a href="#数据表中的那些键" class="headerlink" title="数据表中的那些键"></a>数据表中的那些键</h3><p>范式的定义会使用到逐渐和候选键（因为主键和候选键可以唯一标识元组），数据库中的键（Key）由一个或多个属性组成。我总结了下数据表中常用的几种键和属性的定义：</p><ul><li>超键：能唯一标识元组的属性集叫做超键。</li><li>候选键：如果超键不包括多余的属性，那么这个超键就是候选键。</li><li>主键：用户可以从候选键中选择一个作为主键。</li><li>外键：如果数据表R1中的某属性集不是R1的主键，而是另一个数据表R2的主键，那么这个属性集就是数据表R1的外键。</li><li>主属性：包含在任一候选键中的属性称为主属性。</li><li>非主属性：与主属性相对，指的是不包含在任何一个候选键中的属性。</li></ul><p>通常，我们也将候选键称之为 “码”，把主键也称为 “主码”。因为键可能是由多个属性组成的，针对单个属性，我们还可以用<code>主属性</code>和<code>非主属性</code>来进行区分。</p><p>看到上面的描述你可能还有点懵，我举个简单的例子。</p><p>我们之前用过NBA的球员表（palyer）和球队表（team）。这里我可以把球员定义为包含球员标号、姓名、身份证号、年龄、和球队编号；球队表包含球队编号、主教练和球队所在地。</p><p>对于球员表来说，超键就是包括球员编号或者身份证号的任意组合，比如（球员编号）（球员编号，姓名）（身份证号，年龄）等。</p><p>候选键就是最小的超键，对于球员表来说，候选键就是（球员编号）或者（身份证号）。</p><p>主键是我们自己选定，也就是从候选键中选择一个，比如（球员编号）。</p><p>外键就是球员表中的球队编号。</p><p>在player表中，主属性是（球员编号）（身份证号），其他的属性（姓名）（年龄）（球队编号）都是非主属性。</p><h3 id="从1NF到3NF"><a href="#从1NF到3NF" class="headerlink" title="从1NF到3NF"></a>从1NF到3NF</h3><p><strong>1NF指的是数据表中的任何属性都是原子性的，不可再分。</strong>这很好理解，我们在设计某个字段的时候，对于字段X来说，就不能把字段X拆分成字段X-1和字段X-2。事实上，任何的DBMS都会满足第一范式的要求，不会讲字段进行拆分。</p><p><strong>2NF指的是数据表里的非主属性都要和这个数据表的候选键有完全依赖的关系</strong>。所谓完全依赖不同于部分依赖，也就是不能仅依赖候选键的一部分属性，而必须依赖全部属性。</p><p>这里我举一个没有满足2NF的例子，比如说我们设计一张球员比赛表player_game，里面包含球员编号、姓名、年龄、比赛编号、比赛时间、和比赛场地等属性，这里候选键和主键都为（球员编号，比赛编号），我们可以通过候选键来决定如下的关系：</p><p>（球员编号，比赛编号）→ （姓名，年龄，比赛时间，比赛场地，得分）。</p><p>但是这个数据表不满足第二范式，因为数据表中的字段之间还存在着如下的对应关系：</p><p>（球员编号）→ （姓名，年龄）</p><p>（比赛编号）→ （比赛时间，比赛时间）</p><p>也就是说候选键中的某个字段决定了非主属性。你也可以理解为，对于非主属性来说，并非完全依赖候选键。这样会产生怎样的问题呢？</p><ol><li>数据冗余：如果一个球员可以参加m场比赛，那么球员的i姓名和年龄就重复了m-1次。一个比赛也可能会由n个球员参加，比赛的时间和地点就重复了n-1次。</li><li>插入异常：如果我们想要添加一场新的比赛，但是这时还没有确定参加这场球员都有谁，那么就没法插入。</li><li>删除异常：如果我们要删除某个球员的球员编号，如果没有单独保存比赛表的话，就会同时把比赛信息删除掉。</li><li>更新异常：如果我们调整了某个比赛的时间，那么数据表中的所有这个比赛的时间都需要就行调整，否则就会出现一场比赛时间不同的情况。</li></ol><p>为了避免出现上述的情况，我们可以把球员比赛表设计为下面的三张表。</p><p>球员player表包含球员编号、姓名、和年龄等属性；比赛game表包含比赛编号、比赛时间和比赛场地等属性；球员比赛关系player_game表包含球员编号、比赛编号和得分等属性。</p><p>这样的话，每张数据表都符合第二范式，也就避免了异常情况的发生</p><p>。某种程度上2NF是对1NF原子性的升级。1NF告诉我们字段属性需要时原子性的，而2NF告诉我们一张表就是一个独立的对象，也就是说一张表只表达一个意思。</p><p><strong>3NF在满足2NF的同时，对任何非主属性都不传递依赖于候选键</strong>。也就是说不存在非主属性A依赖于非主属性B，非主属性B依赖于候选键的情况。</p><p>我们用球员plyer表举例子，这张表包含的属性包括球员编号、姓名、球队名称、和球队主教练。现在，我们把属性之间的依赖关系画出来，如下图所示：</p><p><img src="C:\Users\22520\Desktop\mysql\img\下载(70).png"></p><p>你能看到球员编号决定了球队名称，同时球队名称决定了球队主教练，非主属性球队主教练就会传递依赖于球员编号，因此不符合3NF的要求</p><p>如果要达到3NF的要求，需要把数据表拆成下面这样：</p><p>球员表的属性包括球员编号、姓名和球队名称；球队表的属性包括球队名称、球队主教练。</p><p>我在总结一下，1NF需要保证表中每个属性都保持原子性；2NF需要保证表中的非主属性与候选键完全依赖；3NF是需要保证非主属性与候选键不存在传递依赖。</p><h3 id="BCNF（巴斯范式）"><a href="#BCNF（巴斯范式）" class="headerlink" title="BCNF（巴斯范式）"></a>BCNF（巴斯范式）</h3><p>如果数据表的关系模式符合3NF的要求，就不存在问题了吗？我们来看下这张仓库管理关系warehouse_keeper表：</p><p>![](C:\Users\22520\Desktop\mysql\img\下载 (72).png)</p><p>在这个数据表中，一个仓库只有一个管理员，同时一个管理员以遏制管理一个仓库。我们先来梳理下这些属性之间的依赖关系。</p><p>仓库名决定了管理员，管理员也决定了仓库名，同时（仓库名，物品名）的属性几个可以决定数量这个属性。</p><p>这样，我们就可以找到数据表的候选键时（管理员，物品名）和（仓库名，物品名），然后我们从候选键中选择一个作为主键，比如（仓库名，物品名）。</p><p>在这里，主属性是包含在任一候选键中的属性，也就是仓库名，管理员，和物品名。非主属性时数量这个属性。</p><p>如何判断一张表的范式呢？我们需要根据范式的等级，从低到高进行判断。</p><p>首先，数据表每个属性都是原子性的，符合1NF的要求；其次，数据表中非主属性 “数量” 都与候选键全部依赖，（仓库名，物品名）决定数量，（官员，物品名）决定数量，因此，数据表符合2NF的要求；最后，数据表的非主属性，不传递依赖于候选键。因此符合3NF的要求。</p><p>你能看到，即便数据表符合3NF的要求，同样可能存在插入、更新和删除数据的异常。</p><p>这种情况下该怎么解决呢？</p><p>首先我们需要确认造成异常的原因：主属性仓库名对于候选键（管理员，物品名）是部分依赖的关系，这样就有可能导致上面的异常情况。人们在3NF的基础上进行了改进，提出了 <strong>BCNF，也叫做巴斯-科德范式，他在3NF的基础上消除了主属性对候选键的部分依赖或者传递依赖关系。</strong></p><p>根据BCNF的要求，我们需要把仓库管理关系warehouse_keeper表拆分成下面这样：</p><p>仓库名：（仓库名，管理员）</p><p>仓库表：（仓库名，物品名，数量）</p><p>这样就不存在主属性对于候选键的部分依赖或传递依赖，上面数据表的设计就符合 BCNF。</p><h3 id="反范式设计"><a href="#反范式设计" class="headerlink" title="反范式设计"></a>反范式设计</h3><p>尽管围绕着数据表的设计有很多范式，但事实上，我们在设计数据表的时候却不一定要参照这写标准。</p><p>我们在之前已经了解了越高阶的范式得到的数据表越多，数据冗余度越低。但有时候，我们在设计数据表的时候，还需要为了性能和读取效率违反范式化的原则。反范式就是相对范式化而言的，换句话说，就是允许少量的冗余，通过空间换时间。</p><p>如果我们想要对查询效率进行优化，有时候反范式优化也是一种优化思路。</p><p>比如我们想要查询某个商品的前1000条评论，会涉及到两张表。</p><p>商品评论表product_comment，对应的字段名称及含义如下：</p><p>![](C:\Users\22520\Desktop\mysql\img\下载 (73).png)</p><p>用户表user，对应的字段名称及含义如下;</p><p>![](C:\Users\22520\Desktop\mysql\img\下载 (74).png)</p><p>下面，就用这两张表模拟一下反范式优化。</p><h3 id="实验数据：模拟两张百万量级的数据表"><a href="#实验数据：模拟两张百万量级的数据表" class="headerlink" title="实验数据：模拟两张百万量级的数据表"></a>实验数据：模拟两张百万量级的数据表</h3><p>为了更好地进行 SQL 优化实验，我们需要给用户表和商品评论表随机模拟出百万量级的数据。我们可以通过存储过程来实现模拟数据。</p><p>下面是给用户表随机生成 100 万用户的代码：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DEFINER=<span class="string">`root`</span>@<span class="string">`localhost`</span> <span class="keyword">PROCEDURE</span> <span class="string">`insert_many_user`</span>(<span class="keyword">IN</span> <span class="keyword">start</span> <span class="built_in">INT</span>(<span class="number">10</span>), <span class="keyword">IN</span> max_num <span class="built_in">INT</span>(<span class="number">10</span>))</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line"><span class="keyword">DECLARE</span> i <span class="built_in">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">DECLARE</span> date_start DATETIME <span class="keyword">DEFAULT</span> (<span class="string">&#x27;2017-01-01 00:00:00&#x27;</span>);</span><br><span class="line"><span class="keyword">DECLARE</span> date_temp DATETIME;</span><br><span class="line"><span class="keyword">SET</span> date_temp = date_start;</span><br><span class="line"><span class="keyword">SET</span> autocommit=<span class="number">0</span>;</span><br><span class="line">REPEAT</span><br><span class="line"><span class="keyword">SET</span> i=i+<span class="number">1</span>;</span><br><span class="line"><span class="keyword">SET</span> date_temp = <span class="keyword">date_add</span>(date_temp, <span class="built_in">interval</span> <span class="keyword">RAND</span>()*<span class="number">60</span> <span class="keyword">second</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> <span class="keyword">user</span>(user_id, user_name, create_time)</span><br><span class="line"><span class="keyword">VALUES</span>((<span class="keyword">start</span>+i), <span class="keyword">CONCAT</span>(<span class="string">&#x27;user_&#x27;</span>,i), date_temp);</span><br><span class="line">UNTIL i = max_num</span><br><span class="line"><span class="keyword">END</span> <span class="keyword">REPEAT</span>;</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br><span class="line"><span class="keyword">END</span></span><br></pre></td></tr></table></figure><p>我用 date_start 变量来定义初始的注册时间，时间为 2017 年 1 月 1 日 0 点 0 分 0 秒，然后用 date_temp 变量计算每个用户的注册时间，新的注册用户与上一个用户注册的时间间隔为 60 秒内的随机值。然后使用 REPEAT … UNTIL … END REPEAT 循环，对 max_num 个用户的数据进行计算。在循环前，我们将 autocommit 设置为 0，这样等计算完成再统一插入，执行效率更高。</p><p>然后我们来运行 call insert_many_user(10000, 1000000); 调用存储过程。这里需要通过 start 和 max_num 两个参数对初始的 user_id 和要创建的用户数量进行设置。运行结果：</p><p>![](C:\Users\22520\Desktop\mysql\img\下载 (75).png)</p><p>你能看到在 MySQL 里，创建 100 万的用户数据用时 1 分 37 秒。</p><p>接着我们再来给商品评论表 product_comment 随机生成 100 万条商品评论。这里我们设置为给某一款商品评论，比如 product_id=10001。评论的内容为随机的 20 个字母。以下是创建随机的 100 万条商品评论的存储过程：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">CREATE</span> DEFINER=<span class="string">`root`</span>@<span class="string">`localhost`</span> <span class="keyword">PROCEDURE</span> <span class="string">`insert_many_product_comments`</span>(<span class="keyword">IN</span> <span class="keyword">START</span> <span class="built_in">INT</span>(<span class="number">10</span>), <span class="keyword">IN</span> max_num <span class="built_in">INT</span>(<span class="number">10</span>))</span><br><span class="line"><span class="keyword">BEGIN</span></span><br><span class="line"><span class="keyword">DECLARE</span> i <span class="built_in">INT</span> <span class="keyword">DEFAULT</span> <span class="number">0</span>;</span><br><span class="line"><span class="keyword">DECLARE</span> date_start DATETIME <span class="keyword">DEFAULT</span> (<span class="string">&#x27;2018-01-01 00:00:00&#x27;</span>);</span><br><span class="line"><span class="keyword">DECLARE</span> date_temp DATETIME;</span><br><span class="line"><span class="keyword">DECLARE</span> comment_text <span class="built_in">VARCHAR</span>(<span class="number">25</span>);</span><br><span class="line"><span class="keyword">DECLARE</span> user_id <span class="built_in">INT</span>;</span><br><span class="line"><span class="keyword">SET</span> date_temp = date_start;</span><br><span class="line"><span class="keyword">SET</span> autocommit=<span class="number">0</span>;</span><br><span class="line">REPEAT</span><br><span class="line"><span class="keyword">SET</span> i=i+<span class="number">1</span>;</span><br><span class="line"><span class="keyword">SET</span> date_temp = <span class="keyword">date_add</span>(date_temp, <span class="built_in">INTERVAL</span> <span class="keyword">RAND</span>()*<span class="number">60</span> <span class="keyword">SECOND</span>);</span><br><span class="line"><span class="keyword">SET</span> comment_text = <span class="keyword">substr</span>(<span class="keyword">MD5</span>(<span class="keyword">RAND</span>()),<span class="number">1</span>, <span class="number">20</span>);</span><br><span class="line"><span class="keyword">SET</span> user_id = <span class="keyword">FLOOR</span>(<span class="keyword">RAND</span>()*<span class="number">1000000</span>);</span><br><span class="line"><span class="keyword">INSERT</span> <span class="keyword">INTO</span> product_comment(comment_id, product_id, comment_text, comment_time, user_id)</span><br><span class="line"><span class="keyword">VALUES</span>((<span class="keyword">START</span>+i), <span class="number">10001</span>, comment_text, date_temp, user_id);</span><br><span class="line">UNTIL i = max_num</span><br><span class="line"><span class="keyword">END</span> <span class="keyword">REPEAT</span>;</span><br><span class="line"><span class="keyword">COMMIT</span>;</span><br><span class="line"><span class="keyword">END</span></span><br></pre></td></tr></table></figure><p>同样的，我用 date_start 变量来定义初始的评论时间。这里新的评论时间与上一个评论的时间间隔还是 60 秒内的随机值，商品评论表中的 user_id 为随机值。我们使用 REPEAT … UNTIL … END REPEAT 循环，来对 max_num 个商品评论的数据进行计算。</p><p>然后调用存储过程，运行结果如下：</p><p>![](C:\Users\22520\Desktop\mysql\img\下载 (76).png)</p><p>MySQL 一共花了 2 分 7 秒完成了商品评论数据的创建。</p><h3 id="反范式优化实验对比"><a href="#反范式优化实验对比" class="headerlink" title="反范式优化实验对比"></a>反范式优化实验对比</h3><p>如果我们想要查询某个商品 ID，比如 10001 的前 1000 条评论，需要写成下面这样：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> p.comment_text, p.comment_time, u.user_name <span class="keyword">FROM</span> product_comment <span class="keyword">AS</span> p </span><br><span class="line"><span class="keyword">LEFT</span> <span class="keyword">JOIN</span> <span class="keyword">user</span> <span class="keyword">AS</span> u </span><br><span class="line"><span class="keyword">ON</span> p.user_id = u.user_id </span><br><span class="line"><span class="keyword">WHERE</span> p.product_id = <span class="number">10001</span> </span><br><span class="line"><span class="keyword">ORDER</span> <span class="keyword">BY</span> p.comment_id <span class="keyword">DESC</span> <span class="keyword">LIMIT</span> <span class="number">1000</span></span><br></pre></td></tr></table></figure><p>运行结果（1000 条数据行）：</p><p>![](C:\Users\22520\Desktop\mysql\img\下载 (77).png)</p><p>运行时长为 0.395 秒，查询效率并不高。</p><p>这是因为在实际生活中，我们在显示商品评论的时候，通常会显示这个用户的昵称，而不是用户 ID，因此我们还需要关联 product_comment 和 user 这两张表来进行查询。当表数据量不大的时候，查询效率还好，但如果表数据量都超过了百万量级，查询效率就会变低。这是因为查询会在 product_comment 表和 user 表这两个表上进行聚集索引扫描，然后再嵌套循环，这样一来查询所耗费的时间就有几百毫秒甚至更多。对于网站的响应来说，这已经很慢了，用户体验会非常差。</p><p>如果我们想要提升查询的效率，可以允许适当的数据冗余，也就是在商品评论表中增加用户昵称字段，在 product_comment 数据表的基础上增加 user_name 字段，就得到了 product_comment2 数据表。</p><p>这样一来，只需单表查询就可以得到数据集结果：</p><p>![](C:\Users\22520\Desktop\mysql\img\下载 (78).png)</p><p>优化之后只需要扫描一次聚集索引即可，运行时间为 0.039 秒，查询时间是之前的 1/10。 你能看到，在数据量大的情况下，查询效率会有显著的提升。</p><h3 id="反范式存在的问题-amp-使用场景"><a href="#反范式存在的问题-amp-使用场景" class="headerlink" title="反范式存在的问题 &amp; 使用场景"></a>反范式存在的问题 &amp; 使用场景</h3><p>从上面的例子中可以看出，反范式可以通过空间换时间，提升查询的效率，但是反范式也会带来一些新的问题。</p><p>在数据量小的情况下，反范式不能体现性能的又是，可能还会让数据库设计更加复杂。比如采用存储过程来支持数据的更新，删除等额外操作，很容易增加系统的维护成本。</p><p>比如用户每次更新昵称的时候，都需要执行存储过程来更新，如果昵称更新频繁，会非常消耗系统资源。</p><p>那么反范式优化适用于哪些场景呢？</p><p>在现实生活中，我们经常需要一些冗余信息，比如订单中的收货人信息，包括姓名、电话和地址等。每次发生的订单收货信息都是于历史快照，需要进行保存，但用户可以随时修改自己的信息，这时保存这些冗余信息都是非常有必要的。</p><p>让冗余信息有交织或者能大幅提高查询效率的时候，我们就可以采取反范式的优化。</p><p>此外反范式优化也常用在数据仓库的设计中，因为数据仓库通常存储历史数据，对增删改的实时性不强，对历史数据的分析需求强。这时适当允许数据的冗余度，更方便进行数据分析。</p><p>我简单总结下数据仓库和数据库在使用上的区别：</p><ol><li>数据库设计的目的在于捕获数据，而数据仓库设计的目的在于分析数据；</li><li>数据库对数据的增删改实时性要求强，需要存储在线的用户数据，而数据仓库存储的一般是历史数据；</li><li>数据库设计需要尽量避免冗余，但为了提高查询效率也允许一定的冗余度，而数据仓库在设计上更偏向采用反范式设计。</li></ol><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>这些范式只是提出了设计的标准，实际上设计数据表时，未必要符合这些原则。一方面是因为这些范式本身存在一些问题，可能会带来插入，更新，删除等的异常情况（这些会在下一讲举例说明），另一方面，它们也可能降低会查询的效率。这是为什么呢？因为范式等级越高，设计出来的数据表就越多，进行数据查询的时候就可能需要关联多张表，从而影响查询效率。</p><p>你能看到设计范式越高阶，数据表就会越精细，数据的冗余度也就越少，在一定程度上可以让数据库在内部关联上更好地组织数据。但有时候我们也需要采用反范进行优化，通过空间来换取时间。</p><p>范式本身没有优劣之分，只有适用场景不同。没有完美的设计，只有合适的设计，我们在数据表的设计中，还需要根据需求将范式和反范式混合使用。</p><p><img src="">![下载 (71)](C:\Users\22520\Desktop\mysql\img\下载 (71).png)</p><p>![](C:\Users\22520\Desktop\mysql\img\下载 (79).png)</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 数据表范式 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>MySQL索引使用原则</title>
      <link href="/2020/11/23/%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%88%99/"/>
      <url>/2020/11/23/%E7%B4%A2%E5%BC%95%E7%9A%84%E4%BD%BF%E7%94%A8%E5%8E%9F%E5%88%99/</url>
      
        <content type="html"><![CDATA[<h3 id="创建索引有哪些规律？"><a href="#创建索引有哪些规律？" class="headerlink" title="创建索引有哪些规律？"></a>创建索引有哪些规律？</h3><p>创建索引有一定规律。但这些规律出现的时候，我们就可以通过创建索引提升查询效率，下面来看看什么情况下可以创建索引：</p><h4 id="1-字段的数值有唯一性的限制，比如用户名"><a href="#1-字段的数值有唯一性的限制，比如用户名" class="headerlink" title="1.字段的数值有唯一性的限制，比如用户名"></a>1.字段的数值有唯一性的限制，比如用户名</h4><p>索引本身可以起到约束的作用，比如唯一索引、主键索引、都是可以起到唯一性约束的，因此在我们的数据表中，如果某个字段是唯一性的，就可以直接创建唯一性索引，或者主键索引。</p><h4 id="2-频繁作为WHERE查询条件的字段，尤其在数据表大的情况下"><a href="#2-频繁作为WHERE查询条件的字段，尤其在数据表大的情况下" class="headerlink" title="2.频繁作为WHERE查询条件的字段，尤其在数据表大的情况下"></a>2.频繁作为WHERE查询条件的字段，尤其在数据表大的情况下</h4><p>在数据量大的情况下，某个字段在SQL查询的WHERE条件中经常被使用到，那么就需要给这个字段创建索引了。创建普通索引就可以大幅提升数据查询的效率。</p><p>我之前列举了 product_comment 数据表，这张数据表中一共有 100 万条数据，假设我们想要查询 user_id=785110 的用户对商品的评论。</p><p>如果我们没有对 user_id 字段创建索引，进行如下查询：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> comment_id, product_id, comment_text, comment_time, user_id <span class="keyword">FROM</span> product_comment <span class="keyword">WHERE</span> user_id = <span class="number">785110</span></span><br></pre></td></tr></table></figure><p>运行结果：</p><p><img src="https://i.loli.net/2020/11/27/rVsNxil3BM9CS1y.png"></p><p>运行时间为0.699s，你能看到查询效率还是比较低的。当我们对user_id字段创建索引之后，运行时间为0.047s ,不到原来的1/10，效率提升还是明显的。</p><h4 id="3-需要经常GROUP-BY-和-ORDER-BY的列"><a href="#3-需要经常GROUP-BY-和-ORDER-BY的列" class="headerlink" title="3.需要经常GROUP BY 和 ORDER BY的列"></a>3.需要经常GROUP BY 和 ORDER BY的列</h4><p>索引就是让数据按照某种顺序进行存储或检索，因此，当我们使用GROUP BY对数据进行分组查询，或者ORDER BY对数据进行排序的时候，就需要对分组或者排序的字段进行索引。</p><p>比如我们按照user_id对商品评论数据进行分组，显示不同的user_id和商品评论的数量，显示100个即可。</p><p>如果我们不对user_id创建索引，执行下面的SQL语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> user_id,<span class="keyword">count</span>(*) <span class="keyword">as</span> <span class="keyword">num</span> <span class="keyword">FROM</span> product_comment <span class="keyword">group</span> <span class="keyword">by</span> user_id <span class="keyword">limit</span> <span class="number">100</span></span><br></pre></td></tr></table></figure><p>运行结果（100条记录，运行时间1.666s）：</p><p><img src="https://i.loli.net/2020/11/27/XKoFPyRZmdLnqkW.png"></p><p>如果我们对user_id创建索引，在执行SQL语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> user_id,<span class="keyword">count</span>(*) <span class="keyword">as</span> <span class="keyword">num</span> <span class="keyword">FROM</span> product_comment <span class="keyword">group</span> <span class="keyword">by</span> user_id <span class="keyword">limit</span> <span class="number">100</span></span><br></pre></td></tr></table></figure><p><img src="https://i.loli.net/2020/11/27/tlFDfE8AV9Sc1JZ.png"></p><p>你能看到当对user_id创建索引后，得到的结果中user_id字段的数值也是按照顺序展示的，运行时间却不到原来时间的1/40，效率提升很明显。</p><p>同样，如果是ORDER BY，也需要对字段创建索引。我们再来看下同时有GROUP BY 和 ORDER BY 的情况。比如我们按照user_id进行评论分组，同时按照评论时间降序的方式进行排序，这时我们就需要同时进行GROUP BY 和 ORDER BY，那么是不是需要单独创建user_id的索引和comment_time的索引呢？</p><p>当我们对user_id和comment_time分别创建索引，执行下面的SQL查询：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> user_id, <span class="keyword">count</span>(*) <span class="keyword">as</span> <span class="keyword">num</span> <span class="keyword">FROM</span> product_comment <span class="keyword">group</span> <span class="keyword">by</span> user_id <span class="keyword">order</span> <span class="keyword">by</span> comment_time <span class="keyword">desc</span> <span class="keyword">limit</span> <span class="number">100</span></span><br></pre></td></tr></table></figure><p>运行结果（运行时间 &gt; 100 s）:</p><p><img src="https://i.loli.net/2020/11/27/hepDfild4tPL9O6.png"></p><p>实际上多个单列索引在多条件查询时只会生效一个索引（MySQL会选择其中一个限制最严格的作为索引），所以在多条件联合索引的时候最好创建联合索引。在这个例子中，我们创建联合索引(user_id,comment_time)，再来看下查询的时间，查询的时间为0.775s，效率提升了很多。如果我么你创建联合索引的顺序为（comment_time,user_id）呢？运行时间为1.990s,同样比两个单列索引要快，但是会比顺序为(user_id,comment_time)的所以要慢一些。这时因为在进行SELECT 查询的时候，先进行GROUP BY，在对数据进行ORDER BY的操作，索引按照这个联合索引的顺序效率是最高的。</p><p><img src="https://i.loli.net/2020/11/27/4xC2qrUFoufTwQm.png"></p><h4 id="4-UPDEATE、DELETE-的WHERE-条件列，一般也需要创建索引"><a href="#4-UPDEATE、DELETE-的WHERE-条件列，一般也需要创建索引" class="headerlink" title="4.UPDEATE、DELETE 的WHERE 条件列，一般也需要创建索引"></a>4.UPDEATE、DELETE 的WHERE 条件列，一般也需要创建索引</h4><p>我们刚在说的是数据检索的情况。那么当我们对某条数据进行UPDATE 或者 DELETE操作的时候，是否也需要对WHERE的条件列创建索引呢？</p><p>先看下对数据进行UPDATE的情况。</p><p>如果我们想要把comment_text为462eed7ac6e791292a79对应的product_id修改为10002，当我们没有对comment_text进行索引的时候，执行SQL语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> product_comment <span class="keyword">SET</span> product_id = <span class="number">10002</span> <span class="keyword">WHERE</span> comment_text = <span class="string">&#x27;462eed7ac6e791292a79&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果为Affected rows: 1，运行时间为1.173s。</p><p>你能看到效率不高，但如果我们对comment_text字段创建了索引，然后把刚才那条记录更新回product_id=10001，执行SQL语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">UPDATE</span> product_comment <span class="keyword">SET</span> product_id = <span class="number">10001</span> <span class="keyword">WHERE</span> comment_text = <span class="string">&#x27;462eed7ac6e791292a79&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果为Affected rows: 1，运行时间为0.1110s。你能看到这个运行时间是之前的1/10，效率有了大幅的提升。</p><p>如果我们对某条数据进行了DELETE，效率如何呢？</p><p>比如我们先删除comment_text为462eed7ac6e791292a79 的数据。当我们没有对comment_text字段进行索引的时候，执行SQL语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">DELETE</span> <span class="keyword">FROM</span> product_comment <span class="keyword">WHERE</span> comment_text = <span class="string">&#x27;462eed7ac6e791292a79&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果为Affected rows：1，运行时间为1.027s，效率不高。</p><p>如果我们对comment_text创建了索引，再来执行这条SQL语句，运行时间为0.032s，时间是原来的1/32，效率有了大幅的提升。</p><p>你能看到，对数据按照某个条件进行查询后在进行UPDATE 或 DELETE 的的操作，如果对WHERE 字段创建了索引，就能大幅提升效率。原理是因为我们需要先根据WHERE条件列检索出来这条记录，然后再对它进行更新或删除。如果进行更新的时候，更新的字段是非索引字段，提升的效率会更明显，这是因为非索引字段更新不需要对索引进行维护。</p><p>不过在实际工作中，我们需要注意平衡，如果索引太多了，在更新数据的时候，如果涉及到索引更新，就会造成负担。</p><h4 id="5-DISTINCT字段需要创建索引"><a href="#5-DISTINCT字段需要创建索引" class="headerlink" title="5.DISTINCT字段需要创建索引"></a>5.DISTINCT字段需要创建索引</h4><p>有时候我们需要对某个字段进行去重，使用DISTINCT，那么对这个字段创建索引，也会提升查询效率。</p><p>比如我们想要查询商品评论表中不同的user_id都有哪些，如果我们没有对user_id创建索引，执行SQL语句，看看情况是怎么样的。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span>(user_id) <span class="keyword">FROM</span> <span class="string">&#x27;product_comment&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果（600637条记录，运行时间2.283s）：</p><p><img src="https://i.loli.net/2020/11/27/UD5KqbwtJPyjxE8.png"></p><p>如果我们对user_id创建索引，在执行SQL语句，看看情况又是怎样的。</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> <span class="keyword">DISTINCT</span>(user_id) <span class="keyword">FROM</span> <span class="string">&#x27;product_comment&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果（600637条记录，运行时间0.627s）：</p><p><img src="https://i.loli.net/2020/11/27/BaMn7cgsFr9o1eO.png"></p><p>你能看到SQL查询效率有了提升，同时显示出来的user_id还是按照递增的顺序进行展示的。这是因为索引会对数据按照某种顺序进行排列，索引在去重的时候也会快很多。</p><h4 id="6-做多表JOIN连接操作时，创建索引需要注意以下的原则"><a href="#6-做多表JOIN连接操作时，创建索引需要注意以下的原则" class="headerlink" title="6.做多表JOIN连接操作时，创建索引需要注意以下的原则"></a>6.做多表JOIN连接操作时，创建索引需要注意以下的原则</h4><p>首先，连接表的数量尽量不要超过3张，因为每增加一张表就相当于增加了一次嵌套的循环，数量级增长会非常快，严重影响查询的效率。</p><p>其次，对WHERE条件创建索引，因为WHERE才是对数据条件的过滤。如果在数据量非常大的情况下，没有WHERE条件过滤时非常可怕的。</p><p>最后，对用于连接的字段创建索引，并且该字段在多张表中的类型必须一致。比如user_id在prodect_comment表和user表中都为int(11)类型，而不能一个为int另一个为varchar类型。</p><p>举个例子，如果我们只对user_id创建索引，执行SQL语句：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> comment_id, comment_text, product_comment.user_id, user_name <span class="keyword">FROM</span> product_comment <span class="keyword">JOIN</span> <span class="keyword">user</span> <span class="keyword">ON</span> product_comment.user_id = user.user_id</span><br><span class="line"><span class="keyword">WHERE</span> comment_text = <span class="string">&#x27;462eed7ac6e791292a79&#x27;</span> </span><br></pre></td></tr></table></figure><p>运行结果（1条数据，运行时间0.810s）：</p><p><img src="https://i.loli.net/2020/11/27/QamUBtf2qTlZwx3.png"></p><p>这里我们对comment_text创建索引，在执行上面的SQL语句，运行时间为0.046s。</p><p>如果我们不使用WHERE 条件查询，而是直接采用JOIN..ON..进行连接的话，即使使用了各种优化手段，总的运行时间也会很长（&gt;100s）。</p><h3 id="什么情况下索引失效"><a href="#什么情况下索引失效" class="headerlink" title="什么情况下索引失效"></a>什么情况下索引失效</h3><p>创建了索引，还要避免索引失效，你可以先思考下都有哪些情况会造成索引失效？下面是一些常见的索引失效的例子：</p><h4 id="1-如果索引进行了表达式计算，则会失效"><a href="#1-如果索引进行了表达式计算，则会失效" class="headerlink" title="1.如果索引进行了表达式计算，则会失效"></a>1.如果索引进行了表达式计算，则会失效</h4><p>我们可以使用EXPLAIN 关键字来查看MySQL中一条SQL语句的执行计划，比如：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> comment_id,user_id,comment_text <span class="keyword">FROM</span> product_comment <span class="keyword">WHERE</span> comment_id+<span class="number">1</span> = <span class="number">900001</span></span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">+----+-------------+-----------------+------------+------+---------------+------+---------+------+--------+----------+-------------+</span><br><span class="line">| id | select_type | table           | partitions | type | possible_keys | key  | key_len | ref  | rows   | filtered | Extra       |</span><br><span class="line">+----+-------------+-----------------+------------+------+---------------+------+---------+------+--------+----------+-------------+</span><br><span class="line">|  1 | SIMPLE      | product_comment | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 996663 |   100.00 | Using where |</span><br><span class="line">+----+-------------+-----------------+------------+------+---------------+------+---------+------+--------+----------+-------------+</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>你能看到如果对索引进行了表达式计算，索引就失效了。这是因为我们需要把索引字段的取值都取出来，然后一次进行表达式的计算来进行判断，因此采用的就是全表扫描的方式，运行时间也会慢很多，最终运行时间为2.538秒。</p><p>为了避免索引失效，我们对SQL进行重写：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">SELECT</span> comment_id,user_id,comment_text <span class="keyword">FROM</span> product_comment <span class="keyword">WHERE</span> comment_id = <span class="number">900000</span></span><br></pre></td></tr></table></figure><p>运行时间为0.039秒。</p><h4 id="2-如果索引使用函数，也会造成失效"><a href="#2-如果索引使用函数，也会造成失效" class="headerlink" title="2.如果索引使用函数，也会造成失效"></a>2.如果索引使用函数，也会造成失效</h4><p>比如我们想要对comment_text的前三abc的内容进行条件筛选，这里我么你来看下执行计划：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> comment_id, user_id, comment_text <span class="keyword">FROM</span> product_comment <span class="keyword">WHERE</span> <span class="keyword">SUBSTRING</span>(comment_text, <span class="number">1</span>,<span class="number">3</span>)=<span class="string">&#x27;abc&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight text"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+----+-------------+-----------------+------------+------+---------------+------+---------+------+--------+----------+-------------+</span><br><span class="line">| id | select_type | table           | partitions | type | possible_keys | key  | key_len | ref  | rows   | filtered | Extra       |</span><br><span class="line">+----+-------------+-----------------+------------+------+---------------+------+---------+------+--------+----------+-------------+</span><br><span class="line">|  1 | SIMPLE      | product_comment | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 996663 |   100.00 | Using where |</span><br><span class="line">+----+-------------+-----------------+------------+------+---------------+------+---------+------+--------+----------+-------------+</span><br></pre></td></tr></table></figure><p>你能看到对索引字段进行函数操作，造成了索引失效，这时可以进行查询重写：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">SELECT comment_id, user_id, comment_text FROM product_comment WHERE comment_text LIKE &#39;abc%&#39;</span><br></pre></td></tr></table></figure><p>使用 EXPLAIN 对查询语句进行分析：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+----+-------------+-----------------+------------+-------+---------------+--------------+---------+------+------+----------+-----------------------+</span><br><span class="line">| id | select_type | table           | partitions | type  | possible_keys | key          | key_len | ref  | rows | filtered | Extra                 |</span><br><span class="line">+----+-------------+-----------------+------------+-------+---------------+--------------+---------+------+------+----------+-----------------------+</span><br><span class="line">|  1 | SIMPLE      | product_comment | NULL       | range | comment_text  | comment_text | 767     | NULL |  213 |   100.00 | Using index condition |</span><br><span class="line">+----+-------------+-----------------+------------+-------+---------------+--------------+---------+------+------+----------+-----------------------+</span><br></pre></td></tr></table></figure><p>你能看到经过查询重写后，可以使用索引进行范围检索，从而提升查询效率。</p><h4 id="3-在WHERE子句中，如果在OR前的条件列进行了索引，而在OR后的条件列没有进行索引，那么索引会失效。"><a href="#3-在WHERE子句中，如果在OR前的条件列进行了索引，而在OR后的条件列没有进行索引，那么索引会失效。" class="headerlink" title="3.在WHERE子句中，如果在OR前的条件列进行了索引，而在OR后的条件列没有进行索引，那么索引会失效。"></a>3.在WHERE子句中，如果在OR前的条件列进行了索引，而在OR后的条件列没有进行索引，那么索引会失效。</h4><p>比如下面的SQL语句，comment_id是主键，而comment_text没有进行索引，因为OR的含义就是两个只要满足一个即可，因此只有在一个列进行索引是没有意义的，只要有条件列没有进行索引，就会进行全表扫描，因此索引的条件列也会失效：</p><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> comment_id, user_id, comment_text <span class="keyword">FROM</span> product_comment <span class="keyword">WHERE</span> comment_id = <span class="number">900001</span> <span class="keyword">OR</span> comment_text = <span class="string">&#x27;462eed7ac6e791292a79&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+----+-------------+-----------------+------------+------+---------------+------+---------+------+--------+----------+-------------+</span><br><span class="line">| id | select_type | table           | partitions | type | possible_keys | key  | key_len | ref  | rows   | filtered | Extra       |</span><br><span class="line">+----+-------------+-----------------+------------+------+---------------+------+---------+------+--------+----------+-------------+</span><br><span class="line">|  1 | SIMPLE      | product_comment | NULL       | ALL  | PRIMARY       | NULL | NULL    | NULL | 996663 |    10.00 | Using where |</span><br><span class="line">+----+-------------+-----------------+------------+------+---------------+------+---------+------+--------+----------+-------------+</span><br></pre></td></tr></table></figure><p>如果我们把comment_text创建了索引会是怎么样的呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+----+-------------+-----------------+------------+-------------+----------------------+----------------------+---------+------+------+----------+------------------------------------------------+</span><br><span class="line">| id | select_type | table           | partitions | type        | possible_keys        | key                  | key_len | ref  | rows | filtered | Extra                                          |</span><br><span class="line">+----+-------------+-----------------+------------+-------------+----------------------+----------------------+---------+------+------+----------+------------------------------------------------+</span><br><span class="line">|  1 | SIMPLE      | product_comment | NULL       | index_merge | PRIMARY,comment_text | PRIMARY,comment_text | 4,767   | NULL |    2 |   100.00 | Using union(PRIMARY,comment_text); Using where |</span><br><span class="line">+----+-------------+-----------------+------------+-------------+----------------------+----------------------+---------+------+------+----------+------------------------------------------------+</span><br></pre></td></tr></table></figure><p>你能看到这里使用了index merge，简单来说index merge就是对comment_id和comment_text分别进行了扫描，然后将这两个结果集进行了合并。这样做的好处就是避免了全表扫描。</p><h4 id="4-当我们使用LIKE进行模糊查询的时候，后面不能是"><a href="#4-当我们使用LIKE进行模糊查询的时候，后面不能是" class="headerlink" title="4.当我们使用LIKE进行模糊查询的时候，后面不能是%"></a>4.当我们使用LIKE进行模糊查询的时候，后面不能是%</h4><figure class="highlight sql"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">EXPLAIN</span> <span class="keyword">SELECT</span> comment_id,user_id,comment_text <span class="keyword">FROM</span> product_comment <span class="keyword">WHERE</span> comment_text <span class="keyword">LIKE</span> <span class="string">&#x27;%abc&#x27;</span></span><br></pre></td></tr></table></figure><p>运行结果：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">+----+-------------+-----------------+------------+------+---------------+------+---------+------+--------+----------+-------------+</span><br><span class="line">| id | select_type | table           | partitions | type | possible_keys | key  | key_len | ref  | rows   | filtered | Extra       |</span><br><span class="line">+----+-------------+-----------------+------------+------+---------------+------+---------+------+--------+----------+-------------+</span><br><span class="line">|  1 | SIMPLE      | product_comment | NULL       | ALL  | NULL          | NULL | NULL    | NULL | 996663 |    11.11 | Using where |</span><br><span class="line">+----+-------------+-----------------+------------+------+---------------+------+---------+------+--------+----------+-------------+</span><br></pre></td></tr></table></figure><p>这个很好理解，如果一本字典按照字母顺序进行了排序，我们会从首位进行匹配，而不会对中间位置进行匹配，否则索引就是失效了。</p><h4 id="5-索引列与NULL-或者-NOT-NULL-进行判断的时候也会失效"><a href="#5-索引列与NULL-或者-NOT-NULL-进行判断的时候也会失效" class="headerlink" title="5.索引列与NULL 或者 NOT NULL 进行判断的时候也会失效"></a>5.索引列与NULL 或者 NOT NULL 进行判断的时候也会失效</h4><p>这时因为索引并不存储空值，所以最好在设计数据表的时候就将字段设置为NOT NULL约束，比如你可以将INT类型的字段，默认值设置为0。将字符类型的默认值设置为空字符串(‘’)。</p><h4 id="6-我们在使用联合索引的时候需要注意最左原则"><a href="#6-我们在使用联合索引的时候需要注意最左原则" class="headerlink" title="6.我们在使用联合索引的时候需要注意最左原则"></a>6.我们在使用联合索引的时候需要注意最左原则</h4><p>最左原则也就是需要从左到右的使用索引中的字段，一条SQL语句可以使用联合索引的一部分，但是需要从最左侧开始，否则就会失效。</p><h3 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h3><p>实际工作中，查询的需求多种多样，创建的索引也会越来越多。这时还需要注意，我们要尽可能扩展索引，而不是新建索引，因为索引数量过多需要维护的成本也会变大，导致写效率变低。同时，我们还需要定期查询使用率低的索引，对于从未使用过的索引可以进行删除，这样才能让索引在 SQL 查询中发挥最大价值。</p><p><img src="https://i.loli.net/2020/11/27/zENF8JySCi7sVxZ.png"></p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> MySQL索引使用原则 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TLS1.2连接过程解析</title>
      <link href="/2020/11/20/TLS1.2%20%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%A8%8B%E8%A7%A3%E6%9E%90/"/>
      <url>/2020/11/20/TLS1.2%20%E8%BF%9E%E6%8E%A5%E8%BF%87%E7%A8%8B%E8%A7%A3%E6%9E%90/</url>
      
        <content type="html"><![CDATA[<h3 id="TLS1-2-连接过程解析"><a href="#TLS1-2-连接过程解析" class="headerlink" title="TLS1.2 连接过程解析"></a>TLS1.2 连接过程解析</h3><h4 id="HTTPS建立连接"><a href="#HTTPS建立连接" class="headerlink" title="HTTPS建立连接"></a>HTTPS建立连接</h4><p>当你在浏览器地址栏里键入 “<code>https</code>” 开头的URI，再往下回车，会发生什么？</p><p>你应该知道，浏览器首先要从URI里提取出协议名和域名。因为协议名是 “<code>https</code>“，所以浏览器就知道了端口号是默认的443，它再用DNS解析域名，得到目标的IP地址，然后就可以使用三次握手与网站建立TCP连接了。</p><p>在HTTP协议里，建立连接后，浏览器会立即发送请求报文。但现在是HTTPS协议，他需要再用另外一个 “握手” 过程，在TCP上建立安全连接，之后才是收发HTTP报文。</p><p>这个 “握手” 过程与TCP有些类似，是HTTPS和TLS协议里最重要，最核心的部分，懂了他，你就可以自豪的说自己 “掌握了HTTPS”。</p><h4 id="TLS协议的组成"><a href="#TLS协议的组成" class="headerlink" title="TLS协议的组成"></a>TLS协议的组成</h4><p>TLS包含几个子协议，你也可以理解为它是由几个不同职责的模块组成，比较常用的有记录协议，警报协议，握手协议，变更密码规范协议等。</p><p><code>记录协议</code> 规定了TLS收发数据的基本单位：记录（record）。它有点像是TCP里的segment，所有的其他子协议都需要通过记录协议发出。但多个记录数据可以在一个TCP包里一次性发出，也并不需要像TCP那样返回ACK。</p><p><code>警报协议</code> 的职责是向对方发出警报信息，有点像是HTTP协议里的状态码。比如，protocol_version就是不支持旧版本，bad_certificate就是证书有问题，收到警报后另一方可以选择继续，也可以立即终止连接。</p><p><code>握手协议</code> 是TLS里最复杂的子协议，要比TCP的SYN/ACK复杂的多，浏览器和服务器会在握手的过程中协商TLS版本号、随机数、密码套件等信息，然后交换证书和密钥参数，最终双方协商得到会话密钥，用于后续的混合加密系统。</p><p>下面这张图简要的描述了TLS的握手过程，其中每一个 ”框“ 都是一个记录，多个记录组合成以个TCP包发送。所以，最多经过两次消息往返（4个消息）就可以完成握手，然后就可以在安全的通信环境里发送HTTP报文，实现HTTPS协议。</p><p><img src="https://i.loli.net/2020/11/26/ythvAoNsLbZx61U.png"></p><h4 id="ECDHE-握手过程"><a href="#ECDHE-握手过程" class="headerlink" title="ECDHE 握手过程"></a>ECDHE 握手过程</h4><p><img src="https://i.loli.net/2020/11/26/ZVHEbP1jTSiDtWe.png"></p><p>在TCP建立连接之后，浏览器会首先发送一个 ”<code>Cilent Hello</code>“ 消息，也就是跟服务器 ”打招呼“。里面有客户端的版本号、支持的密码套件，还有一个随机数（Client Random），用于后续生成会话密钥。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">Handshake Protocol: Client Hello</span><br><span class="line">    Version: TLS 1.2 (0x0303)</span><br><span class="line">    Random: 1cbf803321fd2623408dfe…</span><br><span class="line">    Cipher Suites (17 suites)</span><br><span class="line">        Cipher Suite: TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256 (0xc02f)</span><br><span class="line">        Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (0xc030)</span><br></pre></td></tr></table></figure><p>这个意思就是：”我这边有这些信息，你看看哪些是能用的，关键的随机数可得留着。“</p><p>作为 “礼尚往来”，服务器收到 “Client Hello” 后，会返回一个 “Server Hello” 消息。把版本号对一下，也给出一个<code>随机数（Server Random）</code>，然后从客户端的列表选一个作为本次通信使用的密码套件，在这里他选择了 ”TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384“。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">Handshake Protocol: Server Hello</span><br><span class="line">    Version: TLS 1.2 (0x0303)</span><br><span class="line">    Random: 0e6320f21bae50842e96…</span><br><span class="line">    Cipher Suite: TLS_ECDHE_RSA_WITH_AES_256_GCM_SHA384 (0xc030)</span><br></pre></td></tr></table></figure><p>这个的意思是：“版本号对上了，可以加密，你的密码套件挺多，我选一个最合适的把，用椭圆曲线加RSA、AES、SHA384”。我也给你一个随机数，你也得留着。“</p><p>然后，服务器为了证明自己的身份，就把证书也发给了客户端</p><p>接下来是一个关键的操作，因为服务器选了ECDHE算法，所以他会在证书后发送 ”Server Ket Exchange“ 消息，里面是 <code>椭圆曲线的公钥</code>，用来实现密钥交换算法，再加上自己的私钥签名认证。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Handshake Protocol: Server Key Exchange</span><br><span class="line">    EC Diffie-Hellman Server Params</span><br><span class="line">        Curve Type: named_curve (0x03)</span><br><span class="line">        Named Curve: x25519 (0x001d)</span><br><span class="line">        Pubkey: 3b39deaf00217894e...</span><br><span class="line">        Signature Algorithm: rsa_pkcs1_sha512 (0x0601)</span><br><span class="line">        Signature: 37141adac38ea4...</span><br></pre></td></tr></table></figure><p>这相当于说：”刚才我选的密码套件有点复杂，所以再给你个算法的参数，和刚才的随机数一样有用，别丢了。为了防止别人冒充，我又盖了个章。”</p><p>之后是 “Server Hello Done” 消息，服务器说：“我的信息就是这些，打招呼完毕”。</p><p>这样第一个消息往返就结束了（两个TCP包），结果是客户端和服务器通过明文共享了三个消息：<code>Client Random</code>、<code>Server Random</code>、<code>Server Param</code>。</p><p>客户端这时也拿到了服务器的证书，那这个证书是不是真实有效呢？</p><p>它就开始走证书链逐级验证，确认证书的真实性，<strong>再用证书公钥验证签名</strong>，就确认了服务器的身份：“刚才跟我打招呼的不是骗你，可以接着往下走。”</p><p>然后，客户端按照密码套件的要求，也生成一个<code>椭圆曲线的公钥</code>，用 “<code>Client key Exchange</code>” 消息发给服务器。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Handshake Protocol: Client Key Exchange</span><br><span class="line">    EC Diffie-Hellman Client Params</span><br><span class="line">        Pubkey: 8c674d0e08dc27b5eaa…</span><br></pre></td></tr></table></figure><p>现在客户端和服务器手里都拿到了密钥交换算法的两个参数（Client Params，Server Params），就用ECDHE算法一阵算，算出一个新的东西，叫 “Pre-Master”，其实也是一个随机数。</p><p>现在客户端和服务端手里有了三个随机数：Client Random、Server Random 和 Pre-Master。用这三个作为原始材料，就可以生成用于加密会话的主密钥，叫 “<code>Master Secret</code>”。而黑客因为拿不到 “Pre-Master”，所以也就得不到主密钥。</p><p>为什么非得这么麻烦，非要三个随机数呢？</p><p>这就必须说TLS的设计者考虑的非常周到了，他们不信任客户端或服务器伪随机数的可靠性，为了保证真正的 “完全随机”，“不可预测”，把三个不可靠的随机数混合起来，那么 “随机”的程度就非常高了，足够让黑客难以猜测。</p><p>你一定很想知道“Master Secret” 究竟怎么算出来的吧，贴一下RFC里的公式</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">master_secret &#x3D; PRF(pre_master_secret, &quot;master secret&quot;,</span><br><span class="line">                    ClientHello.random + ServerHello.random)</span><br></pre></td></tr></table></figure><p>这里的“PRF”就是伪随机数函数，它基于密码套件里的最后一个参数，比如这次的 SHA384，通过摘要算法来再一次强化“Master Secret”的随机性。</p><p>主密钥有 48 字节，但它也不是最终用于通信的会话密钥，还会再用 PRF 扩展出更多的密钥，比如客户端发送用的会话密钥（client_write_key）、服务器发送用的会话密钥（server_write_key）等等，避免只用一个密钥带来的安全隐患。</p><p>有了主密钥和派生的会话密钥，握手就快结束了。客户端发一个“Change Cipher Spec”，然后再发一个“Finished”消息，把之前所有发送的数据做个摘要，再加密一下，让服务器做个验证。</p><p>意思就是告诉服务器：“后面都改用对称算法加密通信了啊，用的就是打招呼时说的 AES，加密对不对还得你测一下。”</p><p>服务器也是同样的操作，发“Change Cipher Spec”和“Finished”消息，双方都验证加密解密 OK，握手正式结束，后面就收发被加密的 HTTP 请求和响应了</p><h4 id="RSA握手过程"><a href="#RSA握手过程" class="headerlink" title="RSA握手过程"></a>RSA握手过程</h4><p>整个握手过程真是够复杂的，但你可能会问了，好像这个过程和其他地方看到的不一样呢?</p><p>刚才说的其实是如今主流的TLS握手过程，这与传统的握手有两点不同。</p><p>第一个，使用ECDHE实现密钥交换，而不是RSA，所以会在服务器端发出 “Server key Exchange” 消息。</p><p>第二个，因为使用了ECDHE，客户端可以不用等到服务器发回 “Finished” 确认握手完毕，立即就发出HTTP报文，省去了一个消息往返的时间浪费。这个叫 “TLS False Start”，意思就是 “抢跑”，和 “TCP Fast Open” 有点像，都是不等连接完全建立就提前发应用数据，提高传输的效率。</p><p><img src="https://i.loli.net/2020/11/26/bocaPJrnK234zWq.png"></p><p>大体流程没有变，只是“Pre-Master” 不再需要算法生成，而是客户端直接生成随机数，然后用服务器的公钥加密，通过 “Client Key Exchange” 消息发给服务器。服务器再用私钥解密，这样双方也实现了共享三个随机数，就可以生成主密钥。</p><h4 id="双向认证"><a href="#双向认证" class="headerlink" title="双向认证"></a>双向认证</h4><p>到这里TLS握手就基本讲完了。</p><p>不过上面说的是 “单向认证” 握手，只是认证了服务器的身份，而没有认证客户端的身份。这是因为通常单向认证通过后已经建立了安全通信，用账号、密码等简单的手段就能够确认用户的真实身份。</p><p>但为了防止账号、密码被盗，有时候（比如网上银行）还会使用U盾给用户办法客户端证书，实现 “双向认证”，这样会更加安全。</p><p>双向认证的流程也没有太多变化，只是在 “Server Hello Done” 之后，“Client Key Exchange” 之前，客户端要发送 “Client Certificate” 消息，服务器收到后也把证书链走一遍，验证客户端的身份。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul><li>HTTPS 协议会先与服务器执行 TCP 握手，然后执行 TLS 握手，才能建立安全连接；</li><li>握手的目标是安全地交换对称密钥，需要三个随机数，第三个随机数“Pre-Master”必须加密传输，绝对不能让黑客破解；</li><li>“Hello”消息交换随机数，“Key Exchange”消息交换“Pre-Master”；</li><li>“Change Cipher Spec”之前传输的都是明文，之后都是对称密钥加密的密文</li></ul>]]></content>
      
      
      <categories>
          
          <category> HTTPS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> TLS1.2连接过程 </tag>
            
            <tag> HTTPS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>数字签名与证书</title>
      <link href="/2020/11/18/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E4%B8%8E%E8%AF%81%E4%B9%A6/"/>
      <url>/2020/11/18/%E6%95%B0%E5%AD%97%E7%AD%BE%E5%90%8D%E4%B8%8E%E8%AF%81%E4%B9%A6/</url>
      
        <content type="html"><![CDATA[<h3 id="数字签名与证书"><a href="#数字签名与证书" class="headerlink" title="数字签名与证书"></a>数字签名与证书</h3><p>黑客虽然拿不到会话密钥，无法破解密文，但可以通过窃听收集到足够多的密文，在尝试着修改，重组后发送给网站。因为没有完整性保护，服务器只能 “照单全收”，然后他就可以通过服务器的响应获取进一步的线索，最终就会破解出明文。</p><p>另外，黑客也可以伪造身份发布公钥。如果你拿到了假的公钥，混合加密就完全失效了。你以为自己是在和 “某宝” 通信，实际上网线的另一端却是黑客，银行卡号、密码等敏感信息就在 “安全” 的通信过程中被窃取了。</p><p>所以，在机密性的基础上还必须加上完整性、身份认证等特征，才能真正的安全。</p><h4 id="摘要算法"><a href="#摘要算法" class="headerlink" title="摘要算法"></a>摘要算法</h4><p>实现完整性的手段主要是<code>摘要算法</code>，也就是常说的散列函数、哈希函数。</p><p>你可以把摘要算法近似的理解成一种特殊的压缩算法，他能够把任意长度的数据 “压缩” 成固定长度、而且独一无二的 “摘要” 字符串，就好像是给这段数据生成了一个数字 “指纹”。</p><p>换一个角度，也可以把摘要算法理解成特殊的 “加密算法”，他只有算法，没有密钥，加密后的数据无法解密，不能从摘要逆推出原文。</p><p><img src="https://i.loli.net/2020/11/26/Bh8qofUaiT53ycE.png"></p><p>摘要算法实际上是把数据从一个 “大空间” 映射到了小空间，所以就存在 “冲突（colisin，也叫冲突）” 的可能性，就如同现实中的指纹一样，可能会有两份不同的原文对应相同的摘要。好的摘要算法必须能够 “抵抗冲突”，让这种可能性尽量地小。</p><p>因为摘要算法对输入具有 “单向性” 和 “雪崩效应”，输入的微小不同会导致输出的剧烈变化，所以也被TLS用来生成伪随机数（PRF，pseud random function）。</p><p>你一定在日常工作中听过、或者用过MD5，SHA-1，他们就是最常用的两个摘要算法，能够生成16字节和20字节长度的数字摘要。但这两个算法的安全强度比较低，不够安全，在TLS里已经被禁止使用了。</p><p>目前TLS推荐使用的是SHA-1的后继者：SHA-2。</p><p>SHA-2实际上是一系列摘要算法的统称，总共有6中，常用的有SHA224、SHA256、SHA384，分别能够生成28字节、32字节、48字节的摘要。</p><h4 id="完整性"><a href="#完整性" class="headerlink" title="完整性"></a>完整性</h4><p>摘要算法保证了 “数字摘要” 和原文是完全等价的。所以只要在原文后附上它的摘要，就能够保证数据的完整性。</p><p>比如，你发了条消息：“转账1000元”，然后再加上一个SHA-2的摘要，网站收到后也计算一下消息的摘要，把这两份 “指纹” 做个对比，如果一直，说明消息是完整可信的，没有被修改。</p><p>如果黑客在中间哪怕改动了一个标点符号，摘要也会完全不同，网站计算比对就会发现消息被篡改，是不可信的。</p><p>不过摘要算法不具有机密性，如果明文传输，那么黑客可以修改消息后把摘要也一起改了，网站还是鉴别不出完整性。</p><p>所以，真正的完整性必须要建立在机密性之上，在混合加密系统里用的会话密钥机密信息和摘要，这样黑客无法得知明文，也没有办法动手脚了。</p><p>这有个术语，叫哈希消息认证码（HMAC）。</p><p><img src="https://i.loli.net/2020/11/26/ZWXTN4EOsFMDcHe.png"></p><h4 id="数字签名"><a href="#数字签名" class="headerlink" title="数字签名"></a>数字签名</h4><p>加密算法结合摘要算法，我们的通信过程可以说是比较安全了。但这里还有漏洞，就是通信的两个端点就像一开始所说的，黑客可以伪装成网站来窃取信息。而返过来，你也可以伪装成你，向网站发送支付、转账等信息，网站没有办法确认你的消息，前可能就这么被偷走了。</p><p>现实生活中，解决身份认证的手段是签名和印章，只要在纸上写上签名或者盖个章，就能够证明这份文件确实是由本人而不是其他人发出的。</p><p>在TLS里有个东西和现实中的签名、印章很像，只能由本人持有，而其他任何人都不会有呢？只要用这个东西，就能够在数字世界里证明你的身份。</p><p>这个东西就是非对称加密里的 “<code>私钥</code>”，使用私钥再加上摘要算法，就能实现 “<code>数字签名</code>“，同时实现 ”身份认证“ 和 ”不可否认“。</p><p>数字签名的原理其实很简单，就是把公钥私钥的用法反过来，之前是公钥加密，私钥解密，现在是私钥加密、公钥解密。</p><p>但又因为非对称加密效率太低，所以私钥只加密原文的摘要，这样运算量就小的多，而且得到的数字签名也很小，方便保管和传输。</p><p>签名和公钥一样完全公开，任何人都可以获取。但这个签名只有用私钥对应的公钥才能解开，拿到摘要后，再对比原文验证完整性，就可以像签署文件一样证明消息确实是你发的。</p><p>刚才的这两个行为也有专用术语，叫做 ”<code>签名</code>“ 和 ”<code>验签</code>“。</p><p>只要你和网站互相交换公钥，就可以用”签名“和”验签“ 来确认消息的真实性，因为私钥保密，黑客不能伪造签名，就能保证通信双发的身份。</p><p>比如，你用自己的私钥签名一个消息 ”我是小明“。网站收到后用你的公钥验签，确认身份没问题，于是也用它的私钥签名消息 ”我是某宝“。你收到后再用它的公钥验一下，也没问题，这样你和网站就知道对方不是假冒的，后面就可以混合加密进行安全通信了。</p><h4 id="数字证书和CA"><a href="#数字证书和CA" class="headerlink" title="数字证书和CA"></a>数字证书和CA</h4><p>到现在，综合使用对称加密，非对称加密和摘要算法，我们已经实现了安全的四大特性，是不是已经完美了呢？</p><p>不是的，这里还有一个 ”<code>公钥的信任</code>“ 问题。因为谁都可以发布公钥，我们还缺少防止黑客伪造公钥手段，也就是说，怎么判断这个公钥是你或某宝的公钥呢？</p><p>我们可以用类似密钥交换的方式解决公钥认证问题，用别的私钥来给公钥签名，显然，这又会陷入 ”无穷递归“。</p><p> 但这次实在是 ”没招了“，要终结这个 ”死循环“，就必须引入 ”外力“，找一个公认的可行的第三方，让它作为 ”新人的起点，递归的终点“，构建起公钥的信任链。</p><p>这个 ”第三方“ 就是我们常说的<code>CA</code>（Certificate Authority，证书认证机构）。他就像网络世界里的公安局、具有极高的可信度，由他来给各个公钥签名，用自身的信誉来保证公钥无法伪造，是可信的。</p><p>CA对公钥的签名认证也是有格式的，不是简单地把公钥绑定在持有者身份上就完事了，还要包含序列号，用途，颁发者，有效时间等等，把这些打成一个包再签名，完整地证明公钥关联地这种信息，形成 ”<code>数字证书</code>“。</p><p>知名地CA全世界就那么几家，比如DigiCert、Verisign、Entrust、Let‘ s Encrypt等，它们签发地证书分DV、OV、EV三种，区别在于可信程度。</p><p>DV是最低的，只是域名级别的可行，背后是谁不知道。EV是最高的，经过了法律和审计的严格核查，可以证明网站拥有者的身份（在浏览器地址栏会显示出公司的名字，例如Apple、GitHub的网站）。</p><p>不过，CA怎么证明自己呢？</p><p>这还是信任链的问题。小一点的CA可以让大CA签名认证，但链条的最后，也就是RootCA，就只能自己证明自己了，这个就叫 ”<code>自签名证书</code>“ 或者 ”<code>根证书</code>“。你必须相信，否则整个证书信任链就走不下去了。</p><p><img src="https://i.loli.net/2020/11/26/OI7f3bClYGmD5L4.png"></p><p>有了这个证书体系，操作系统和浏览器都内置了各大 CA 的根证书，上网的时候只要服务器发过来它的证书，就可以验证证书里的签名，顺着证书链（Certificate Chain）一层层地验证，直到找到根证书，就能够确定证书是可信的，从而里面的公钥也是可信的。</p><p>我们的实验环境里使用的证书是“野路子”的自签名证书（在 Linux 上用 OpenSSL 命令行签发），肯定是不会被浏览器所信任的，所以用 Chrome 访问时就会显示成红色，标记为不安全。但你只要把它安装进系统的根证书存储区里，让它作为信任链的根，就不会再有危险警告。</p><h4 id="证书体系的弱点"><a href="#证书体系的弱点" class="headerlink" title="证书体系的弱点"></a>证书体系的弱点</h4><p>证书体系（PKI，Public Key Infrastructure）虽然是目前整个网络世界的安全基础设施，但绝对的安全是不存在的，它也有弱点，还是关键的“信任”二字。</p><p>如果 CA 失误或者被欺骗，签发了错误的证书，虽然证书是真的，可它代表的网站却是假的。</p><p>还有一种更危险的情况，CA 被黑客攻陷，或者 CA 有恶意，因为它（即根证书）是信任的源头，整个信任链里的所有证书也就都不可信了。</p><p>这两种事情并不是“耸人听闻”，都曾经实际出现过。所以，需要再给证书体系打上一些补丁。</p><p>针对第一种，开发出了 CRL（证书吊销列表，Certificate revocation list）和 OCSP（在线证书状态协议，Online Certificate Status Protocol），及时废止有问题的证书。</p><p>对于第二种，因为涉及的证书太多，就只能操作系统或者浏览器从根上“下狠手”了，撤销对 CA 的信任，列入“黑名单”，这样它颁发的所有证书就都会被认为是不安全的。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul><li>摘要算法用来实现完整性，能够为数据生成独一无二的“指纹”，常用的算法是 SHA-2；</li><li>数字签名是私钥对摘要的加密，可以由公钥解密后验证，实现身份认证和不可否认；</li><li>公钥的分发需要使用数字证书，必须由 CA 的信任链来验证，否则就是不可信的；</li><li>作为信任链的源头 CA 有时也会不可信，解决办法有 CRL、OCSP，还有终止信任。</li></ul>]]></content>
      
      
      <categories>
          
          <category> HTTPS </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTPS </tag>
            
            <tag> 加密算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP的缓存控制</title>
      <link href="/2020/11/18/HTTP%E7%9A%84%E7%BC%93%E5%AD%98%E4%BB%A3%E7%90%86/"/>
      <url>/2020/11/18/HTTP%E7%9A%84%E7%BC%93%E5%AD%98%E4%BB%A3%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="HTTP的缓存控制"><a href="#HTTP的缓存控制" class="headerlink" title="HTTP的缓存控制"></a>HTTP的缓存控制</h3><h4 id="服务器的缓存控制"><a href="#服务器的缓存控制" class="headerlink" title="服务器的缓存控制"></a>服务器的缓存控制</h4><p>为了更好的说明缓存的运行机制，下面我用 “<code>生鲜速递</code>” 作为比喻，看看缓存是如何工作的。</p><p>春天到了，天气很热。你想吃西瓜消暑，于是打开冰箱，但很不巧，冰箱是空的。不过没事，现在物流很发达，给生鲜超市打电话，不一会，就给你送来一个八斤的沙瓤大西瓜，上面还贴着标签：“保鲜期5天”。好了，你把它放进冰箱，想吃的时候随时拿出来。</p><p>在这个场景里，“<code>生鲜超市</code>” 就是Web服务器，“<code>你</code>” 就是浏览器，“<code>冰箱</code>” 就是浏览器的内部缓存。整个流程翻译成HTTP就是：</p><ol><li>浏览器发现缓存无数据，于是发送请求，向服务器获取资源；</li><li>服务器响应请求，返回资源，同时标记资源的有效期；</li><li>浏览器缓存资源，等待下次重用。</li></ol><p><img src="https://i.loli.net/2020/11/26/ZLJzNw8aydcBGn7.png"></p><p>服务器标记资源有效期使用的头字段是 “Cache-Control”，里面的值 “max-age” 就是资源的有效时间，相当于告诉服务器，“这个页面只能缓存30秒”，之后就算是过期，不能用。 “</p><p>你可能要问了，让浏览器直接缓存数据就好了，为什么要加个有效期呢？</p><p>这是因为网络上的数据随时都在变化，不能保证它稍后的时间还是原来的样子。就像生鲜超市给你快递的西瓜，只有5天的保鲜期，过了这个期限最好还是别吃，不然可能会闹肚子。</p><p>”<code>Cache-control</code>“ 字段里的 ”<code>max-age</code>“ 和上一讲里Cookie有点像，都是标记资源的有效期，</p><p>但我必须提醒你注意，这里的max-age是 ”<code>生存时间</code>“，时间的计算起点是响应报文的创建时刻（即Date字段，也就是离开服务器的时刻），而不是客户端收到报文的时刻，也就是说包含了在链路传输过程中所有结点所停留的时间。</p><p>比如，服务器设定 ”max-age=5“，但因为网络质量很糟糕，等浏览器收到响应报文已经过去了4秒，那么这个资源在客户端就最多能够再存1秒钟，之后就会失效。</p><p>”max-age“ 是HTTP缓存控制最常用的属性，此外在响应报文里还可以用其他的属性来跟精确的指示浏览器应该如何使用缓存：</p><ul><li>no_store：<code>不允许缓存</code>，用于某些变化非常频繁的数据，例如秒杀页面；</li><li>no_cache：他的字面含义容易与no_store搞混，实际的意思并不是不允许缓存，而是<code>可以缓存</code>，但在使用之前必须要去服务器验证是否过期，是否有最新的版本；</li><li>must-revalidate：又是和no_cache相似的词，他的意思是如果缓存不过期就可以继续使用，但过期了如果还想用就必须去服务器验证。</li></ul><p>听的有点糊涂吧。没关系，我拿生鲜速递来举例说明一下：</p><ul><li>no_store：买来的西瓜不允许放进冰箱，要么立刻吃，要么立刻扔掉；</li><li>no_cache：可以放进冰箱，但吃之前必须问超市有没有更新鲜的，有就吃超市里的。</li><li>must-revalidate：可以放进冰箱，保鲜期内可以吃，过期了就要问超市让不让吃。</li></ul><p>你看，你这超市管的还挺多啊，西瓜到了家里怎么吃还得听他的。不过没办法，在HTTP协议里服务器就是这样的霸气。</p><blockquote><p>把服务器的缓存控制策略画了一个流程图，对照着它你就可以在今后开发里明确 ”<code>Cache-Control</code>“ 的用法了。</p></blockquote><p><img src="https://i.loli.net/2020/11/26/vhXEQ1WpoHJFT2t.png"></p><h4 id="客户端的缓存控制"><a href="#客户端的缓存控制" class="headerlink" title="客户端的缓存控制"></a>客户端的缓存控制</h4><p>现在冰箱里已经有了 ”缓存“ 的西瓜，是不是可以直接开吃了呢？</p><p>你可以在Chrome里点几次 ”刷新按钮“，估计你会失望，页面上的ID一直在变，根本不是缓存的结果，明明说缓存30秒，怎么就不起作用呢？</p><p>其实不止服务器可以发”<code>Cache-Control</code>“ 头，浏览器也可以发 ”Cache-Control“，也就是说请求 - 应答的双方都可以用这个字段进行缓存控制，互相协助缓存的使用策略。</p><p>当你点”<code>刷新</code>“ 按钮的时候，浏览器会在请求头里加一个 ”<code>Cache-Control：max-age=0</code>“。因为max-age是 ”<code>生存时间</code>“ ，max-age = 0 的意思就是 ”我要一个最新新鲜的西瓜“，而本地缓存里的数据至少保存了几秒钟，所以浏览器就不会使用缓存，而是向服务器发送请求。服务器看到max-age=0，也就会用一个最新生成的报文回应浏览器。</p><p>Ctrl+F5的 ”<code>强制刷新</code>“ 又是什么样的呢？</p><p>他其实就是发了一个 “<code>Cache-Control: no-cache</code>“，含义和 ”max-age=0“ 基本一样，就看后台服务器怎么理解，通常两者效果是相同的。</p><p>那么，浏览器的缓存究竟什么时候才能生效呢？</p><p>别着急，试着点一下浏览器的 ”<code>前进</code>“ ”<code>后退</code>“ 按钮，再看开发者工具，你就会惊喜地发现 “from disk cache” 的字样，意思是没有发送网络请求，而是读取的磁盘上的缓存。</p><p>这几个操作与刷新有什么区别的？</p><p>其实也很简单，在 前进 ，后退，跳转这些重定向动作中浏览器不会”夹带私货“，只用最基本的请求头，没有 ”<code>Cache-Control</code>“，所以就会检查缓存，直接利用之前的资源，不再进行网络通信。</p><h4 id="条件请求"><a href="#条件请求" class="headerlink" title="条件请求"></a>条件请求</h4><p>浏览器用 ”<code>Cache-Control</code>“ 做缓存控制只能是刷新数据，不能很好的利用缓存数据，又因为缓存会失效，使用前还必须要去服务器验证是否是最新版。</p><p>那么该怎么做呢？</p><p>浏览器可以用两个连续的请求组成 ”验证动作“ ：先是一个HEAD，获取资源的修改时间等元信息，然后和缓存数据做比较，如果没有改动就使用缓存，节省网络流量，否则就再发一个GET请求，获取最新的版本。</p><p>但这样的两个请求网络成本实在太高了，所以HTTP就定义了一系列<em>”<code>IF</code>“</em>  开头的 ”<code>条件请求</code>“ 字段，专门用来检查验证资源是否过期，把这两个请求才能完成的工作合并在一个请求里做。而且，验证的责任也交给服务器，浏览器只需 ”坐享其成“。</p><p>条件请求一共又5个头字段，我们最常用的是 ”<code>if-Modified-Since</code>“ 和 ”<code>If-None-Match</code>“ 这两个。需要第一次的响应报文预先提供 ”<code>Last-modified</code>“ 和 ”ETag“，然后第二次请求时就可以带上缓存里的原值，验证资源是否时最新的。</p><p>如果资源没有变，服务器就会回应一个 ”304 Not Modified“ ，表示缓存依然有效，浏览器就可以更新一下有效期，然后放心大胆的使用缓存了。</p><p><img src="https://i.loli.net/2020/11/26/Vv5THMWKSdtk6Qm.png"></p><p>”Last-modified“ 很好理解，就是文件的最后修改时间，ETag是什么呢 ？</p><p>ETag是 ”实体标签（Entity Tag）“ 的缩写，是资源的一个唯一标识，主要是用来解决修改时间无法准确区分文件变化的问题。</p><p>比如，一个文件在一秒内修改了多次，但因为修改时间是秒级，所以这一秒内的新版本无法区分。</p><p>再比如，一个文件定期更新，但有时会是同样的内容，实际上没有变化，用修改时间就会误以为发生了变化，传送给浏览器就会浪费宽带。</p><p>使用ETag就可以精确的识别资源的变动情况，让浏览器能够更有效地利用缓存。</p><p>ETag还有 ”强“，”弱“ 之分。</p><p>强ETag要求资源在字节级别必须完全相符，弱ETag在值前又个 ”W/“标记，只要求资源在语义上没有变化，但内部可能发生了变化（例如HTML里的标签地顺序调整，或者多了几个空格）。</p><p>还是拿生鲜速递做比喻最容易理解：</p><p>你打电话给超市，”我这个西瓜是三天前买的，还有最新的吗？“。超市看了下库存说：”没有啊，我这里都是三天前的。“ 于是你就知道了，再让超市送货也没用，还是吃冰箱里的西瓜吧。这就是 ”<code>if-Modified-Since</code>“ 和 ”<code>Last-modified</code>“。</p><p>但你还是想要最新的，就又打电话：”又不是沙瓤的西瓜吗？“，超市告诉你都是沙瓤的，于是你还是只吃冰箱里的西瓜。这就是 ”<code>If-None-Match</code>“ 和 ”<code>弱Etag</code>“</p><p>第三次打电话，你说 ”有不是8斤的沙瓤西瓜吗？“，这回超市给了你满意的答复：”有个10斤的沙瓤西瓜“。于是，你就让掉了冰箱里的存货，让超市重新送了一个新的大西瓜。这就是 ”<code>If-None-Match</code>“ 和 ”强ETag“。</p><blockquote><p>条件请求里其他的三个头字段是“If-Unmodified-Since”“If-Match”和“If-Range”，其实只要你掌握了“if-Modified-Since”和“If-None-Match”，可以轻易地“举一反三”。</p></blockquote><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul><li>缓存是优化系统性能的重要手段，<code>HTTP</code> 传输的每一个环节中都可以有缓存；</li><li>服务器使用“<code>Cache-Control</code>”设置缓存策略，常用的是“<code>max-age</code>”，表示资源的有效期；</li><li>浏览器收到数据就会存入缓存，如果没过期就可以直接使用，过期就要去服务器验证是否仍然可用；</li><li>验证资源是否失效需要使用“条件请求”，常用的是“<code>if-Modified-Since</code>”和“<code>If-None-Match</code>”，收到 <code>304</code> 就可以复用缓存里的资源；</li><li>验证资源是否被修改的条件有两个：“<code>Last-modified</code>”和“<code>ETag</code>”，需要服务器预先在响应报文里设置，搭配条件请求使用；</li><li>浏览器也可以发送“<code>Cache-Control</code>”字段，使用“<code>max-age=0</code>”或“<code>no_cache</code>”刷新数据</li></ul><blockquote><p>HTTP 缓存看上去很复杂，但基本原理说白了就是一句话：“没有消息就是好消息”，“没有请求的请求，才是最快的请求。”</p></blockquote><p><img src="https://i.loli.net/2020/11/26/gkI8L3vNyYKPARF.png"></p>]]></content>
      
      
      <categories>
          
          <category> HTTP协议 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> HTTP协议 </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>对称加密与非对称加密</title>
      <link href="/2020/11/18/%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E4%B8%8E%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86/"/>
      <url>/2020/11/18/%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86%E4%B8%8E%E9%9D%9E%E5%AF%B9%E7%A7%B0%E5%8A%A0%E5%AF%86/</url>
      
        <content type="html"><![CDATA[<h3 id="对称加密与非对称加密"><a href="#对称加密与非对称加密" class="headerlink" title="对称加密与非对称加密"></a>对称加密与非对称加密</h3><p>由于HTTPS、TLS都运行在计算机上，所以 “密钥” 就是一长串的数字，但约定俗称的度量单位是 “位”（bit），而不是 “字节”（byte）。比如，说密钥长度是128，就是16字节的二进制串，密钥长度是1024，就是128字节的二进制串。</p><p>按照密钥的使用方式，加密可以分为两大类：<strong>对称加密和非对称加密。</strong></p><h4 id="对称加密"><a href="#对称加密" class="headerlink" title="对称加密"></a>对称加密</h4><p><code>对称加密</code> 很好理解，就是指加密和解密时使用的密钥都是同一个，是 “对称的”。只要保证了密钥的安全，那整个通信过程就可以说具有了机密性。</p><p>举个例子，你想要登录某网站，只要事先和它约定好使用一个对称密码，通信过程中传输的全是密钥加密后的密文，只有你和网站才能解密。黑客即使能够窃听，看到的也只是乱码，因为没有密钥无法解出明文，所以就实现了机密性。</p><p><img src="https://i.loli.net/2020/11/26/wjAS5GZus32RLCU.png"></p><p>TLS里有非常多的对称加密算法可供选择，比如RC4、DES、3DES、AES、ChaCha20等，但前三种算法都被认为是不安全的，通常都禁止使用，目前常用的只有AES和ChaCha20。</p><p>AES的意思是 “高级加密标准”，密钥长度可以是128、192 或 256。他是DES算法的替代者，安全强度很高，性能也很好，而且有的硬件还会做特殊优化，所以非常流行，是应用最广泛的对称加密算法。</p><p>ChaCha20 是Google 设计另一种加密算法，密钥长度固定位256位，纯软件运行性能要超过AES，曾经在移动客户端上比较流行，但ARMv8之后也加入了AES硬件优化，所以现在不再具有明显的优势，但仍然算得上是一个不错的算法。</p><h4 id="加密分组模式"><a href="#加密分组模式" class="headerlink" title="加密分组模式"></a>加密分组模式</h4><p>对称算法还有一个 “分组模式” 的概念，它可以让算法用固定长度的密钥加密任意长度的明文，把小秘密（即密钥）转化为大秘密（即密文）。</p><p>最早就ECB，CBC，CFD，OFB等几种分组模式，但都陆续被发现有安全漏洞，所以现在基本都不怎么用了。最新的分组模式被称为AEAD，在加密的同时增加里认证的功能，常用的是GCM、CCM和Poly1305。</p><p>把上面这些组合起来，就可以得到TLS密码套件中定义的对称加密算法。</p><p>比如，AES128-GCM，意思是密钥长度位128位的AES算法，使用的分组模式是GCM；ChaCha20-Poly1305的意思是ChaCha20算法，使用的分组模式是Poly1305。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">https:&#x2F;&#x2F;www.chrono.com&#x2F;24-1?key&#x3D;123456</span><br><span class="line"> </span><br><span class="line">algo  &#x3D; aes_128_cbc</span><br><span class="line">plain &#x3D; hello openssl</span><br><span class="line">enc   &#x3D; 93a024a94083bc39fb2c2b9f5ce27c09</span><br><span class="line">dec   &#x3D; hello openssl</span><br></pre></td></tr></table></figure><h4 id="非对称加密"><a href="#非对称加密" class="headerlink" title="非对称加密"></a>非对称加密</h4><p>对称加密看上去好像完美的实现了机密性，但其中有一个很大的问题：如何把密钥安全地传递给对方，术语叫 “密钥交换” 。</p><p>因为在对称加密算法中只要持有密钥就可以解密。如果你和网站约定地密钥在传递途中被黑客窃取，那他就可以在之后随意解密收发地数据，通信过程也就没有机密性可言了。</p><p>这个问题该怎么解决呢？</p><p>你或许会说：“把密钥在加密一下发过去就好了”，但传输“加密密钥地密钥” 又成了新问题。这就像是 “鸡生蛋，蛋生鸡” ，就可以无限递归下去。只用对称加密算法，是觉得无法解决密钥交换问题的。</p><p>所以，就出现了非对称加密（也叫公钥加密算法）。</p><p>它有两个密钥，一个叫“<code>公钥</code>”（public key），一个叫 “<code>私钥</code>”（private key）。两个密钥是不同地，“不对称”，公钥可以公开给任何人使用，而私钥必须严格保密。</p><p>公钥和私钥有个特别的 “<code>单向性</code>”，虽然都可以用来加密解密，但公钥加密后只能用私钥解密，反过来，私钥加密后也只能用公钥解密。</p><p>非对称加密可以解决 “密钥交换” 的问题。网站秘密保管私钥，在网上任意分发公钥，你先要登录网站只要用公钥加密就行了，密文只能由私钥持有者才能解密。而黑客因为没有私钥，所以就无法破解密文。</p><p><img src="https://i.loli.net/2020/11/26/His8dtlDrbhAXcR.png"></p><p>非对称加密算法的设计要比对称加密算法难得多，在TLS里只有很少的几种，比如DH、DSA、RSA、ECC 等。</p><p>RSA可能是其中最著名的一个，几乎可以说是非对称加密的代名词，他的安全性基于 “整数分解” 的数学难题，使用两个超大素数的乘积作为生成密钥的材料，想要从公钥推算出私钥是非常困难的。</p><p>10年前的RSA密钥推荐长度是1024，但随着计算机运算能力的提高，现在1024已经不安全了，普遍认为至少要2048位。</p><p>ECC（Elliptic Curve Cryptography）是非对称加密里的“后起之秀”，它基于“椭圆曲线离散对数”的数学难题，使用特定的曲线方程和基点生成公钥和私钥，子算法 ECDHE 用于密钥交换，ECDSA 用于数字签名。</p><p>目前比较常用的两个曲线是 P-256（secp256r1，在 OpenSSL 称为 prime256v1）和 x25519。P-256 是 NIST（美国国家标准技术研究所）和 NSA（美国国家安全局）推荐使用的曲线，而 x25519 被认为是最安全、最快速的曲线。</p><p>ECC 名字里的“椭圆”经常会引起误解，其实它的曲线并不是椭圆形，只是因为方程很类似计算椭圆周长的公式，实际的形状更像抛物线，比如下面的图就展示了两个简单的椭圆曲线。</p><p>比起 RSA，ECC 在安全强度和性能上都有明显的优势。160 位的 ECC 相当于 1024 位的 RSA，而 224 位的 ECC 则相当于 2048 位的 RSA。因为密钥短，所以相应的计算量、消耗的内存和带宽也就少，加密解密的性能就上去了，对于现在的移动互联网非常有吸引力。</p><p><img src="https://i.loli.net/2020/11/26/7T23jhiFq5eodyu.png" alt="image-20201116170032098"></p><h4 id="混合加密"><a href="#混合加密" class="headerlink" title="混合加密"></a>混合加密</h4><p>看到这里，虽然非对称加密没有 “密钥交换” 的问题，但因为他们都是基于复杂的数学难题，运算速度很慢，即使是ECC也要比AES差上好几个数量级。如果仅用非对称加密加密，虽然保证了安全，但通信的速度有如龟速、蜗牛，实用性就变成了零。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">aes_128_cbc enc&#x2F;dec 1000 times : 0.97ms, 13.11MB&#x2F;s</span><br><span class="line"> </span><br><span class="line">rsa_1024 enc&#x2F;dec 1000 times : 138.59ms, 93.80KB&#x2F;s</span><br><span class="line">rsa_1024&#x2F;aes ratio &#x3D; 143.17</span><br><span class="line"> </span><br><span class="line">rsa_2048 enc&#x2F;dec 1000 times : 840.35ms, 15.47KB&#x2F;s</span><br><span class="line">rsa_2048&#x2F;aes ratio &#x3D; 868.13</span><br><span class="line"></span><br></pre></td></tr></table></figure><p>可以看到，RSA的运行速度是非常慢的，2048位的加解密大约是15kb/s（微妙或毫秒级），而AES128则是13MB/S（纳秒级），差了几百倍。</p><p>那么，是不是能够把对称加密和非对称加密结合起来呢，两者互相取长补短，即能高效的加密解密，又能安全的密钥交换。</p><p>这就是现在TLS里使用的<code>混合加密</code> 方式，其实说穿了也很简单：</p><p>在通信刚开始的时候使用非对称算法，比如RSA、ECDHE，首先解决密钥交换的问题。</p><p>然后用随机数产生对称算法使用的 “<code>会话密钥</code>”，再用公钥加密。因为会话密钥很短，通常只有16字节或32字节，所以慢点也无所谓。</p><p>对方拿到密文后用私钥解决，取出会话密钥。这样，双方就实现了对称加密的安全交换，后续就不再使用非对加密，全都使用对称加密。</p><p><img src="https://i.loli.net/2020/11/26/psj8SQ1TcXdPrlC.png"></p><p>这样混合加密就结局了对称加密算法的密钥交换问题，而且安全和性能兼顾，完美的实现了机密性。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ol><li>加密算法的核心思想是 “把一个小秘密（密钥）转化为一个大秘密（密文消息）”，守住了小秘密，也就守住了大秘密；</li><li>对称加密只使用一个密钥，运算速度快，密钥必须保密，无法做到安全的密钥交换，常用的有AES 和 ChaCha20；</li><li>非对称加密使用两个密钥：公钥和私钥，公钥可以任意分发而密钥保密，解决了密钥交换的问题但速度慢，常用的有RSA和ECC；</li><li>把对称加密和非对称加密结合起来就得到了 “<code>又好又快</code>“ 地混合加密，也就是TLS里使用的加密方式。 </li><li>简单来说，SSL就是通信双方通过非对称加密协商出一个用于对称加密的密钥。</li></ol>]]></content>
      
      
      <categories>
          
          <category> 加密算法 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 加密算法 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>TCP协议</title>
      <link href="/2020/10/20/%E9%9D%A2%E5%90%91%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%AF%E9%9D%A0%E7%9A%84%E8%BF%90%E8%BE%93%E5%8D%8F%E8%AE%AE%20TCP/"/>
      <url>/2020/10/20/%E9%9D%A2%E5%90%91%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%AF%E9%9D%A0%E7%9A%84%E8%BF%90%E8%BE%93%E5%8D%8F%E8%AE%AE%20TCP/</url>
      
        <content type="html"><![CDATA[<h3 id="面向连接的可靠的运输协议-TCP"><a href="#面向连接的可靠的运输协议-TCP" class="headerlink" title="面向连接的可靠的运输协议 TCP"></a>面向连接的可靠的运输协议 TCP</h3><p>​    TCP被称为面向链接的，这是因为在一个应用进程可以开始向另一个应用进程发送数据之前，这两个进程必须相互“握手”，即他们必须相互发送某些预备报文段，以建立确保数据传输的参数。作为TCP连接建立的一部分，连接的双方都将初始化与TCP连接相关的许多TCP状态变量。</p><p>​    由于TCP协议只在端系统中运行，而不在中间的网络元素（路由器和交换机）中运行，所以中间的网络元素不会维持TCP连接状态。事实上，中间路由器对TCP连接完全视而不见，他们看到的是数据，而不是连接。</p><p>​    TCP连接提供的是全双工服务：如果一台主机上的进程A与另一台主机上的进程B存在一条TCP连接，那么应用层数据就可以从进程B流向进程A的同时，也从进程A流向进程B。TCP连接也总是点对点的。即在单个发送方与接收方之间的连接。所谓“多播”，即在一次发送操作中，从一个发送方将数据传送给多个接收方，对TCP来说这是不可能的。对于TCP而言，两台主机是一对，而三台主机则太多！</p><h3 id="TCP协议详解"><a href="#TCP协议详解" class="headerlink" title="TCP协议详解"></a>TCP协议详解</h3><p><img src="https://static01.imgkr.com/temp/5acf82aa4f4c4513a180925f431f4573.png" alt="image-20201103171002436"></p><h5 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h5><ul><li><p>TCP是面向连接的协议</p></li><li><p>TCP的一个连接有两端（点对点通信）</p></li><li><p>TCP提供可靠的传输服务</p></li><li><p>TCP协议提供全双工的通信</p></li><li><p>TCP是面向字节流的协议</p><p><img src="https://static01.imgkr.com/temp/f6f6ec01b1404c4aa86795c8f7a7e417.png" alt="image-20201103171159143"></p></li></ul><h5 id="TCP首部格式"><a href="#TCP首部格式" class="headerlink" title="TCP首部格式"></a>TCP首部格式</h5><p><img src="https://static01.imgkr.com/temp/437f2373a73045f6ad2fca637ea29423.png" alt="image-20201103173128597"></p><ul><li><p>序号： </p><ul><li>一共32位，范围是0-2^32-1</li><li>一个字节一个序号</li><li>代表数据首字节序号</li></ul></li><li><p>确认号</p><ul><li><p>0-2^32-1</p></li><li><p>一个字节一个序号</p></li><li><p>期望收到数据的首字节序号（确认号为N：则表示N-1序号的数据都已经收到）</p></li></ul></li></ul><ul><li><p>数据偏移</p><ul><li><p>占4位：0-15，单位为：32位字</p></li><li><p>数据偏离首部的距离</p><p><img src="https://static01.imgkr.com/temp/18f7be02226d4ee8bc17ac00b576229c.png" alt="image-20201103174626449"></p></li></ul></li><li><p>TCP标记</p><ul><li><p>占6位，每位各有不同意义</p><p><img src="https://static01.imgkr.com/temp/d47f18a9bbba4f3dbbbdea6c12d49f21.png" alt="image-20201103174734701"></p></li></ul></li></ul><p><img src="https://static01.imgkr.com/temp/785a4c50178748dd8aef930f3213c389.png" alt="image-20201103174757710"></p><ul><li><p>窗口</p><ul><li>占16位：0-2^16-1</li><li>窗口指明允许发送的数据量<ul><li>确认号：501 ，窗口：1000，那么501~1500字节的数据都可以传输</li></ul></li></ul></li><li><p>校验和</p></li><li><p>紧急指针</p><ul><li>紧急数据（URG = 1）</li><li>指定紧急数据在报文的位置</li></ul></li><li><p>TCP选项</p><ul><li><p>最多40字节</p></li><li><p>支持未来的拓展</p></li></ul></li></ul><h5 id="TCP-可靠传输基本原理"><a href="#TCP-可靠传输基本原理" class="headerlink" title="TCP 可靠传输基本原理"></a>TCP 可靠传输基本原理</h5><p><strong>ARQ协议</strong>：自动重传请求是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超市这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送一段时间之内没有收到确认帧，他通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议。</p><ul><li><p>停止等待ARQ协议</p><ul><li>停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到ACK确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。</li><li>在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认；</li></ul><p><strong>优点</strong>：简单</p><p><strong>缺点</strong>：信道利用率低，等待时间长。</p></li><li><p>连续ARQ协议</p><ul><li>连续ARQ协议可提高信道利用率。发送方维持一个发送窗口（滑动窗口协议）内的分组，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组已经正确收到了。</li></ul><p><strong>优点</strong>： 信道利用率高，容易实现，即使确认丢失，也不必重传。</p><p><strong>缺点</strong>：不能向发送方反映出接收方已经正确收到所有分组的信息。比如：发送方发送了5条消息，中间第三条丢失了，这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 回退N，表示需要退回来重传已经发送过的N个消息，显然单个分组的差错就能够引起重传大量分组，许多分组根本没有必要重传。</p></li><li><p>选择重传协议</p><ul><li>选择重传协议通过让发送方仅重传那些它怀疑在接收方出错的分组而避免了不必要的重传。接收方将确认一个正确接受的分组而不管其是否按序。失序的分组将被缓存知道所有丢失分组皆被收到为止。</li></ul></li></ul><p><strong>TCP的差错回复机制最好被分类位滑动窗口（GBN）协议与选择重传（SR）协议的结合体。</strong></p><h5 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h5><p> 如果发送者发送数据过快，接收者来不及接收，那么就会有分组丢失。为了避免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。流量控制的根本目的是防止分组丢失，他是构成TCP可靠性的一方面。</p><p>如何实现流量控制？</p><p>由滑动窗口协议（连续ARQ协议）实现。滑动窗口协议即保证了分组无差错、有序接受，也实现了流量控制。主要的方式就是接收方返回的ACK中包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送。</p><p>流量控制引发的死锁？怎么避免死锁的发生？</p><ul><li>当发送者收到了一个窗口为0的应答，发送者便停止发送，等待接收者的下一个应答。但是如果这个窗口不为0的应答在传输过程丢失，发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待，从而产生死锁。<br>为了避免流量控制引发的死锁，TCP使用了持续计时器。每当发送者收到一个零窗口的应答后就启动该计时器。时间一到便主动发送报文询问接收者的窗口大小。若接收者仍然返回零窗口，则重置该计时器继续等待；若窗口不为0，则表示应答报文丢失了，此时重置发送窗口后开始发送，这样就避免了死锁的产生。</li></ul><h5 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h5><p>​    <strong>拥塞控制和流量控制的区别</strong></p><p>​    发送方维持一个叫做拥塞控制窗口的状态变量。拥塞窗口的大小却决于网络的拥塞程度，并且动态的在变化，发送方让自己的发送窗口等于拥塞控制，另外考虑到接收方的接收能力，发送窗口可能小于拥塞窗口。</p><hr><p>TCP的拥塞控制采用四种算法，即 满开始、拥塞避免、快充次、快恢复</p><p><strong>拥塞控制算法</strong></p><hr><p>-慢开始算法的思路是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是由小到大逐渐增加拥塞窗口的大小</p><hr><p>为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh状态变量。ssthresh的用法如下：当cwnd&lt;ssthresh时，使用慢开始算法。<br>当cwnd&gt;ssthresh时，改用拥塞避免算法。<br>当cwnd=ssthresh时，慢开始与拥塞避免算法任意</p><p><strong>拥塞避免算法</strong></p><p>拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。</p><p>无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。<img src="https://static01.imgkr.com/temp/7cc2d108c68f4e34aede20b3b453a6b0.jpg" alt="v2-f7db63b1f00cbd8170e1435616e06216_720w"></p><p>（1）拥塞窗口cwnd初始化为1个报文段，慢开始门限初始值为16<br>（2）执行慢开始算法，指数规律增长到第4轮，即cwnd=16=ssthresh，改为执行拥塞避免算法，拥塞窗口按线性规律增长<br>（3）假定cwnd=24时，网络出现超时（拥塞），则更新后的ssthresh=12，cwnd重新设置为1，并执行慢开始算法。当cwnd=12=ssthresh时，改为执行拥塞避免算法</p><h5 id="TCP三次握手"><a href="#TCP三次握手" class="headerlink" title="TCP三次握手"></a>TCP三次握手</h5><hr><p><img src="https://static01.imgkr.com/temp/391b3d19f2ae462d94e48745ecf2e477.png" alt="image-20201109202921191"></p><p>TCP的连接建立，我们常常称为三次握手。</p><p>A： 您好，我是A。</p><p>B：您好A，我是B。</p><p>A：您好B</p><p>为什么要三次，而不是两次？按说两个人打招呼，一来一回就可以了，为什么不是四次？</p><p>假设这个通路是非常不可靠的，A要发起一个连接，当发了第一个请求渺无音信的时候，会有很多的可能性，比如第一个请求包丢了，再如果没有丢，但是绕了弯路，超时了，还有B没有响应，不想和我连接。</p><p>A不能确认结果，于是再发，再发。终于有一个请求包到了B，但是请求包到了B的这个事情，目前A还是不知道，A还有可能再发。</p><p>B收到了请求包，就知道了A的存在，并且知道A要和它建立连接。如果B不愿意建立连接，则A会重试一阵后放弃，连接建立失败，没有是问题；如果B是乐意建立连接，则会发送应答包给A。</p><p>当然对于B来说，这个应答包也是一如网络深似海，不知道能不能到达A。这个时候B自然不能认为连接是建立好了，因为应答包仍然会丢，会绕弯路，或者A已经挂了都有可能。</p><p>而且这个时候B还能碰到一个诡异的现象就是，A和B原来建立了连接，做了简单的通信，结束了连接。还记得吗？ A建立连接的时候，请求包重复发了几次，有的请求包绕了一个大圈又回来了，B会认为这也是一个正常的请求话，因此建立了连接，可以想象这个连接会不会进行下去，也没有终结的时候，纯属单相思了。<strong>因而两次握手肯定不行。</strong></p><p>B发送的应答可能会发送很多次，但是只要一次到达A，A就认为连接已经建立了，因为对与A来说，他的消息有去有回。A会给B发送应答之应答，而B也在等这个消息，才能确认连接建立，只有等到了这个消息，对于B来讲，才算他的消息有去有回。</p><p>当然A发送给B的应答之应答也会丢，也会绕路，甚至B挂了。按理来说，还应该有个应答之应答之应答，这样下去没底了。所以四次握手是可以的，四十次都可以，关键四百次也不能保证就真的可靠了。只要双方的消息都有去有回，就基本可以了。</p><p>好在大部分情况下，A和B建立连接之后，A会马上发送数据的，一旦A发送数据，则很多问题都得到了解决。例如A发送给B的应答丢了，当A后续发送的数据到达的时候,B可以认为这个连接已经建立，或者B压根就挂了，A发送的数据，会报错，说B不可达，A就知道B出事情了。</p><p>当然你可以说A比较坏，就是不发数据，建立连接后空着。我们在程序设计的时候，可以要求开启keepalive机制，即使没有真实的数据包，也有探活包。</p><p>三次握手除了双方建立连接外，主要还是为了沟通一件事情，就是<strong>TCP包的序号问题。</strong></p><p>A要告诉B我这面发起的包的序号起始是从哪个号开始的，B同样也要告诉A，B发起的包的序号是从哪个号开始的。为什么序号都不能从1开始呢？因为这样往往会出现冲突。</p><p>例如，A连上B之后，发送了1，2，3三个包，但是发送3的时候，中间丢了，或者绕路了，于是重新发送，后来A掉线了，重新连上B后，序号又从1开始，然后发送2，但是压根没想发送3,但是上次绕路的那个3又回来了，发给了B，B自然认为，这就是下一个包，于是发送了错误。</p><p>因而，每个连接都要有不同的序号。这个序号的起始序号是随着时间变化的，可以看成一个32位的计数器，没4微秒加一，如果计算下，如果到重复，需要4个多小时，那个绕路的包早就死翘翘了，因为我们都知道IP包头里有个TTL，也即生存时间。</p><h5 id="TCP四次挥手"><a href="#TCP四次挥手" class="headerlink" title="TCP四次挥手"></a>TCP四次挥手</h5><p>A：啊，我不想玩了。</p><p>B：噢，你不想玩了我知道了。</p><p>这个时候，还只是A不想玩了，也即A不会再放松数据了，但是B能不能在ACK的时候直接关闭呢？当然不可以了，很有可能A是发完了最后的数据就准备不玩了，但是B还没做完自己的事情，还是可以发送数据的，所以称为半关闭的状态。</p><p>这个时候A可以选择不再接受数据了，也可以选择在接收一段数据，等待B也主动关闭。</p><p>B：A啊，好吧，我也不玩了，拜拜。</p><p>A：好的，拜拜。</p><p>这样整个连接就关闭了。但是这个过程有没有异常情况呢？当然有，上面是和平分手的场面。</p><p>A开始说 “不玩了”，B说“知道了”，这个回合没什么问题，因为在此前，双方还处于合作状态，如果A说“不玩了”，没有收到回复，则A会重新发送“不玩了”。但是这个回合结束之后，就有可能出现异常情况了，因为已经有乙方率先撕破脸。</p><p>一种情况是，A说完“不玩了”之后，直接跑路，是会有问题的，因为B还没有发起结束，而如果A跑路，B就算发起结束，也得不到回答，B就不知道该怎么办了。另一种情况，A说完“不玩了”，B直接跑路，也是有问题的，因为A不知道B是还有事情要处理，还是过一会儿会发送结束。</p><p><img src="https://static01.imgkr.com/temp/aa5a17546cf94df4bee9bce8a544e54e.png" alt="image-20201109204021605"></p><p>那怎么解决这些问题？TCP协议专门设计了几个状态来处理这些问题。</p><p>断开的时候，我们可以看到，当A说“不玩了”，就会进入 FIN_WAIT_1的状态，B收到“A不玩”的消息后，发送知道了，就进入CLOSE_WAIT的状态。</p><p>A收到“B说知道了”，就进入FIN_WAIT_2的状态，如果这个时候B直接跑路，则A将永远在这个状态。TCP协议里面并没有对这个状态的处理，但是Linux有，可以调整tcp_fin_timeout这个参数，设置一个超时时间。</p><p>如果B没有跑路，发送了“B也不玩了”的请求到达A是，A发送“知道B也不玩了”的ACK后，从FIN_WAIT_2状态结束，按说A可以跑路了，但是最后的这个ACK万一B收不到呢？则B会重新发送一个“B不玩了”，这个时候A已经跑路的话，B就在也收不到ACK了，因而TCP协议要求A最后等待一段时间TIME_WAIT，这个时间要足够长，长到如果B没收到ACK的话，“B说不玩了”会重发的，A会重新发一个ACK并且足够时间到达B。</p><p>A直接跑路还是有一个问题是，A的端口就直接空出来了，但是B不知道，B原来发送的很多的包还有可能在路上，如果A的端口被一个新的应用占用了，这个新的应用会受到上个连接B发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来B发送的所有的包都死翘翘了，再空处端口来。</p><p>等待的时间设为2MSL，MSL是Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为TCP报文基于是IP协议的，而IP头中有一个TTL域，是IP数据包可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值位0则数据包将被丢弃，同时发送ICMP报文通知源主机。协议规定MSL位2分钟，实际应用中常用的是30秒，1分钟和两分钟等。</p><p>还有一种情况就是，B超过了2MSL的时间，依然没有收到他发的FIN的ACK，怎么办呢？按照TCP的原理，B当然还会重发FIN，这个时候A再收到这个包之后，A就表示，我已经在这里等了这么长时间了，已经仁至义尽了，之后的我都不会认了。于是就直接发送RST，B就知道A早就跑路了。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机 </tag>
            
            <tag> 网络 </tag>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DNS协议</title>
      <link href="/2020/10/20/DNS%E5%8D%8F%E8%AE%AE/"/>
      <url>/2020/10/20/DNS%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<h3 id="DNS协议"><a href="#DNS协议" class="headerlink" title="DNS协议"></a>DNS协议</h3><h4 id="DNS服务器"><a href="#DNS服务器" class="headerlink" title="DNS服务器"></a>DNS服务器</h4><p>在网络世界中，你肯定记得住网站的名称，但是很难记住网站的IP地址，因而也需要一个地址簿，就是DNS服务器。</p><p>由此可见，DNS在日常生活中多么重要。每个人上网，都需要访问它，但是同时，这对它来讲也是非常大的挑战。一旦它出了故障，整个互联网都将瘫痪。另外，上网的人分布在全世界各地，如果大家都去同一个地方访问某一台服务器，时延将会非常大。因而，<code>DNS服务器，一定要设置成高可用、高并发和分布式的</code>。</p><p>于是就有了这样树状的层次结构。</p><p><img src="https://static01.imgkr.com/temp/63de54c0f60146e3b5f734d3c7a0fb73.png" alt="image-20201114200828449"></p><ul><li><p>根DNS服务器：返回顶级域DNS服务器的IP地址；</p></li><li><p>顶级域DNS服务器：返回权威DNS服务器的IP地址；</p></li><li><p>权威DNS服务器：返回相应主机的IP地址。</p></li></ul><h4 id="DNS解析流程"><a href="#DNS解析流程" class="headerlink" title="DNS解析流程"></a>DNS解析流程</h4><p>为了提高DNS的解析性能，很多网络都会就近部署DNS缓存服务器。于是，就有了以下的DNS解析流程。</p><ol><li>电脑客户端会发出一个DNS请求，问<code> www.163.com</code>的IP是啥，并发给<code>本地域名服务器（本地DNS）</code>。那本地域名服务器（本地DNS）是什么呢？如果是通过DHCP配置，本地DNS是由你的网络服务商，如电信、移动等自动分配，它通常在网络服务商的某个机房。</li><li>本地DNS收到来自客户端的请求。你可以想象这台服务器上缓存了一张域名与之对应IP地址的大表格。如果能找到<code>www.163.com</code>，它直接就返回IP地址。如果没有，本地DNS就回去问它的根域名服务器：“老大，能告诉我<code>www.163.com </code>的 IP地址吗？”根域名服务器是最高层次，全球共有13套。他不直接用于域名解析，但能指明一条道路。</li><li>根DNS收到来自本地DNS的请求，发现后缀是 .com ，说 ：“噢，<code>www.163.com</code> 啊，这个域名是由.com区域管理，我给你它的顶级域名服务器地址，你去问问它把。”</li><li>本地DNS转向问顶级域名服务器：“老二，你能告诉我<code>www.163.com</code>的IP地址吗？” 顶级域名服务器就是大名鼎鼎的比如.com、.net.、.org这些一级域名，它负责管理二级域名，比如163.com，所以他能提供一条更清晰的方向。</li><li>顶级域名服务器说：“我给你负责<code>www.163.com</code> 区域的权威DNS服务器的地址，你去问他应该能问道。”</li><li>本地DNS转向问权威DNS服务器：“您好，<code>www.163.com</code>对应的IP地址是啥？” 163.com的权威DNS服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</li><li>权威DNS服务器查询后将对应的IP地址告诉本地DNS。</li><li>本地DNS再将IP地址返回客户端，客户端和目标建立连接。</li></ol><p><img src="https://static01.imgkr.com/temp/d6601ca92b5341da92465570cd096614.png" alt="image-20201114202816067"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机 </tag>
            
            <tag> 网络 </tag>
            
            <tag> DNS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Http连接管理</title>
      <link href="/2020/10/20/HTPP%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86/"/>
      <url>/2020/10/20/HTPP%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="HTPP连接管理"><a href="#HTPP连接管理" class="headerlink" title="HTPP连接管理"></a>HTPP连接管理</h3><h4 id="短链接"><a href="#短链接" class="headerlink" title="短链接"></a>短链接</h4><p>HTTP 协议最初（0.9/1.0）是个非常简单的协议，通信过程采用了简单的“请求-= - 应答” 方式。</p><p>它底层的数据传输基于TCP/IP，每次发送请求前需要先于服务器建立连接，收到响应报文后立即关闭连接。</p><p>因为客户端与服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态，所以就被称为“<code>短链接</code>”。</p><p>短链接的缺点相当严重，因为在TCP协议里，建立连接和关闭连接都是非常“<code>昂贵</code> ” 的操作。TCP建立连接要有“<code>三次握手</code>”，发送3个数据包，需要一个RTT；关闭连接是“<code>四次挥手</code>”，需要2个RTT。</p><p>而 HTTP 的一次简单“请求 - 响应”通常只需要 4 个包，如果不算服务器内部的处理时间，最多是 2 个 RTT。这么算下来，浪费的时间就是“3÷5=60%”，有三分之二的时间被浪费掉了，传输效率低得惊人。</p><p><img src="https://static01.imgkr.com/temp/cbf74426ab20464cb9b60852afdb8005.png" alt="img"></p><p>单纯地从理论上讲，TCP 协议你可能还不太好理解，我就拿打卡考勤机来做个形象的比喻吧。</p><p>假设你的公司买了一台打卡机，放在前台，因为这台机器比较贵，所以专门做了一个保护罩盖着它，公司要求每次上下班打卡时都要先打开盖子，打卡后再盖上盖子。</p><p>可是偏偏这个盖子非常牢固，打开关闭要费很大力气，打卡可能只要 1 秒钟，而开关盖子却需要四五秒钟，大部分时间都浪费在了毫无意义的开关盖子操作上了。</p><p>可想而知，平常还好说，一到上下班的点在打卡机前就会排起长队，每个人都要重复“开盖 - 打卡 - 关盖”的三个步骤，你说着急不着急。</p><p>在这个比喻里，打卡机就相当于服务器，盖子的开关就是 TCP 的连接与关闭，而每个打卡的人就是 HTTP 请求，很显然，短连接的缺点严重制约了服务器的服务能力，导致它无法处理更多的请求。</p><h4 id="长连接"><a href="#长连接" class="headerlink" title="长连接"></a>长连接</h4><p>针对短链接暴露出的缺点，HTPP协议就提出了“<code>长连接</code>” 的通信方式，也叫<code>持久连接</code>、<code>连接保活</code>、<code>连接复用</code>。</p><p>其实解决办法也很简单，用的就是 “<code>成本均摊</code>” 的思路，既然TCP的连接和关闭非常耗时间，难么就把这个时间成本由原来的一个“<code>请求 - 应答</code>” 均摊到多个 “<code>请求 - 应答</code>” 上。</p><p><img src="https://static01.imgkr.com/temp/4671de88ec9e4c46a9db1eac6a57bcf3.png"></p><p>在短连接里发送了三次 HTTP“请求 - 应答”，每次都会浪费 60% 的 RTT 时间。而在长连接的情况下，同样发送三次请求，因为只在第一次时建立连接，在最后一次时关闭连接，所以浪费率就是“3÷9≈33%”，降低了差不多一半的时间损耗。显然，如果在这个长连接上发送的请求越多，分母就越大，利用率也就越高。</p><p>继续用刚才的打卡机的比喻，公司也觉得这种反复“开盖 - 打卡 - 关盖”的操作太“反人类”了，于是颁布了新规定，早上打开盖子后就不用关上了，可以自由打卡，到下班后再关上盖子。</p><p>这样打卡的效率（即服务能力）就大幅度提升了，原来一次打卡需要五六秒钟，现在只要一秒就可以了，上下班时排长队的景象一去不返，大家都开心。</p><h4 id="连接相关的头字段"><a href="#连接相关的头字段" class="headerlink" title="连接相关的头字段"></a>连接相关的头字段</h4><p>由于长连接对性能的改善效果非常显著，所以在HTTP/1.1 中的连接都会默认启用长连接。不需要用什么特殊的头字段指定，只要向服务器发送了第一次请求，后续的请求都会重复利用第一次打开的TCP连接，也就是长连接，在这个连接上收发数据。</p><p>当然，我们可以在请求头里明确地要求使用长连接机制，使用的字段是Connection，值是“keep-alive”。</p><p>不过不管客户端是否显示要求长连接，如果服务器支持长连接，他总会在响应报文里放一个“<code>Connection：keep-alive</code>” 字段，告诉客户端：“我是支持长连接的，接下来就用这个TCP连接一直收发数据吧”。</p><p>因为TCP连接长时间不关闭，服务器必须在内存里保存它的状态，这就占用了服务器的资源。如果有大量的空闲长连接只连不发，就会很快耗费服务器的资源，导致服务器无法为真正有需要的用户提供服务。</p><p>所以，长连接也需要在恰当的时间关闭，不能永远保持与服务器的连接，这在客户端或者服务器都可以做到。</p><p>在客户端，可以在请求头里加上“<code>Connection：close</code>”字段，告诉服务器：“这次通信后就关闭连接”。服务器看到这个字段，就知道客户端要主动关闭连接，于是在响应报文里也家伙是那个这个字段，发送之后就调用Socket API关闭TCP连接。</p><blockquote><p>服务器通常不会主动关闭连接，但也可以使用一些策略。拿Nginx来举例，它有两种方式：</p></blockquote><ol><li>使用“<code>keepalive_timeout</code>”  指令，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源。</li><li>使用“<code>keepalive_requests</code>” 指令，设置长连接上可发送的最大请求次数。比如设置成1000，那么但Nginx在这个连接上处理了1000个请求后，也会主动断开连接。</li></ol><h4 id="对头阻塞"><a href="#对头阻塞" class="headerlink" title="对头阻塞"></a>对头阻塞</h4><p>看完了短链接和长连接，接下来就要说到著名的 “队头阻塞”了。</p><p>“<code>队头阻塞</code>” 与短链接和长连接无关，而是由HTTP基本的 “请求 - 应答” 模型所导致的。</p><p>因为HTTP规定报文必须是 “一发一收”，这就形成了一个先进先出的 “串行” 队列。队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在前面的请求最优先处理。</p><p>如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得跟着一起等待，结果就是其他的请求承担了不应有的时间成本。</p><p><img src="https://static01.imgkr.com/temp/b460c2c9aba24ab7894a7a99039cfd0c.png"></p><p>还是用打卡机做个比喻。</p><p>上班的时间点上，打击都在排队打卡，可这个时候偏偏在最前面的那个人遇到了打卡机故障，怎么也不能打卡成功，急得满头大汗。等找人把打卡机修好，后面排队的所有人全吃了。</p><h4 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h4><p>因为“请求 - 应答” 模型不能变，所以“对头阻塞” 问题在HTPP/1.1 里无法解决，只能<strong>缓解</strong>，有什么办法呢？</p><p>公司里可以在多买几台打卡机放在前台，这样大家可以不用挤在一个队伍里，分散打卡，一个队伍偶尔阻塞也不要紧，可以改换到其他不阻塞的队伍。</p><p>这在HTTP里就是“<code>并发连接</code>”，也就是同时对一个域名发起多个长连接，用数量来解决质量的问题。</p><p>但这种方式也存在缺陷。如果每个客户端都想自己快，建立很多个连接，用户数 × 并发数就会是天王数字。服务器的资源根本扛不住，或者被服务器认为是而已攻击，反而会造成 “拒绝服务”。</p><p>所以，HTTP协议建议客户端使用并发，但不能 “<code>滥用</code>” 并法。RFC2616里明确限制每个客户端最多并发2个连接。不过时间证明这个数字实在是太小了，众多浏览器都无视标准，把这个上限提高了到了6~8。后来修订的RFC7230也就“顺水推舟”，取消了这个“2” 的限制。</p><p>但“<code>并发连接</code>” 所压榨出的性能也跟不上高速发展的互联网无无止境的需求，还有别的什么办法吗？</p><p>公司发展的太快了，员工越来越多，上下班打卡成了迫在眉睫的大问题。前台空间有限，放不下更多的打卡机了，怎么办？那就多开几个打卡的地方，每个楼层、办公区的入口也放上三四台打卡机，把人进一步分流，不要都往前台挤。</p><p>这个就是 <strong>“<code>域名分片（domain sharding）</code>”</strong> 技术，还是用数量来解决质量的思路。</p><p>HTPP协议和浏览器不是限制并发连接数量吗？好，那我就多开几个域名，比如shard1.chrono.com、shard2.chrono.com，而这些域名都指向同一台服务器，这样实际长连接的数量就又上去了，真是美滋滋。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul><li>早期的HTTP协议使用短链接，收到响应后就立即关闭连接，效率很低；</li><li>HTTP/1.1 默认启用长连接，在一个连接上收发多个请求响应，提高了传输效率；</li><li>服务器会发送“<code>Connection: keep-alive</code>” 字段表示启用了长连接；</li><li>报文头里如果有 “<code>Connection: close</code>”  就意味着长连接即将关闭；</li><li>过多的长连接会占用服务器资源，所以服务器会用一些策略有选择地关闭长连接；</li><li>“<code>对头阻塞</code>” 问题会导致性能下降，可以用 “<code>并发连接</code>” 和 “<code>域名分片</code>”  的技术缓解。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机 </tag>
            
            <tag> 网络 </tag>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP协议</title>
      <link href="/2020/10/20/HTTP%E5%8D%8F%E8%AE%AE/"/>
      <url>/2020/10/20/HTTP%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<h4 id="HTTP-是什么"><a href="#HTTP-是什么" class="headerlink" title="HTTP 是什么"></a>HTTP 是什么</h4><hr><p>先看下一下HTTP的名字：“超文本传输协议”，它可以拆成三个部分，分别是：“超文本”，“传输” 和 “协议”。</p><ul><li>协议：HTTP是在一个用在计算机世界里的协议。它使用计算机能够理解的语言确立了一种计算机之间交流通信的规范，以及相关的各种控制和错误处理的方式。</li><li>HTTP是在一个计算机世界里专门用来再两点之间传输数据的约定和规范。</li><li>所谓“文本”，就表示HTTP传输的不是TCP/UDP这些底层协议里被切分的杂乱无章的二进制包，而是完整的、有意义的数据，可以被浏览器、服务器这样的上层应用程序处理，所谓“超文本”，就是“超越了普通文本的文本”，它是文字、图片、音频、视频的混合体，最关键的是含有“超链接”，能够从一个“超文本”跳跃到另一个“超文本”，形成复杂的非线性、网状的结构关系。</li></ul><p><strong>HTTP是一个在计算机世界里专门在两点之间传输文字、图片、音频、视频等超文本数据的约定和规范。</strong></p><h3 id="报文结构"><a href="#报文结构" class="headerlink" title="报文结构"></a>报文结构</h3><p>HTTP 协议的请求和相应报文的结构基本相同，由三大部分组成：</p><ol><li>起始行（start line）：描述请求或响应的基本信息；</li><li>头部字段集合（header）：使用key-value形式更详细地说明报文；</li><li>消息正文（entity）：实际传输的数据，它不一定是纯文本，可以是图片，视频等二进制数据。</li></ol><p>这其中前两部分其实行和头部字段经常又合称为 “<strong>请求头</strong>” 或 “<strong>响应头</strong>”，消息正文又称为“实体”，但与“header对应”，很多时候就直接称为“<strong>body</strong>”。</p><p>HTTP协议规定报文必须有header，但可以没有body，而且在headr之后必须要有一个“空行”，也就是“CRLF”，十六进制的“0D0A”。</p><p>完整的HTTP报文就像是下图的这个样子：</p><p><img src="https://static01.imgkr.com/temp/03ab4cbf26084476a9ef0854d3823b79.png" alt="image-20201112174427780"></p><p><img src="https://static01.imgkr.com/temp/f5741b0fa17341a1826aea163144485f.png" alt="image-20201112192843966"></p><p>第一行 “GET / HTTP/1.1” 就是请求行，而后面的 “host”  “Connection” 等等都属于header，报文的最后是一个空白行结束，没有body</p><p>在很多时候，特别是浏览器发送GET请求的时候都是这样，HTTP报文经常是只有header而没有body。</p><h4 id="请求行"><a href="#请求行" class="headerlink" title="请求行"></a>请求行</h4><p><strong>请求行简要的描述了客户端想要如何操作服务器端的资源。</strong></p><p>请求行由三部分构成：</p><ol><li>请求方法：是一个动词，如GET/POST，表示对资源的操作；</li><li>请求目标：通常是一个URI，标记可请求方法要操作的资源；</li><li>版本号：表示报文使用的HTTP协议版本。</li></ol><p>这三个部分通常使用空格（space）来分隔，最后要用CRLF换行表示结束</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">GET</span> <span class="string">/</span> HTTP/1.1</span><br></pre></td></tr></table></figure><p>在这个请求行里，”GET“ 是请求方法，”/“是请求目标，”HTTP/1.1“ 是版本号，把这三部分连起来，意思就是”服务器你好，我想获取网站根目录下的默认默认文件，我用的协议版本号是1.1，请不要用1.0或者2.0回复我“。</p><h4 id="状态行"><a href="#状态行" class="headerlink" title="状态行"></a>状态行</h4><p><strong>状态行的意思是服务器响应的状态。</strong></p><p>比起请求行来说，状态行要简单一些，同样也是由三部分构成：</p><ol><li><p>版本号：表示报文使用的HTTP协议版本；</p></li><li><p>状态码：一个三位数，用代码形式表示处理的记过，比如200是成功，500是服务器错误；</p></li><li><p>原因：作为数字状态码补充，是更详细的解释文字，帮助人理解原因。</p></li></ol><p><img src="https://static01.imgkr.com/temp/1d766b5420074c4e8f441cfae5d4b191.png" alt="image-20201112194612463"></p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 <span class="number">200</span> OK</span><br></pre></td></tr></table></figure><p>意思就是：”浏览器你好，我已经处理完了你的请求，这个报文使用的协议版本号是1.1，状态码是200，一切OK“</p><figure class="highlight http"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">HTTP/1.1 <span class="number">404</span> NOT Found</span><br></pre></td></tr></table></figure><p>翻译成人话就是：”抱歉浏览器，刚才你的请求收到了，但我没找到你想要的资源，错误代码是404，接下来的事情你看着办吧。“</p><h4 id="头部字段"><a href="#头部字段" class="headerlink" title="头部字段"></a>头部字段</h4><p>请求行或状态行再加上头部字段集合就构成了HTTP报文里完整的请求头或响应头。</p><p><img src="https://static01.imgkr.com/temp/477e9dd163aa458b947dbb073b385846.png"></p><p><img src="https://static01.imgkr.com/temp/a8eb8a31f6a34cf787f840cd99f8a63b.png"></p><p>请求头和响应头的结构基本一样的，唯一的区别是起始行。</p><p>头部字段是key-value的形式，key和value之间用 “:”分割，最后用CRLF换行表示字段结束。比如在”Host：127.0.0.1“ 这一行里key就是”Host“，value就是”127.0.0.1“。</p><p>HTTP头部字段非常灵活，不仅可以使用标准里的Host、Connection等已有头，也可以任意添加自定义头，这就给HTTP协议带来了无限的可能。</p><h4 id="常用头字段"><a href="#常用头字段" class="headerlink" title="常用头字段"></a>常用头字段</h4><p>HTTP协议规定了非常多的头部字段，实现各种各样的功能，但基本上可以分为四大类：</p><ol><li>通用字段：在请求头和响应头里都可以出现；</li><li>请求字段：仅能出现在请求头里，进一步说明请求信息或者额外的附加条件；</li><li>响应字段：仅能出现在响应头里，补充说明响应报文的信息；</li><li>实体字段：它实际上属于通用字段，但专门描述body的额外信息。</li></ol><p>对HTTP报文的解析和处理实际上主要就是对头部字段的处理，理解了头部字段也就理解了HTTP报文。</p><p>首先要说的就是Host字段，它属于请求字段，只能出现在请求头里，他同时也是唯一一个HTTP/1.1规范里要求<strong>必须出现</strong> 的字段，也就是说，如果请求头里没有Host，拿着就是一个错误的报文。</p><p><strong>Host</strong> 字段告诉服务器这个请求应该由哪个主机来处理，当一台计算机上托管了多个虚拟主机的时候，服务器端就需要用Host来选择，有点像是一个简单的”路由重定向“。</p><p><strong>User-Agent</strong> 是请求字段，只出现在请求头里。它使用一个字符串来米描述发起HTTP请求的客户端，服务器可以依据他来返回最合适此浏览器显示的页面。</p><p>但由于历史原因，User-Agent非常混乱，每个浏览器都自称是”Mozilla“ ”Chrome“ “Safari”，企图使用这个字段来互相伪装，导致User-Agent变得越来越长，最终变得毫无意义。</p><p><strong>Date</strong>字段是一个通用字段，但通常出现在响应头里，表示HTTP报文创建时间，客户端可以使用这个时间再搭配其他字段决定缓存策略。</p><p><strong>Server</strong> 字段是响应字段，只能出现在响应头里。他告诉客户端当前正在提供Web服务的软件名称个版本号，例如： ”Server：openresty/1.15.8.1“</p><p>Server字段也不是必须要出现的，因为这会把服务器的一部分信息暴露给外界，如果这个版本恰好存在bug，那么黑客就有可能利用bug攻陷服务器。所以，由的网站响应头里要么没有这个字段，要么就给出一个完全无关的描述信息。</p><p>比如GitHub，它的Server字段里就看不出是使用了Apache还是Nginx，他只显示为 ”GitHub.com“。</p><p>实体字段里要说的一个是<strong>Content-Length</strong> ，它表示报文里body的长度，也就是请求头或响应头空行后面数据的长度。</p><h4 id="请求方法"><a href="#请求方法" class="headerlink" title="请求方法"></a>请求方法</h4><blockquote><p>目前<code>HTTP/1.1</code>规定了八种方法，单词都必须是大写的形式</p></blockquote><ul><li><p>GET：获取资源，可以理解为读取或者下载数据；</p></li><li><p>HEAD：获取资源的元信息；</p></li><li><p>POST：向资源提交数据，选当与写入或者上传数据；</p></li><li><p>PUT：类似POST；</p></li><li><p>DELETE：删除资源；</p></li><li><p>CONNECTION：建立特殊的连接隧道；</p></li><li><p>OPTIONS：列出可对资源实行的方法；</p></li><li><p>TRACE：追踪请求 - 响应的传输路径</p><h6 id="安全与幂等"><a href="#安全与幂等" class="headerlink" title="安全与幂等"></a>安全与幂等</h6><p>在HTTP协议里，所谓的“<code>安全</code>”是指请求方法不会”破坏”服务器上的资源，即不会对服务器上的资源造成实质的修改。</p><p>按照这个定义，只有GET和HEAD方法是“<code>安全</code>” 的，因为他们是“<code>只读</code>”操作，只要服务器不故意曲解请求方法的处理方式，无论GET和HEAD操作多少次，服务器上的数据都是安全的。</p><p>而POST/PUT/DELETE操作会修改服务器上的资源，增加或删除数据，所以是不“<code>不安全</code>”的。</p><p>所谓的“<code>幂等</code>”实际上是一个数学用语，被借用到了HTTP协议里，意思是多次执行相同的操作，结果也都是相同的，即多次”幂”后结果“相等”。</p><p>很显然，GET和HEAD既是安全的也是幂等的，DELETE可以多次删除同一个资源，效果都是“资源不存在”，所以也是幂等的。</p><p>POST和PUT的幂等性质就略费解一点。</p><p>按照RFC里的语义，POST是“新增或提交数据“，多次提交数据会创建多个资源，所以不是幂等的；而PUT是”替换或更新数据“，多次更新一个资源，资源还是会第一次更新的状态，所以是幂等的。</p><p><code>建议</code></p><p>对比SQL来加深理解：把POST理解成INSERT，把PUT理解成UPDATE，这样就很清楚了。多次INSET会添加多条记录，而多次UPDATE只会操作一次记录，而且效果相同。</p></li></ul><h4 id="URI"><a href="#URI" class="headerlink" title="URI"></a>URI</h4><blockquote><p>URI：统一资源标识符（Uniform Resource Identifier）。因为它经常出现在浏览器的地址栏里，所以俗称为“网络地址”，简称“网址”。</p></blockquote><p>严格地说，URI不完全等同于网址，它包含有URL和URN两个部分，在HTTP世界里用的网址实际上是URL：<code>统一资源定位符（Uniform Resource Locator）</code>。但因为URL实在是太普及了，所以常常把这两者简单地视为相等。</p><p><img src="https://static01.imgkr.com/temp/23e3cbd12ac3425b84a04c7ab03db082.png" alt="img"></p><ol><li><p>scheme：翻译成中文叫<code>方案名</code> 或者 <code>协议名</code>，表示资源应该使用哪种协议来访问，最长见的就是http，另外还有<code>https</code>、<code>ftp</code>、<code>file</code>。</p></li><li><p>scheme之后，必须是三个特定的字符<code>://</code>，它把scheme和后面的部分分离开。</p></li><li><p>://之后被称为<code>authority</code>，表示资源所在的主机名，通常的行驶时“host:post”，即主机名加端口号。</p></li><li><p>path：用来标记资源所在位置的path，浏览器就可以链接服务器访问资源了。</p></li><li><p>query：查询参数，在path之后，用一个“？”开始，但不包含“？”，表示对资源附加额外要求，它有一套自己的格式，是多个“key=value”的字符串，这些KV值用字符串“&amp;”连接。</p></li></ol><h4 id="响应状态码"><a href="#响应状态码" class="headerlink" title="响应状态码"></a>响应状态码</h4><ul><li>响应状态码在响应报文里表示了服务器对请求的处理结果；</li><li>状态码后的原因短语是简单的文字描述，可以自定义；</li><li>状态码是十进制的三位数，分为五类，从100到599</li><li><code>2xx</code> 类状态码表示成功，常用的有<code>200</code>、<code>204 No Content 表示响应头后面没有body数据</code> 、<code>206</code>；</li><li><code>3xx</code> 类状态码表示重定向，常用的有<code>301</code> 、<code>302</code>、<code>304</code>；</li><li><code>4xx</code> 类状态码表示客户端错误，常用的有 <code>400 Bad Request 通用的错误码</code> 、<code>403 Forbidden 服务器表示禁止访问资源</code>、<code>404 NOT Found 资源在服务器上未找到</code>；</li><li><code>5xx</code> 类状态码表示服务端错误，常用的有 <code>500</code>、<code>501</code>、<code>502</code>、<code>503</code>；</li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><ul><li><p><code>HTTP</code> 报文结构就像是“大头儿子”，由“起始行 + 头部 + 空行 + 实体”组成，简单地说就是“<code>header+body</code>”；</p></li><li><p><code>HTTP</code> 报文可以没有 <code>body</code>，但必须要有 <code>header</code>，而且 <code>header</code> 后也必须要有空行，形象地说就是“大头”必须要带着“脖子”；</p></li><li><p>请求头由“请求行 + 头部字段”构成，响应头由“状态行 + 头部字段”构成；</p></li><li><p>请求行有三部分：请求方法，请求目标和版本号；</p></li><li><p>状态行也有三部分：版本号，状态码和原因字符串；</p></li><li><p>头部字段是 <code>key-value</code> 的形式，用“<code>:</code>”分隔，不区分大小写，顺序任意，除了规定的标准头，也可以任意添加自定义字段，实现功能扩展；</p></li><li><p><code>HTTP/1.1</code> 里唯一要求必须提供的头字段是 <code>Host</code>，它必须出现在请求头里，标记虚拟主机名；</p></li><li><p>请求方法是客户端发出的、要求服务器执行的，对资源的一种操作；</p></li><li><p>请求方法是对服务器的”指示“，真正应如何处理由服务器来决定；</p></li><li><p>最常用的请求方法是GET和POST，分别是获取数据和发送数据；</p></li><li><p>HEAD方法是轻量级的GET，用来获取资源的元信息；</p></li><li><p>PUT基本上是POST的同义词，多用于更新数据；</p></li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机 </tag>
            
            <tag> 网络 </tag>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP的Cookie机制</title>
      <link href="/2020/10/20/HTTP%E7%9A%84Cookie%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/10/20/HTTP%E7%9A%84Cookie%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h3 id="HTTP的Cookie机制"><a href="#HTTP的Cookie机制" class="headerlink" title="HTTP的Cookie机制"></a>HTTP的Cookie机制</h3><h4 id="Cookie的工作过程"><a href="#Cookie的工作过程" class="headerlink" title="Cookie的工作过程"></a>Cookie的工作过程</h4><p>当用户通过浏览器第一次访问服务器的时候，服务器肯定不知道他的身份的。所以，就要创建一个独特的身份标识数据，格式是 “<code>key=value</code>”，然后放进<code>Set-Cookie</code>字段里，随着响应报文一同发给浏览器。</p><p>浏览器收到响应报文，看到里面有<code>Set-Cookie</code>，就知道这是服务器给的身份标识，于是就保存起来，下次请求的时候就自动把这个值放进<code>Cookie</code>字段里发给服务器。</p><p>因为第二次请求里面有了<code>Cookie</code>字段，服务器就知道这个用户不是新人，之前来过，就可以拿出Cookie里的值，识别出用户的身份，然后提供个性化的服务。</p><p>不过因为服务器的 “<code>记忆能力</code>” 实在是太差，一张小纸条经常不够用。所以，服务器有时会在响应头里添加多个 <code>Set-Cookie</code>，存储多个 “<code>key=value</code>”。但浏览器这边发送时不需要多个<code>Cookie</code>字段，只需要在一行里用 “<code>;</code>” 隔开就行。</p><p><img src="https://static01.imgkr.com/temp/8cc8f3668a994f2eb3425a30c1ce04a3.png" alt="img"></p><p>从这张图中我们也能够看到，Cookie是由浏览器负责存储的，而不是操作系统。所以，他是”浏览器绑定“ 的，只能在本浏览器内生效。</p><p>如果你换个浏览器或者换台电脑，新的浏览器里没有服务器对应的Cookie，就好像时脱掉了贴着纸条的衣服，”健忘“ 的服务器也就认不出来了，只能再走一遍Set-Cookie 流程。</p><p>Cookie的属性</p><p>说到这里，你应该知道了，Cookie就是服务器委托浏览器存储在客户端里的一些数据，而这些数据通常都会记录用户的关键识别信息。所以，就需要在“<code>key=value</code>” 外再用一些手段来保护，防止外泄或窃取，这些手段就是Cookie的属性。</p><p><img src="https://static01.imgkr.com/temp/e1b21f941464457398ba971f5283518f.png"></p><p>首先，我们应该<code>设置Cookie的生存周期</code>，也就是它的有效期，让他只能在一段时间内可用，就像是食品的“保鲜期”，一旦超时这个期限浏览器就认为时Cookie失效，在存储里删除，也不会发送给服务器。</p><p>Cookie的有效期可以使用Expires 和 Max-Age 两个属性来设置。</p><p>“<code>Expires</code>” 俗称 “过期时间”，用的时绝对的时间点，可以理解为“截止日期”。“<code>Max-Age</code>” 用的时相对时间，单位时秒，浏览器用收到报文的时间点再加上Max-Age，就可以得到失效的绝对时间。</p><p>Expires 和 Max-Age 可以同时出现，两者的失效时间可以一致，也可以不一致，当浏览器会优先采用Max-Age计算失效期。</p><p>比如在这个例子里，Expires 标记的过期时间是“GMT 2019 年 6 月 7 号 8 点 19 分”，而 Max-Age 则只有 10 秒，如果现在是 6 月 6 号零点，那么 Cookie 的实际有效期就是“6 月 6 号零点过 10 秒”。</p><p>其次，我们需要“<code>设置Cookie的作用域</code>”，让浏览器仅发送给特定的服务器和URI，避免被其他网站盗用。</p><p>作用域的设置比较简单，“<code>Domain</code>” 和 ”<code>Path</code>“ 指定了Cookie所属的域名和路径，浏览器在发送Cookie前会从URI中提取出host和path部分，比对Cookie的属性。如果不满足条件，就不会在请求头里发送Cookie。</p><p>最后要考虑的就是”<code>Cookie的安全性了</code>“，尽量不要让服务器意外的人看到。</p><p>写过前端的同学一定知道，在JS脚本里可以用document.cookie来读写Cookie数据，这就带来了安全隐患，有可能会导致”跨站脚本“（XSS）攻击窃取数据。</p><p>属性 ”<code>HttpOnly</code>“ 会告诉浏览器，此Cookie只能通过浏览器HTTP协议传输，禁止其他方式访问，浏览器的JS引擎就会禁用document.cookie等一切相关的API，脚本攻击也就无从谈起了。</p><p>另外一个属性 ”<code>SameSite</code>“ 可以防范 ”<code>跨站请求伪造</code>“（CSRF）攻击，设置成 ”SameSite=Strict“ 可以严格限定Cookie不能随着跳转连接跨站发送，而”<code>SameSit=Lax</code>“ 则略宽松一点，允许GET/HEAD等安全方法，但禁止POST跨站发送。</p><p>还有一个属性叫 ”Secure“，表示这个Cookie仅能用HTTPS协议加密传输，明文的HTTP协议会禁止发送。但Cookie本身不是加密的，浏览器里还是以明文的形式存在。</p><h4 id="Cookie的应用"><a href="#Cookie的应用" class="headerlink" title="Cookie的应用"></a>Cookie的应用</h4><p>现在我们回到最开始的话题，有了Cookie，服务器就有了 “<code>记忆能力</code>”，能够保存“状态”，那么应该如何使用Cookie呢？</p><p>Cookie最基本的一个用途就是<code>身份识别</code>，保存用户的登录信息，实现会话事务。</p><p>比如，你用账号和密码登录某电商，登录成功后网站服务器就会发给浏览器一个Cookie，内容大概是“<code>name=yourid</code>”，这样就成功地把身份标签贴在了你身上。</p><p>之后你在网站里面随便访问哪件商品的页面，浏览器都会自动把身份Cookie发送给服务器，所以服务器总会知道你的身份，一方面免去了重复登陆的麻烦，另一方面也能够自动记录你的浏览记录和购物下单（在后台数据库或者也用Cookie），实现了 “<code>状态保持</code>”。</p><p>Cookie的另一个常见用途就是<code>广告追踪</code>。</p><p>你上网的时候肯定看过很多的广告图片，这些图片背后都是广告商网站（例如Google），他会“偷偷地” 给你贴上Cookie小纸条，这样你上其他地网站，别地广告就能能用Cookie读出你的身份，然后做行为分析，再推给你广告。</p><p>这种Cookie不是由访问地主站存储地，所以又叫 “第三方Cookie”。如果广告商势力很大，广告到处都是，那么就比较“恐怖”了，无论你走到哪里他都会通过Cookie认出你来，实现广告“精准打击”。</p><p>为了防止滥用Cookie搜集用户隐私，互联网组织相继提出了DNT（Do Not Track）和 P3P，但实际作用不大。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul><li>Cookie 是服务器委托浏览器存储地一些数据，让服务器有了 “记忆能力”；</li><li>响应报文使用Set-Cookie字段发送 “key=value” 形式的Cookie值；</li><li>请求报文里用地Cookie字段发送多个Cookie值；</li><li>为了保护Cookie，还要给他设置有效期、作用域等属性，常用的由Max-Age、Expires、Domain、HttpOnly等；</li><li>Cookie最基本的用途是身份识别，实现有状态的会话事务。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机 </tag>
            
            <tag> 网络 </tag>
            
            <tag> HTTP </tag>
            
            <tag> Cookie </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络体系</title>
      <link href="/2020/10/19/%E8%AE%A1%E7%AE%97%E7%BA%A7%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/"/>
      <url>/2020/10/19/%E8%AE%A1%E7%AE%97%E7%BA%A7%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h3 id="计算级网络总结"><a href="#计算级网络总结" class="headerlink" title="计算级网络总结"></a>计算级网络总结</h3><h3 id="OSI-参考模型"><a href="#OSI-参考模型" class="headerlink" title="OSI 参考模型"></a>OSI 参考模型</h3><ul><li><p>OSI 参考模型是又国际标准组织（ISO）于1984年提出的分层网络体系结构模型，共分为七层结构，每层完成特定的网络功能。</p><p><img src="https://static01.imgkr.com/temp/2b44d748e33844ee9dd86b2a2458644e.png"></p></li></ul><ul><li><p>OSI参考模型的通信过程</p><p><img src="https://static01.imgkr.com/temp/61a852b45d164ea7ae8d571cc181adef.png" alt="image-20201018162458038"></p></li></ul><ul><li><p>OSI 参考模型的数据通信过程</p><p><img src="https://static01.imgkr.com/temp/1ad7e39cb7ce42768c8328bf179f7554.png" alt="image-20201018162613073"></p></li></ul><ul><li>为什么需要数据封装<ul><li>增加控制信息：每层都会给用户数据增加对应的头生成对应的协议数据单元（PDU）</li><li>控制信息主要包括<ul><li>地址（Address）：标识发送端和接收端</li><li>用于差错检测编码</li><li>协议控制：实现协议功能的附加信息，如: 优先级（priority）、服务质量（QoS）、 和安全控制等 </li></ul></li></ul></li></ul><h4 id="物理层"><a href="#物理层" class="headerlink" title="物理层"></a>物理层</h4><h6 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h6><p><img src="https://static01.imgkr.com/temp/965cb3dfb69c41dd92fcf40cd3a2c31f.png" alt="image-20201018165057660"></p><p>实现每一个比特的传输。</p><h6 id="通信方式"><a href="#通信方式" class="headerlink" title="通信方式"></a>通信方式</h6><p>根据信息在传输线上的传送方向，分为以下三种通信方式：</p><ul><li>单工通信：单向传输  例： 电视台与电视</li><li>半双工通信：双向交替传输  例：对讲机</li><li>全双工通信：双向同时传输 </li></ul><h4 id="数据链路层"><a href="#数据链路层" class="headerlink" title="数据链路层"></a>数据链路层</h4><p><img src="https://static01.imgkr.com/temp/cef2ba82d46f4097a616b864b168ddcf.png" alt="image-20201018165137817"></p><ul><li><p>负责结点-结点（node-to-node）的数据传输</p></li><li><p>组帧：将网络层传输下来的分组添加首部和尾部，用于标记帧的开始和结束</p></li><li><p>物理寻址： 物理层没办法完成寻址，数据链路层在帧头部加入物理地址标识数据</p><p>​    <img src="https://static01.imgkr.com/temp/47b597db1e1144778da75ea5dd396afe.png" alt="image-20201018170157118"></p></li><li><p>差错控制： 检测并重传损失帧或丢失帧，避免重复帧</p></li><li><p>流量控制：降低接收端和发送端传输速度差，避免淹没发送端</p></li></ul><h4 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h4><p><img src="https://static01.imgkr.com/temp/1bcf1cb3184d4373aba5b28a1b2332b2.png" alt="image-20201019212313385"></p><h6 id="功能-1"><a href="#功能-1" class="headerlink" title="功能"></a>功能</h6><ul><li><p>负责源主机到目的主机数据分组</p><ul><li>可能穿越多个网络</li></ul></li><li><p>逻辑寻址</p><ul><li>全局唯一逻辑地址，确保数据分组被送达目的主机，如IP地址。</li></ul></li><li><p>路由</p><ul><li>路由器互联网络，并路由分组至最终目的地</li><li>路径选择</li></ul></li><li><p>分组转发</p></li></ul><p><img src="https://static01.imgkr.com/temp/832c0373a57c48538b4ff0714e1bd825.png" alt="image-20201019212615562"></p><h4 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h4><h6 id="功能-2"><a href="#功能-2" class="headerlink" title="功能"></a>功能</h6><p><img src="https://static01.imgkr.com/temp/72e03f1a755d49efb3708fe22db93fc1.png" alt="image-20201019212652451"></p><ul><li><p>负责源-目的（端到端）（进程间）完整的报文传输</p></li><li><p>分段与重组</p></li><li><p>SAP寻址</p><ul><li>确保将完整报文提交给正确进程，如端口号：</li></ul></li></ul><p><img src="https://static01.imgkr.com/temp/35bc08e80bbb448491ab709bcc22960e.png" alt="image-20201019212855262"></p><ul><li><p>连接控制：负责端到端的连接建立，维护，拆除。</p></li><li><p>流量控制：解决端到端的流量控制，负责匹配两端传输速度。</p></li><li><p>差错控制</p></li></ul><h4 id="会话层"><a href="#会话层" class="headerlink" title="会话层"></a>会话层</h4><p>  <img src="https://static01.imgkr.com/temp/40c9bd08213e4080b4d68b3f730b9330.png" alt="image-20201019221011219"></p><h6 id="功能-3"><a href="#功能-3" class="headerlink" title="功能"></a>功能</h6><ul><li>对话控制</li><li>同步： 在数据流中插入 同步点</li><li>是最薄的一层</li></ul><h4 id="表示层"><a href="#表示层" class="headerlink" title="表示层"></a>表示层</h4><p><img src="https://static01.imgkr.com/temp/1340b0ab60b04614a472c437aae6c709.png" alt="image-20201019221148901"></p><h6 id="功能-4"><a href="#功能-4" class="headerlink" title="功能"></a>功能</h6><ul><li><p>数据表示转化</p><ul><li>转换为主机独立的编码</li></ul></li><li><p>加密/解密</p></li><li><p>压缩/解压缩</p></li></ul><h4 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h4><p>  <img src="https://static01.imgkr.com/temp/fdf8d8c3500b4dff8cb2c3169179c303.png" alt="image-20201019221516060"></p><h6 id="功能-5"><a href="#功能-5" class="headerlink" title="功能"></a>功能</h6><ul><li><p>支持用户通过用户代理（如浏览器）或网络接口使用网络（服务）</p></li><li><p>典型的应用层服务：</p><ul><li>文件传输（FTP）</li><li>电子邮件（SMTP）</li><li>Web（HTTP）</li></ul></li></ul><h3 id="TCP-IP模型"><a href="#TCP-IP模型" class="headerlink" title="TCP/IP模型"></a>TCP/IP模型</h3><p><img src="https://static01.imgkr.com/temp/36981dbe707a49fba482528afb19f755.png" alt="image-20201019221916512"></p><h4 id="五层参考模型"><a href="#五层参考模型" class="headerlink" title="五层参考模型"></a>五层参考模型</h4><ol><li>综合了OIS和TCP/IP的优点</li><li>应用层：支持各种网络应用，FTP，SMTP，HTTP</li><li>传输层：进程-进程的数据传输，TCP，UDP </li><li>网络层：源主机到目的主机的数据分组路由与转发，IP协议、路由协议等</li><li>链路层：相邻网络元素（主机、交换机、路由器）的数据传输。</li><li>物理层：比特传输</li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机 </tag>
            
            <tag> 网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🧔Mysql索引</title>
      <link href="/2020/09/04/MySql%20%E7%B4%A2%E5%BC%95%E6%A6%82%E8%A7%88/"/>
      <url>/2020/09/04/MySql%20%E7%B4%A2%E5%BC%95%E6%A6%82%E8%A7%88/</url>
      
        <content type="html"><![CDATA[<h3 id="索引是万能的吗？"><a href="#索引是万能的吗？" class="headerlink" title="索引是万能的吗？"></a>索引是万能的吗？</h3><p>首先要了解什么是索引(index)。数据库中的索引，就好比一本书的目录，它可以帮我们快速进行特定值的定位与查找，从而加快数据查询的效率。</p><p>索引就是帮助数据库管理系统搞笑获取数据的数据结构。</p><p>索引不是万能的，在有些情况下使用索引反而会让效率变低。</p><p>在数据表中的数据行数比较少的情况下，比如不到1000行，是不需要创建索引的。另外，当数据重复度大，比如高于10%的时候，也不需要对这个字段创建索引。</p><h3 id="索引的种类有哪些"><a href="#索引的种类有哪些" class="headerlink" title="索引的种类有哪些"></a>索引的种类有哪些</h3><p>从功能逻辑上说，索引主要有4种，分别是普通索引、唯一索引、主键索引和全文索引。</p><p>普通索引是基础的索引，没有任何约束，主要用于提高查询效率。唯一索引就是在普通索引的基础上增加了数据唯一性的约束，在一张数据表里可以有多个唯一索引。主键索引在唯一索引的基础上增加了不为空的约束，也就是NOT NULL + UNIQUE，一张表里最多只有一个主键索引。全文索引用的不多，MySQL自带的全文索引只支持英文。我们通常可以采用专门的全文搜索引擎，比如ES。</p><p>其实前三种索引（普通索引，唯一索引，主键索引）都是一类索引，只不过对数据的约束性逐渐提升。在一张数据表中只能有一个主键索引，这是由主键索引的物理方式决定的，因为数据存储在文件中只能按照一种顺序进行存储。但可以有多个普通索引或多个唯一索引。</p><p>按照物理实现方式，索引可以分为2种：聚集索引和非聚集索引。我们也可以把非聚集索引称为二级索引或者辅助索引。</p><h4 id="聚集索引"><a href="#聚集索引" class="headerlink" title="聚集索引"></a>聚集索引</h4><p>聚集索引可以按照主键来排序存储数据，这样在查找行的时候非常有效。举个例子，如果是一本汉语字典，我们想要查找“数”这个字，直接在书中找汉语拼音的位置即可，也就是拼音shu。这样找到了索引的位置，在他后面就是我们想要找的数据行。</p><h4 id="非聚集索引"><a href="#非聚集索引" class="headerlink" title="非聚集索引"></a>非聚集索引</h4><p>在数据库系统会有单独的存储空间存放非聚集索引，这些索引项是按照顺序存储的，但索引项指向的内容是随机存储的。也就是说系统会进行两次查找，第一次先找到索引，第二次找到索引对应的位置取出数据行。非聚集索引不会把索引指向的内容像聚集索引一样直接放到索引的后面，而是维护单独的索引表（只维护索引，不维护索引指向的数据），为数据的检索提供方便。还以汉语字典为例，如果想要查找“数”字，那么按照部首查找的方式，先找到“数”字的偏旁部首，然后这个目录会告诉我们“数字”存放在低多少页，我们再去指定的页码找到这个字。</p><p>聚集索引与非聚集索引的原理不同，在使用上也有一些区别：</p><ol><li>聚集索引的叶子节点存储的就是我们的数据记录，非聚集索引的叶子节点存储的是数据位置。非聚集索引不会影响数据表的物理存储结构。</li><li>一个表只能有一个聚集索引，因为只能有一种排序存储的方式，但可以有多个非聚集索引，也就是多个索引目录提供数据检索，</li><li>使用聚集索引的时候，数据的查询效率高，但如果对数据进行插入，删除，更新等操作，效率会比非聚集索引低。</li></ol><p>建议：</p><ol><li>对WHERE子句的字段建立索引，可以大幅提升查询效率。</li><li>采用聚集索引进行数据查询，比使用非聚集索引查询效率略高。如果查询次数较多，还是尽量使用主键索引进行数据查询。</li></ol><p>除了业务逻辑和物理实现方式，索引还可以按照字段个数进行划分，分成单一索引和联合索引。</p><p>索引列为一列时为单一索引；多个列组合在一起创建的索引叫做联合索引。</p><p>创建联合索引时，我们需要注意创建时的顺序问题，因为联合索引（x，y，z）和（z，y，x）在使用的时候效率可能会存在差别。</p><p>这里需要说明的是联合索引存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配。比如刚才举例的 (x, y, z)，如果查询条件是 WHERE x=1 AND y=2 AND z=3，就可以匹配上联合索引；如果查询条件是 WHERE y=2，就无法匹配上联合索引。</p><h3 id="索引原理"><a href="#索引原理" class="headerlink" title="索引原理"></a>索引原理</h3><p>数据库服务器的两种存储介质，分别为硬盘和内存。内存属于临时存储，容量有限，而当发生意外时会造成数据丢失；硬盘相当于永久存储介质，这也是为什么我们需要把数据保存到硬盘上。</p><p>虽然内存的读取速度很快，但我们还是需要将索引存放到硬盘上，这样的话，当我们在硬盘上进行查询时，也就产生了磁盘的I/O操作。相比于内存的存取来说，硬盘的I/O存取消耗的时间要高很多，所消耗的时间也就越大。如果我们能让索引的数据结构尽量减少硬盘的I/O操作，所消耗的时间也就越小。</p><h4 id="二叉树的局限性"><a href="#二叉树的局限性" class="headerlink" title="二叉树的局限性"></a>二叉树的局限性</h4><p>二分查找法是一种高效的数据检索方式，时间复杂度为O(log2n），是不是采用二叉树就适合作为索引的数据结构呢？</p><h4 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h4><p>假设搜索插入的数值为key：</p><ol><li>如果key大于根节点，则在右子树种进行查找；</li><li>如果key小于根节点，则在左子树中进行查找；</li><li>如果key等于根节点，也就是找到了这个节点，返回根节点即可。</li></ol><p>例子，对数列（34，22，89，5，23，77，91）创造出来的二叉树如图：<br><img src="https://static01.imgkr.com/temp/c465fc5c2d85480488f42e1ac8164d6c.png" alt="image.png"></p><p>但是存在特殊的情况，就是有时候二叉树的深度非常大。比如（5，22，23，34，77，89，91）二叉搜索树如图所示：<br><img src="https://static01.imgkr.com/temp/556038be101c4745bdffed1dd8073e5a.png" alt="image.png"></p><p>可以看出来第一个数的深度时3，也就是说最多只需要3次比较，就可以找到节点，而第二棵树的深度时7，最多需要7次比较才能找到节点。</p><p>第二棵树也属于二分查找树，但是性能已经退化成了一条链表，查找数据的时间复杂度编程了O(n)。为了解决这个问题，人们提出了平衡二叉搜索树（AVL树），它在二分搜索树的基础上增加了约束，每个节点的左子树和右子树的高度不能超过1，也就是左子树和右子树仍然为平衡二叉树。</p><p>常见的平衡二叉树有很多种，包括了平衡二叉树、红黑树、数堆、伸展树。平衡二叉搜索树是最早提出来的自平衡二叉搜索树，当我们提到平衡二叉树时一般指的就是平衡二叉搜索树。事实上第一棵树就属于平衡二叉搜索树，搜索时间复杂度就是O(log2n)。</p><p>数据查询的时间主要依赖于磁盘I/O的次数，如果我们采用二叉树的形式，即使通过平衡二叉树进行了改进，树的深度也是O(log2n)，当n比较大时，深度也是比较高的，比如：<br><img src="https://static01.imgkr.com/temp/766d4b5674094a7cbb9af0c478263bb6.png" alt="image.png"></p><p>每访问一次节点就需要进行一次磁盘 I/O 操作，对于上面的树来说，我们需要进行 5 次 I/O 操作。虽然平衡二叉树比较的效率高，但是树的深度也同样高，这就意味着磁盘 I/O 操作次数多，会影响整体数据查询的效率。</p><p>针对同样的数据，如果我们把二叉树改成了M叉树呢？当M=3时，同样的31个节点由三叉树进行存储：<br><img src="https://static01.imgkr.com/temp/a6fa9744fb354d2aad0db67964518a26.png" alt="image.png"></p><p>你能看到此时树的高度降低了，当数据量 N 大的时候，以及树的分叉数 M 大的时候，M 叉树的高度会远小于二叉树的高度。</p><h4 id="B树"><a href="#B树" class="headerlink" title="B树"></a>B树</h4><p>如果使用二叉树作为索引的实现结构，会让树变的很高，增加硬盘的I/O次数，影响数据查询的时间。因此一个节点就不能只有2个子节点，而应该允许有M个子节点（M&gt;2）。</p><p>B树的出现就是为了解决这个问题的，英文时Balance Tree，也就是平衡多路搜索树，他的高度远小于平衡二叉树的高度。</p><p>B树的结构如下图所示：</p><p><img src="https://static01.imgkr.com/temp/cd8478bcece9462389cbd47539dd1902.png" alt="image.png"></p><p>B树作为平衡的多路搜索树，他的每一个节点最多可以包括M个子节点，M称为B树的阶。同时你能看到，每个磁盘块种包括了关键字和子节点的指针。如果一个磁盘块种包括了x个关键字，那么指针树就是x+1。对于一个100阶的B树来说，如果由三层的话最多可以存储约100万的索引数据。对于大量的索引数据来说，采用B树的结构是非常合适的，因为树的高度要远小二叉树的高度。</p><p>然后我们来看下如何用 B 树进行查找。假设我们想要查找的关键字是 9，那么步骤可以分为以下几步：</p><ol><li>我们与根节点的关键字 (17，35）进行比较，9 小于 17 那么得到指针 P1；</li><li>按照指针 P1 找到磁盘块 2，关键字为（8，12），因为 9 在 8 和 12 之间， 所以我们得到指针 P2；</li><li>按照指针 P2 找到磁盘块 6，关键字为（9，10），然后我们找到了关键字 9</li></ol><p>你能看出来在 B 树的搜索过程中，我们比较的次数并不少，但如果把数据读取出来然后在内存中进行比较，这个时间就是可以忽略不计的。而读取磁盘块本身需要进行 I/O 操作，消耗的时间比在内存中进行比较所需要的时间要多，是数据查找用时的重要因素，B 树相比于平衡二叉树来说磁盘 I/O 操作要少，在数据查询中比平衡二叉树效率要高。</p><h4 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h4><p>B+树基于B树做出了改进，主流的DBMS都支持B+树的索引方式，比如MySQL。</p><p>与B树的差异有以下几点：</p><ol><li>k 个孩子的节点就有 k 个关键字。也就是孩子数量 = 关键字数，而 B 树中，孩子数量 = 关键字数 +1。<ol start="2"><li>非叶子节点的关键字也会同时存在在子节点中，并且是在子节点中所有关键字的最大（或最小）。</li><li>非叶子节点仅用于索引，不保存数据记录，跟记录有关的信息都放在叶子节点中。而 B 树中，非叶子节点既保存索引，也保存数据记录。</li><li>所有关键字都在叶子节点出现，叶子节点构成一个有序链表，而且叶子节点本身按照关键字的大小从小到大顺序链接。</li></ol></li></ol><p><img src="https://static01.imgkr.com/temp/752a5cd4890746bea6ee634a923c2b7b.png" alt="image.png"></p><p>比如，我们想要查找关键字 16，B+ 树会自顶向下逐层进行查找：</p><ol><li>与根节点的关键字 (1，18，35) 进行比较，16 在 1 和 18 之间，得到指针 P1（指向磁盘块 2）</li><li>找到磁盘块 2，关键字为（1，8，14），因为 16 大于 14，所以得到指针 P3（指向磁盘块 7）</li><li>找到磁盘块 7，关键字为（14，16，17），然后我们找到了关键字 16，所以可以找到关键字 16 所对应的数据。</li></ol><p>整个过程一共进行了 3 次 I/O 操作，看起来 B+ 树和 B 树的查询过程差不多，但是 B+ 树和 B 树有个根本的差异在于，B+ 树的中间节点并不直接存储数据。这样的好处都有什么呢？</p><p>首先，B+ 树查询效率更稳定。因为 B+ 树每次只有访问到叶子节点才能找到对应的数据，而在 B 树中，非叶子节点也会存储数据，这样就会造成查询效率不稳定的情况，有时候访问到了非叶子节点就可以找到关键字，而有时需要访问到叶子节点才能找到关键字。</p><p>其次，B+ 树的查询效率更高，这是因为通常 B+ 树比 B 树更矮胖（阶数更大，深度更低），查询所需要的磁盘 I/O 也会更少。同样的磁盘页大小，B+ 树可以存储更多的节点关键字。</p><p>不仅是对单个关键字的查询上，在查询范围上，B+ 树的效率也比 B 树高。这是因为所有关键字都出现在 B+ 树的叶子节点中，并通过有序链表进行了链接。而在 B 树中则需要通过中序遍历才能完成查询范围的查找，效率要低很多。</p><p>总结<br>磁盘的 I/O 操作次数对索引的使用效率至关重要。虽然传统的二叉树数据结构查找数据的效率高，但很容易增加磁盘 I/O 操作的次数，影响索引使用的效率。因此在构造索引的时候，我们更倾向于采用“矮胖”的数据结构。</p><p>B 树和 B+ 树都可以作为索引的数据结构，在 MySQL 中采用的是 B+ 树，B+ 树在查询性能上更稳定，在磁盘页大小相同的情况下，树的构造更加矮胖，所需要进行的磁盘 I/O 次数更少，更适合进行关键字的范围查询。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 索引 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🧔Java常见面试题</title>
      <link href="/2020/09/04/Java%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
      <url>/2020/09/04/Java%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h3 id="1-Java面向对象编程三大特征：封装-继承-多态"><a href="#1-Java面向对象编程三大特征：封装-继承-多态" class="headerlink" title="1.Java面向对象编程三大特征：封装 继承 多态"></a>1.Java面向对象编程三大特征：封装 继承 多态</h3><p><strong>封装</strong></p><p>封装把一个对象的属性私有化，同时提供一些可以被外界访问的属性的方法，如果属性不想被外界访问，我们大可不必提供给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。</p><p><strong>继承</strong></p><p>继承时使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承我们能够非常方便的复用以前的代码。</p><h6 id="关于继承的三点："><a href="#关于继承的三点：" class="headerlink" title="关于继承的三点："></a>关于继承的三点：</h6><p>1.子类拥有父类对象所有的属性和方法(包括私有属性和私有方法)，但是父类中的私有属性和方法子类是无法访问的，<strong>只是拥有</strong>。<br>2.子类可以拥有自己属性和方法，即子类可以对父类进行扩展。<br>3.子类可以用自己的方式实现父类的方法</p><p><strong>多态</strong></p><p>所谓多态就是指程序中定义的应用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定的，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须由程序运行期间才能决定。</p><p>在Java中有两种形式可以实现多态:继承和接口</p><h3 id="2-String-StringBuffer-和-StringBuilder的区别是什么？String为什么是不可变的"><a href="#2-String-StringBuffer-和-StringBuilder的区别是什么？String为什么是不可变的" class="headerlink" title="2.String StringBuffer 和 StringBuilder的区别是什么？String为什么是不可变的"></a>2.String StringBuffer 和 StringBuilder的区别是什么？String为什么是不可变的</h3><p>可变性</p><p>简单的来说：String 类中使用的final关键字修饰字符数组保存字符串，private final char value[]，所以String对象是不可变的。</p><pre><code>补充：在Java9之后，String类的实现改用byte数组存储字符串 private final byte[] value</code></pre><p>而StringBuilder 与 StringBuffer 都继承自AbstractStringBuilder类，在AbstractStringBuilder中也是使用字符数组保存字符串char[] value 但是没有用final关键字修饰，所以这两种对象都是可变的，</p><p>线程安全性</p><p>String 中的对象是不可变的，也就可以理解为常量，线程安全。AbstractStringBuilder 是 StringBuilder与StringBuffer的公共父类，定义了一些字符串的基本操作。StringBuffer对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder并没有对方法进行加同步锁，所以是非线程安全的。</p><p>性能</p><p>每次对String类型进行改变的时候，都会产生一个新的String对象，然后将指针指向新的String对象。StringBuffer 每次都会对StringBuffer对象本身进行操作，而不是生成新的对象并未改变对象的引用。相同情况下使用StringBuilder相比使用StringBuffer仅能获得10%~15%左右的性能提升，但却要冒线程不安全的风险。</p><p>对于三者的使用总结：</p><ol><li>操作少量的数据：使用String</li><li>单线程下操作大量数据：使用StringBuilder</li><li>多线程下操作大量数据：使用StringBuffer</li></ol><h3 id="2-Java集合框架"><a href="#2-Java集合框架" class="headerlink" title="2.Java集合框架"></a>2.Java集合框架</h3><p><strong>Collection</strong></p><ol><li>List</li></ol><ul><li>ArrayList Object数组</li><li>Vector Object数组</li><li>LinkedList 双向链表(jdk1.6之前为循环，jdk1.7取消了循环)</li></ul><ol start="2"><li>Set</li></ol><ul><li>HashSet (无需且唯一)：基于HashMap实现的，底层采用HashMap来保存元素</li><li>LinkedHashSet：LinkedHashSet继承于HashSet，并且其内部是通过LinkedHashMap来实现的。</li><li>TreeSet（有序唯一）</li></ul><p>Vector是Java早期早期提供的线程安全的动态数组，如果不是线程安全，并不建议选择，毕竟同步是有额外开销的。Vector内部是使用对象数组来保存数据，可以根据需要自动的增加容量，当数组已满时，会创建新的数组，并拷贝原有数组数据。</p><p>ArrayList是应用更加广泛的动态数组实现，他本身不是线程安全的，所以性能要好很多。与Vector近似，ArrayList也是可以根据需要调整容量（默认容量为10），不过两者的逻辑有所区别，<strong>Vector扩容时会提高1倍，而ArrayList则是增加50%。</strong></p><p>LinkedList顾名思义是Java提供双向链表，所以它不需要上面两种那样调整容量，他也不是线程安全的。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🧔Redis深度历险读书笔记</title>
      <link href="/2020/09/04/Redis%E6%B7%B1%E5%BA%A6%E5%8E%86%E9%99%A9%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/"/>
      <url>/2020/09/04/Redis%E6%B7%B1%E5%BA%A6%E5%8E%86%E9%99%A9%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis应用-分布式锁"><a href="#Redis应用-分布式锁" class="headerlink" title="Redis应用-分布式锁"></a>Redis应用-分布式锁</h2><p>分布式应用进行逻辑处理时经常会遇到并发问题。</p><p>比如一个操作要修改用户的状态，修改状态需要先读出用户的状态，在内存里进行修改，改完再存回去。如果这样的操作同时进行了，就会出现并发问题，因为读取和保存的两个操作不是原子的。</p><p>这个时候就要使用到分布式锁来限制程序的并发执行。Redis分布式锁使用非常广泛</p><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p>分布式锁本质上是要实现的目标就是在Redis里面占一个茅坑，当别的进程也要来占坑时，发现已经有人在那里了，就只好放弃或者稍后再试。</p><p>占坑一般是使用setnx （set if not exists）指令，只允许一个客户端占坑。先来先占，用完了，在调用del指令释放茅坑。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;setnx lock:codehole  true</span><br><span class="line">OK</span><br><span class="line">....do something </span><br><span class="line">&gt;del lock:codehole&#39;  &#x2F;&#x2F;用来删除锁</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><p>但是有个问题，如果逻辑执行到中间出现异常了，可能会导致del指令没有调用，这样就会陷入死锁，锁永远得不到释放。</p><p>于是我们在拿到锁之后，再给锁加上一个过期时间，比如5秒，这样即使中间出现异常也可以保证5秒之后锁会的到释放。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;setnx lock:codehole true </span><br><span class="line">OK</span><br><span class="line">&gt;expire lock:codehole 5</span><br><span class="line">... do something </span><br><span class="line">&gt;del lockLc:codehole </span><br><span class="line">(integer )1</span><br></pre></td></tr></table></figure><p>但是以上逻辑还是有问题。如果setnx 和 expire 之间服务器进程突然挂掉了，可能是因为机器掉电或者是被认为杀掉的，就可能导致expire得不到执行，也会造成死锁。</p><p>这种问题的根源就在于setnx 和 expire 是两条指令而不是原子指令。如果这两条指令可以一起执行就不会出现问题。</p><p>为了解决这个问题，Redis2.8版本中作者加入了set指令的扩展参数，使得setnx和expire指令可以一起执行了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;set lock:codehole true ex 5 nx </span><br><span class="line">OK</span><br><span class="line">... dosomething </span><br><span class="line">&gt;del lock:codehole </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>上面的指令就是setnx和expire 组合在一起的原子指令，它就是分布式锁的奥义所在。</p><h3 id="超时问题"><a href="#超时问题" class="headerlink" title="超时问题"></a>超时问题</h3><p>Redis 的分布式锁不能解决超时问题，如果在加锁和释放锁之间的逻辑执行的太长，以至于超出了锁的超时限制，就会出现问题。因为这时候锁过期了，第二个线程重新持有了这把锁，但是紧接着第一个线程执行完了业务逻辑，就把锁给释放了，第三个线程就会在第二个线程逻辑执行完之间拿到了锁。</p><p>为了避免这个问题，Redis分布式锁不要用较长时间的任务。如果真的偶尔出现了，数据的小波错乱可能需人工介入解决</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tag &#x3D; random.nextint()  # 随机数 </span><br><span class="line">if redis.set(key, tag, nx&#x3D;True, ex&#x3D;5):</span><br><span class="line">do_something() </span><br><span class="line">redis.delifequals(key, tag)  # 假象的 delifequals 指令 </span><br></pre></td></tr></table></figure><p>有一个更加安全的方案是为set指令的value 参数设置为一个随机数，释放锁时先匹配随机数是否一致，然后在删除key。但是匹配value 和 删除key不是一个原子操作，redis也没有提供类似于delifequals这样的指令，这就需要使用Lua脚本来处理了，因为Lua脚本可以保证连续多个指令的原子性操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># delifequals </span><br><span class="line">if redis.call(&quot;get&quot;,KEYS[1]) &#x3D;&#x3D; ARGV[1] then    </span><br><span class="line">return redis.call(&quot;del&quot;,KEYS[1]) </span><br><span class="line">else</span><br><span class="line">return 0 end</span><br></pre></td></tr></table></figure><h3 id="可重入性"><a href="#可重入性" class="headerlink" title="可重入性"></a>可重入性</h3><p>可重入性是指线程在持有锁的情况下再次请求加锁，如果这一个锁支持同一个线程多次加锁，那么这个锁就是可重入的。比如Java语言里有个ReentrantLock就是可重入锁。Redis分布式锁如果要支持可重入，需要对客户端的set方法进行包装，使用线程的ThreadLocal变量存储当前持有锁的计数。</p><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>在集群环境下，主节点挂掉时，从节点会取而代之，客户端上却并没有明显感知。原先第一个客户端在主节点中申请成功了一把锁，但是这把锁还没有来的及同步到从节点，主节点突然挂掉了。然后从节点变成了主节点，这个新的节点内部没有这把锁，所以但另一个客户端进来请求加锁时，立即就批准了。这样就会导致系统中同样一把锁被两个客户端同时持有，不安全由此产生。</p><p>不过这种不安全也仅仅是在主从发生 failover 的情况下才会产生，而且持续时间极短，业务系统多数情况下可以容忍。</p><h4 id="Redlock算法"><a href="#Redlock算法" class="headerlink" title="Redlock算法"></a>Redlock算法</h4><p>为了解决这个问题，Antirez发明了Redlock算法，他的流程比较复杂，不过有了很多开源的library做了良好的封装，用户拿来用即可</p><p>为了使用 Redlock，需要提供多个 Redis 实例，这些实例之前相互独立没有主从关系。同很多分布式算法一样，redlock 也使用「大多数机制」。 加锁时，它会向过半节点发送 set(key, value, nx=True, ex=xxx) 指令，只要过半节点 set 成功，那就认为加锁成功。释放锁时，需要向所有节点发送 del 指令。不过 Redlock 算法还需要考虑出错重试、时钟漂移等很多细节问题，同时因为 Redlock 需要向多个节点进行读写，意味着相比单实例 Redis 性能会下降一些</p><h4 id="Redlock使用场景"><a href="#Redlock使用场景" class="headerlink" title="Redlock使用场景"></a>Redlock使用场景</h4><p>如果你很在乎高可用性，希望挂了一台 redis 完全不受影响，那就应该考虑 redlock。不过代价也是有的，需要更多的 redis 实例，性能也下降了，代码上还需要引入额外的 library，运维上也需要特殊对待，这些都是需要考虑的成本，使用前请再三斟酌</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis深度历险 </tag>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🧔Redis内存淘汰机制</title>
      <link href="/2020/09/04/Redis%E7%9A%84%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6%E4%BB%A5%E5%8F%8A%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/09/04/Redis%E7%9A%84%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6%E4%BB%A5%E5%8F%8A%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>Redis中有个设置时间过期的功能，即对存储在redis中的值可以设置一个过期时间。如果设置了一批key只能存活1个小时，那么1小时候，redis会把这写key直接全部删掉吗？ redis是怎么做的呢？</p><p>redis主要采用两种机制来处理过起了的key，他并没有直接删除掉。</p><h4 id="定期删除"><a href="#定期删除" class="headerlink" title="定期删除"></a>定期删除</h4><p>定期删除：redis默认每个100ms就<strong>随机抽取</strong>一些设置了过期时间的key，检查其是否过期，如果过期了就删除，但是这里的key是随机抽取出来的，因为如果redis里有大量的key都设置了过期时间，每个100s去遍历所有的过期key，无疑会给cup带来压力。</p><h4 id="惰性删除"><a href="#惰性删除" class="headerlink" title="惰性删除"></a>惰性删除</h4><p>惰性删除：定期删除可能会导致很多的key到了过期时间，却没有被删除掉，这导致redis中存在很多无用的key，除非系统去查一下这个key，这个key才会被redis给删除掉。这就是所谓的惰性删除。</p><p>但是仅仅通过这两种策略还是有问题的，如果没有及时去查，大量的过期key堆积在内存中，导致redis内存被消耗尽了。怎么解决呢？那就是redis的内存淘汰机制。</p><p>redis提供了6中数据淘汰策略：</p><ol><li>volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的淘汰。</li><li>volatile-ttl：从已设置过期时间的数据集中挑选将要过期的key淘汰。</li><li>volatile-random：从已设置过期时间的数据集中随机淘汰。</li><li>allkeys-lru：当前内存不足已容纳新写入的数据是，在所有的键中，挑选最近最少使用的键进行删除。</li><li>allkeys-random：从数据集中任意选择数据淘汰。</li><li>no-eviction：禁止驱逐数据，内存不足时就报错。</li></ol><h3 id="redis的持久化机制-怎么保证redis挂掉之后在重启数据可以恢复"><a href="#redis的持久化机制-怎么保证redis挂掉之后在重启数据可以恢复" class="headerlink" title="redis的持久化机制(怎么保证redis挂掉之后在重启数据可以恢复)"></a>redis的持久化机制(怎么保证redis挂掉之后在重启数据可以恢复)</h3><p>很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，为的是重启机器，机器故障后恢复。</p><p>Redis支持两种不同的持久化操作，Redis的一种持久化方式叫快照（RDB），另外一种方式是只追加文件（append-only-file，AOF）。这两种方式各有千秋。</p><h4 id="快照持久化（RDB）"><a href="#快照持久化（RDB）" class="headerlink" title="快照持久化（RDB）"></a>快照持久化（RDB）</h4><p>Redis可以通过创建快照来获得存储在内存里面的数据在某个时间节点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构），还可以在原地以便重启服务器的时候使用。</p><p>Redis默认采用快照持久化，在redis.conf配置文件中默认有此下配置：</p><pre><code>save 900 1 #在900s之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。save 300 10 #在300s之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。save 60 10000 #在60s之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</code></pre><h4 id="AOF-持久化"><a href="#AOF-持久化" class="headerlink" title="AOF 持久化"></a>AOF 持久化</h4><p>与快照持久化相比，AOF有更好的实时性。默认情况下Redis没有开启AOF方式的持久化，可以通过appendonly参数开启：</p><pre><code>appendonly yes</code></pre><p>开启AOF持久化后每执行一条会更改Redis中的数据命令，Redis机会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appledonly.aof</p><p>在Redis的配置文件中存在三种不同的AOF持久化方式，分别是：</p><pre><code>appendfsync always   #每次有数据修改发生时都会写入AOF文件，这样会严重降低Reids的速度appendfsync everysec #每秒同步一次，显示的将多个写命令同步到磁盘appendfsync no       #让操作系统决定何时进行同步</code></pre><p>建议使用appendfsync everysec选项，让Redis每秒只同步一次AOF文件，Redis性能几乎没有受到任何影响。即使系统崩掉，最多只会丢失一秒之内产生的数据。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。</p><h3 id="RDB的优点"><a href="#RDB的优点" class="headerlink" title="RDB的优点"></a>RDB的优点</h3><ul><li><p>RDB的文件非常紧凑，他保存redis在某个时间上的数据集。</p></li><li><p>RDB适合灾难恢复：他只有一个文件，并且文件非常紧凑。</p></li><li><p>RDB可以最大化节省Redis的性能：父进程在保存RDB的时候只需要<strong>fork</strong>出一个进程即可，父进程无需执行磁盘的IO。</p></li><li><p>RDB在恢复大数据集的时候要比AOF快。</p><h3 id="RDB的缺点"><a href="#RDB的缺点" class="headerlink" title="RDB的缺点"></a>RDB的缺点</h3></li><li><p>如果你要尽量避免Redis在出问题的时候丢失数据，那RDB可能不合适，一旦停机他可能会失去好几分钟的数据。相信这是没人可以接受的。</p></li><li><p>每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 虽然 AOF 重写也需要进行 fork() ，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失。</p></li></ul><h3 id="AOF的优点"><a href="#AOF的优点" class="headerlink" title="AOF的优点"></a>AOF的优点</h3><ul><li>使用AOF会让Redis变得非常耐久，比如：你可以设置不同的策略，比如每秒钟同步一次，一秒钟同步一次(默认)，每写一次同步一次，默认就可以很节省性能，而且最多也就丢失一秒的数据。</li><li>AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 seek ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等）， redis-check-aof 工具也可以轻易地修复这种问题。</li><li>Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。</li></ul><h3 id="AOF的缺点"><a href="#AOF的缺点" class="headerlink" title="AOF的缺点"></a>AOF的缺点</h3><ul><li>对于相同的数据集来说，AOF的文件大小要比RDB的大。</li><li>根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 内存淘汰机制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🧔Redis基础知识</title>
      <link href="/2020/09/04/Redis%E7%AE%80%E4%BB%8B/"/>
      <url>/2020/09/04/Redis%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h2><p>简单来说redis就是一个数据库，不过与传统的数据库不同的是<br>redis的数据是存在内存中的，所以读写速度非常快，因此redis被广泛应用于缓存方向。另外，redis也经常来做分布式锁。redis提供了多种数据类型来支持不同的业务场景。</p><h2 id="Redis常见的数据结构以及使用场景分析"><a href="#Redis常见的数据结构以及使用场景分析" class="headerlink" title="Redis常见的数据结构以及使用场景分析"></a>Redis常见的数据结构以及使用场景分析</h2><h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><pre><code>常用命令：set，get，decr，incr，mget等。</code></pre><p>String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。常规计数：微博数，粉丝数等。</p><h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><pre><code>常用命令：hget，hset，hgetall等。</code></pre><p>hash是一个string类型的field和value的映射表，hash特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。比如:</p><pre><code>key=uservalue=&#123;    &quot;id&quot;:1,    &quot;name&quot;:&quot;test&quot;,    &quot;age&quot;:22&#125;</code></pre><h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><pre><code>常用命令：lpush，rpush，lpop，lrange</code></pre><p>List就是链表，Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，消息列表。</p><p>Redis list 的实现为一个双向链表，既可以支持方向查找和遍历，更方便操作，不过带来了额外的内存开销。</p><p>另外可以通过lrange命令，就是从某个元素的开始读取多少个元素，可以基于list实现分页查询，这个很棒，基于redis实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高。</p><h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><pre><code>常用命令：sadd，spop，smembers，sinion等</code></pre><p>set对外提供的功能与list类似是一个列表的功能，特殊之外在于set是可以排重的。</p><p>当你需要存储一个列表数据，又不希望有重复数据时，set时一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个时list不能提供的。可以通过set轻易实现交集，并集，补集，差集。</p><pre><code>判断member是否在set中    sismember key member    存在返回1，0表示不存在或者key不存在    </code></pre><p>比如：在微博应用中，将一个用户的所有关注存在一个set中，并将其粉丝存在一个集合中，redis可以非常方便的实现共同关注，共同爱好的功能。</p><pre><code>sinterstore dstkey key1...keyN   将key1~keyn的交集存入dskey中</code></pre><h3 id="Sorted-Set"><a href="#Sorted-Set" class="headerlink" title="Sorted Set"></a>Sorted Set</h3><pre><code>常用命令：zadd，zrange，zrem，zcard等</code></pre><p>和set相比sorted set增加了一个权重参数score，使得集合中的元素能够按照score进行排序。</p><p>举例：在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息等信息。</p><h3 id="redis设置过期时间"><a href="#redis设置过期时间" class="headerlink" title="redis设置过期时间"></a>redis设置过期时间</h3><p>Redis中有个设置时间过期的功能，即对存储在redis数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如短信验证码。</p><p>在set key的时候，都可以给一个expire time，就是过期时间，通过过期时间指定这个key可以存过的时间。</p><p><strong>下篇文章介绍redis的内存淘汰机制</strong></p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 缓存 </tag>
            
            <tag> Redis </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🕵️‍♂️RabbitMQ 实现延迟消息（以订单超时为例）</title>
      <link href="/2020/09/04/RabbitMQ%20%E5%AE%9E%E7%8E%B0%E5%BB%B6%E8%BF%9F%E6%B6%88%E6%81%AF%EF%BC%88%E4%BB%A5%E8%AE%A2%E5%8D%95%E8%B6%85%E6%97%B6%E4%B8%BA%E4%BE%8B%EF%BC%89/"/>
      <url>/2020/09/04/RabbitMQ%20%E5%AE%9E%E7%8E%B0%E5%BB%B6%E8%BF%9F%E6%B6%88%E6%81%AF%EF%BC%88%E4%BB%A5%E8%AE%A2%E5%8D%95%E8%B6%85%E6%97%B6%E4%B8%BA%E4%BE%8B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h5 id="铺垫"><a href="#铺垫" class="headerlink" title="铺垫"></a>铺垫</h5><p>RabbitMQ延迟消息以来的是其死信机制</p><p>首先启动RabbitMQ服务器，并在配置文件配置好相关配置</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rabbitmq:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">localhost</span>      <span class="comment"># ip地址</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">5672</span>           <span class="comment"># 端口</span></span><br><span class="line">  <span class="attr">virtual-host:</span> <span class="string">/mall</span>  <span class="comment">#虚拟机</span></span><br><span class="line">  <span class="attr">username:</span> <span class="string">mall</span>       <span class="comment">#用户名</span></span><br><span class="line">  <span class="attr">password:</span> <span class="string">mall</span>       <span class="comment">#密码</span></span><br><span class="line">  <span class="attr">publisher-confirms:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p><strong>整体流程图</strong><br><img src="http://www.yinshi.网址:8090/upload/2020/3/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6-4ec6438a8a3c486cb45a4c8f462d4017.png" alt="延迟消息.png"></p><h3 id="一、使用SpringDataRabbitMQ配置MQ的交换机与队列"><a href="#一、使用SpringDataRabbitMQ配置MQ的交换机与队列" class="headerlink" title="一、使用SpringDataRabbitMQ配置MQ的交换机与队列"></a>一、使用SpringDataRabbitMQ配置MQ的交换机与队列</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RabbitMqConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *订单队列中消息超时后将消息发送到这个交换机</span></span><br><span class="line"><span class="comment">     * 相当于死信交换机</span></span><br><span class="line"><span class="comment">     * */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function">DirectExchange <span class="title">orderDirect</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (DirectExchange) ExchangeBuilder.directExchange(<span class="string">&quot;order.exchange&quot;</span>)</span><br><span class="line">                .durable(<span class="keyword">true</span>)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将订单消息推送到订单队列的交换机</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * */</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> DirectExchange <span class="title">orderTtlDirect</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (DirectExchange) ExchangeBuilder.directExchange(<span class="string">&quot;order.ttl.exchange&quot;</span>)</span><br><span class="line">                .durable(<span class="keyword">true</span>)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *接收取消订单的消息队列(超时后消息转发到这个队列)</span></span><br><span class="line"><span class="comment">     * **/</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Queue <span class="title">orderQueue</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Queue(<span class="string">&quot;order.queue&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 接收订单的消息队列，到期后转发消息转发到orderDirect</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * **/</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Queue <span class="title">orderTtlQueue</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> QueueBuilder.durable(<span class="string">&quot;orderTtl.queue&quot;</span>)</span><br><span class="line">                .withArgument(<span class="string">&quot;x-dead-letter-exchange&quot;</span>,<span class="string">&quot;order.exchange&quot;</span>) <span class="comment">//过期后发送的交换机</span></span><br><span class="line">                .withArgument(<span class="string">&quot;x-dead-letter-routing-key&quot;</span>,<span class="string">&quot;order&quot;</span>) <span class="comment">//过期后发送的routingkey</span></span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 绑定订单队列到交换机</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Binding <span class="title">orderTtlBinding</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> BindingBuilder.bind(orderTtlQueue())</span><br><span class="line">                .to(orderTtlDirect())</span><br><span class="line">                .with(<span class="string">&quot;orderTtl&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 取消订单的消息绑定交换机</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Binding <span class="title">orderBinding</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> BindingBuilder.bind(orderQueue())</span><br><span class="line">                .to(orderDirect())</span><br><span class="line">                .with(<span class="string">&quot;order&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="二、添加消息发送方"><a href="#二、添加消息发送方" class="headerlink" title="二、添加消息发送方"></a>二、添加消息发送方</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CancelOrderSender</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Logger logger = LoggerFactory.getLogger(CancelOrderSender.class);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> RabbitTemplate rabbitTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//消息类型为Long的订单id</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendMessage</span><span class="params">(Long orderId)</span></span>&#123;</span><br><span class="line">        rabbitTemplate.convertAndSend(<span class="string">&quot;order.ttl.exchange&quot;</span>,<span class="string">&quot;orderTtl&quot;</span></span><br><span class="line">                , orderId, <span class="keyword">new</span> MessagePostProcessor() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> Message <span class="title">postProcessMessage</span><span class="params">(Message message)</span> <span class="keyword">throws</span> AmqpException </span>&#123;</span><br><span class="line">                        message.getMessageProperties().setExpiration(<span class="string">&quot;5000&quot;</span>);<span class="comment">//过期时间为5秒</span></span><br><span class="line">                        <span class="keyword">return</span> message;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">        logger.info(<span class="string">&quot;send delay message orderId:&#123;&#125;&quot;</span>,orderId);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="三、启动测试查看日志输出"><a href="#三、启动测试查看日志输出" class="headerlink" title="三、启动测试查看日志输出"></a>三、启动测试查看日志输出</h3><p>5秒后收到了过期的消息</p><p><img src="http://www.yinshi.网址:8090/upload/2020/3/TIM%E6%88%AA%E5%9B%BE20200307231052-aac98a5ba4e0447fbb81a4fcf1b114f4.png" alt="TIM截图20200307231052.png"></p><p>到此结束！</p>]]></content>
      
      
      <categories>
          
          <category> RabbitMQ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RabbitMQ </tag>
            
            <tag> 消息队列 </tag>
            
            <tag> 延迟队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🧙‍♀️RabbitMQ入门</title>
      <link href="/2020/09/04/RabbitMQ%E5%85%A5%E9%97%A8/"/>
      <url>/2020/09/04/RabbitMQ%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>RabbitMQ是由erlang语言开发，基于AMQP（Advanced Message Queue 高级消息队列协议）协议实现的消息队列，它是一种应用程序之间的通信方法，消息队列在分布式系统开发中应用非常广泛。</p><h1 id="相关定义"><a href="#相关定义" class="headerlink" title="相关定义"></a>相关定义</h1><ul><li>Broker： 简单来说就是消息队列服务器实体</li><li>Exchange：它指定消息按什么规则，路由到哪个队列</li><li>Queue：消息队列的载体，每个消息都会投入到一个或多个消息队列中</li><li>Binding：绑定，它的作用就是把exchange和queue按照路由规则绑定起来</li><li>Routing Key： 路由关键字，exchange根据这个关键字进行消息投递</li><li>VHost： 虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。</li><li>Producer： 消息生产者，就是投递消息的程序</li><li>Consumer： 消息消费者，就是接受消息的程序</li><li>Channel： 消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务</li></ul><p><strong>由Exchange、Queue、RoutingKey三个才能决定一个从Exchange到Queue的唯一的线路。</strong></p><h1 id="RabbitMQ的工作模式"><a href="#RabbitMQ的工作模式" class="headerlink" title="RabbitMQ的工作模式"></a>RabbitMQ的工作模式</h1><p> RabbitMQ的官方网站中一共介绍了6种工作模式。<a href="https://www.rabbitmq.com/getstarted.html">6种工作模式</a></p><h4 id=""><a href="#" class="headerlink" title=""></a></h4><h3 id="1-Hello-world-简单模式"><a href="#1-Hello-world-简单模式" class="headerlink" title="1. Hello world 简单模式"></a>1. Hello world 简单模式</h3><p><img src="https://static01.imgkr.com/temp/9f706b05f5b64d91917014687d6cbab6.png" alt="image.png"></p><p>P：生产者：也就是要发送消息的程序</p><p>C：消费者：消息的接受者会监听消息生产者，会一直等待消息到来</p><p>应用场景: 聊天</p><p><strong>Producter 如果发送消息时，如果发送的队列没有绑定交换机和routing key的话，那么将会使用默认的交换机并且将发送的消息队列名作为routing key</strong></p><h3 id="2-Work-queues-工作模式"><a href="#2-Work-queues-工作模式" class="headerlink" title="2. Work queues 工作模式"></a>2. Work queues 工作模式</h3><p><img src="https://static01.imgkr.com/temp/ec86c4977cc44aa3adb78db41dd31934.png" alt="image.png"></p><p>多个消费者监听只听同一名称的队列消费消息（消费者属于竞争关系）</p><h3 id="3-Publish-发布与订阅模式"><a href="#3-Publish-发布与订阅模式" class="headerlink" title="3.Publish 发布与订阅模式"></a>3.Publish 发布与订阅模式</h3><p><img src="https://static01.imgkr.com/temp/3e843a1e17d34746a32c8889331d6e47.png" alt="image.png"></p><p>这种模式添加了一个角色X即交换机Exchange</p><p>多个队列绑定相同的交换机接收相同的消息<br>多个消费者监听相对的队列接收相同的消息</p><p><strong>这种模式需要使用fanout 类型的交换机，这种交换机不处理routing key 只需要将队列绑定到交换机上就可以，因此，fanout类型的交换机转发消息是最快的。</strong> </p><h3 id="4-Routing-路由模式"><a href="#4-Routing-路由模式" class="headerlink" title="4.Routing 路由模式"></a>4.Routing 路由模式</h3><p><img src="https://static01.imgkr.com/temp/b8baa95a8bed4f27b3b0fbc6206f2784.png" alt="image.png"></p><p><strong>队列通过routingkey 绑定 direct类型的交换机，生产者向交换机发送消息时，也需要指定相应的routingkey 交换机就会把这个routingkey对应的消息发送到绑定改rotingkey的队列中，如果routingkey不一致则交换机不会把消息发送到队列中</strong></p><h3 id="5-Topics-通配符模式"><a href="#5-Topics-通配符模式" class="headerlink" title="5.Topics 通配符模式"></a>5.Topics 通配符模式</h3><p><img src="https://static01.imgkr.com/temp/6e3323bea2cc4dbbb733948431929e67.png" alt="image.png">v</p><p>Exchange：使用topic模式的交换机，这种类型的交换机与direct相比就是在绑定routingkey时可以使用通配符</p><p>通配符匹配规则</p><p>#：匹配一个或多个词</p><p>*：匹配不多不少恰好1个词</p><p>举例：</p><p><strong>item.#：</strong> 能够匹配<code>item.insert.abc</code>或者<code>item.insert</code></p><p>*<em>item.<em>：</em></em>只能匹配<code>item.insert</code></p>]]></content>
      
      
      <categories>
          
          <category> RabbitMQ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RabbitMQ </tag>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
