<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>TCP协议</title>
      <link href="/2020/10/20/%E9%9D%A2%E5%90%91%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%AF%E9%9D%A0%E7%9A%84%E8%BF%90%E8%BE%93%E5%8D%8F%E8%AE%AE%20TCP/"/>
      <url>/2020/10/20/%E9%9D%A2%E5%90%91%E8%BF%9E%E6%8E%A5%E7%9A%84%E5%8F%AF%E9%9D%A0%E7%9A%84%E8%BF%90%E8%BE%93%E5%8D%8F%E8%AE%AE%20TCP/</url>
      
        <content type="html"><![CDATA[<h3 id="面向连接的可靠的运输协议-TCP"><a href="#面向连接的可靠的运输协议-TCP" class="headerlink" title="面向连接的可靠的运输协议 TCP"></a>面向连接的可靠的运输协议 TCP</h3><p>​    TCP被称为面向链接的，这是因为在一个应用进程可以开始向另一个应用进程发送数据之前，这两个进程必须相互“握手”，即他们必须相互发送某些预备报文段，以建立确保数据传输的参数。作为TCP连接建立的一部分，连接的双方都将初始化与TCP连接相关的许多TCP状态变量。</p><p>​    由于TCP协议只在端系统中运行，而不在中间的网络元素（路由器和交换机）中运行，所以中间的网络元素不会维持TCP连接状态。事实上，中间路由器对TCP连接完全视而不见，他们看到的是数据，而不是连接。</p><p>​    TCP连接提供的是全双工服务：如果一台主机上的进程A与另一台主机上的进程B存在一条TCP连接，那么应用层数据就可以从进程B流向进程A的同时，也从进程A流向进程B。TCP连接也总是点对点的。即在单个发送方与接收方之间的连接。所谓“多播”，即在一次发送操作中，从一个发送方将数据传送给多个接收方，对TCP来说这是不可能的。对于TCP而言，两台主机是一对，而三台主机则太多！</p><h3 id="TCP协议详解"><a href="#TCP协议详解" class="headerlink" title="TCP协议详解"></a>TCP协议详解</h3><p><img src="https://static01.imgkr.com/temp/5acf82aa4f4c4513a180925f431f4573.png" alt="image-20201103171002436"></p><h5 id="特点"><a href="#特点" class="headerlink" title="特点"></a>特点</h5><ul><li><p>TCP是面向连接的协议</p></li><li><p>TCP的一个连接有两端（点对点通信）</p></li><li><p>TCP提供可靠的传输服务</p></li><li><p>TCP协议提供全双工的通信</p></li><li><p>TCP是面向字节流的协议</p><p><img src="https://static01.imgkr.com/temp/f6f6ec01b1404c4aa86795c8f7a7e417.png" alt="image-20201103171159143"></p></li></ul><h5 id="TCP首部格式"><a href="#TCP首部格式" class="headerlink" title="TCP首部格式"></a>TCP首部格式</h5><p><img src="https://static01.imgkr.com/temp/437f2373a73045f6ad2fca637ea29423.png" alt="image-20201103173128597"></p><ul><li><p>序号： </p><ul><li>一共32位，范围是0-2^32-1</li><li>一个字节一个序号</li><li>代表数据首字节序号</li></ul></li><li><p>确认号</p><ul><li><p>0-2^32-1</p></li><li><p>一个字节一个序号</p></li><li><p>期望收到数据的首字节序号（确认号为N：则表示N-1序号的数据都已经收到）</p></li></ul></li></ul><ul><li><p>数据偏移</p><ul><li><p>占4位：0-15，单位为：32位字</p></li><li><p>数据偏离首部的距离</p><p><img src="https://static01.imgkr.com/temp/18f7be02226d4ee8bc17ac00b576229c.png" alt="image-20201103174626449"></p></li></ul></li><li><p>TCP标记</p><ul><li><p>占6位，每位各有不同意义</p><p><img src="https://static01.imgkr.com/temp/d47f18a9bbba4f3dbbbdea6c12d49f21.png" alt="image-20201103174734701"></p></li></ul></li></ul><p><img src="https://static01.imgkr.com/temp/785a4c50178748dd8aef930f3213c389.png" alt="image-20201103174757710"></p><ul><li><p>窗口</p><ul><li>占16位：0-2^16-1</li><li>窗口指明允许发送的数据量<ul><li>确认号：501 ，窗口：1000，那么501~1500字节的数据都可以传输</li></ul></li></ul></li><li><p>校验和</p></li><li><p>紧急指针</p><ul><li>紧急数据（URG = 1）</li><li>指定紧急数据在报文的位置</li></ul></li><li><p>TCP选项</p><ul><li><p>最多40字节</p></li><li><p>支持未来的拓展</p></li></ul></li></ul><h5 id="TCP-可靠传输基本原理"><a href="#TCP-可靠传输基本原理" class="headerlink" title="TCP 可靠传输基本原理"></a>TCP 可靠传输基本原理</h5><p><strong>ARQ协议</strong>：自动重传请求是OSI模型中数据链路层和传输层的错误纠正协议之一。它通过使用确认和超市这两个机制，在不可靠服务的基础上实现可靠的信息传输。如果发送方在发送一段时间之内没有收到确认帧，他通常会重新发送。ARQ包括停止等待ARQ协议和连续ARQ协议。</p><ul><li><p>停止等待ARQ协议</p><ul><li>停止等待协议是为了实现可靠传输的，它的基本原理就是每发完一个分组就停止发送，等待对方确认（回复ACK）。如果过了一段时间（超时时间后），还是没有收到ACK确认，说明没有发送成功，需要重新发送，直到收到确认后再发下一个分组。</li><li>在停止等待协议中，若接收方收到重复分组，就丢弃该分组，但同时还要发送确认；</li></ul><p><strong>优点</strong>：简单</p><p><strong>缺点</strong>：信道利用率低，等待时间长。</p></li><li><p>连续ARQ协议</p><ul><li>连续ARQ协议可提高信道利用率。发送方维持一个发送窗口（滑动窗口协议）内的分组，凡位于发送窗口内的分组可以连续发送出去，而不需要等待对方确认。接收方一般采用累计确认，对按序到达的最后一个分组发送确认，表明到这个分组为止的所有分组已经正确收到了。</li></ul><p><strong>优点</strong>： 信道利用率高，容易实现，即使确认丢失，也不必重传。</p><p><strong>缺点</strong>：不能向发送方反映出接收方已经正确收到所有分组的信息。比如：发送方发送了5条消息，中间第三条丢失了，这时接收方只能对前两个发送确认。发送方无法知道后三个分组的下落，而只好把后三个全部重传一次。这也叫 回退N，表示需要退回来重传已经发送过的N个消息，显然单个分组的差错就能够引起重传大量分组，许多分组根本没有必要重传。</p></li><li><p>选择重传协议</p><ul><li>选择重传协议通过让发送方仅重传那些它怀疑在接收方出错的分组而避免了不必要的重传。接收方将确认一个正确接受的分组而不管其是否按序。失序的分组将被缓存知道所有丢失分组皆被收到为止。</li></ul></li></ul><p><strong>TCP的差错回复机制最好被分类位滑动窗口（GBN）协议与选择重传（SR）协议的结合体。</strong></p><h5 id="流量控制"><a href="#流量控制" class="headerlink" title="流量控制"></a>流量控制</h5><p> 如果发送者发送数据过快，接收者来不及接收，那么就会有分组丢失。为了避免分组丢失，控制发送者的发送速度，使得接收者来得及接收，这就是流量控制。流量控制的根本目的是防止分组丢失，他是构成TCP可靠性的一方面。</p><p>如何实现流量控制？</p><p>由滑动窗口协议（连续ARQ协议）实现。滑动窗口协议即保证了分组无差错、有序接受，也实现了流量控制。主要的方式就是接收方返回的ACK中包含自己的接收窗口的大小，并且利用大小来控制发送方的数据发送。</p><p>流量控制引发的死锁？怎么避免死锁的发生？</p><ul><li>当发送者收到了一个窗口为0的应答，发送者便停止发送，等待接收者的下一个应答。但是如果这个窗口不为0的应答在传输过程丢失，发送者一直等待下去，而接收者以为发送者已经收到该应答，等待接收新数据，这样双方就相互等待，从而产生死锁。<br>为了避免流量控制引发的死锁，TCP使用了持续计时器。每当发送者收到一个零窗口的应答后就启动该计时器。时间一到便主动发送报文询问接收者的窗口大小。若接收者仍然返回零窗口，则重置该计时器继续等待；若窗口不为0，则表示应答报文丢失了，此时重置发送窗口后开始发送，这样就避免了死锁的产生。</li></ul><h5 id="拥塞控制"><a href="#拥塞控制" class="headerlink" title="拥塞控制"></a>拥塞控制</h5><p>​    <strong>拥塞控制和流量控制的区别</strong></p><p>​    发送方维持一个叫做拥塞控制窗口的状态变量。拥塞窗口的大小却决于网络的拥塞程度，并且动态的在变化，发送方让自己的发送窗口等于拥塞控制，另外考虑到接收方的接收能力，发送窗口可能小于拥塞窗口。</p><hr><p>TCP的拥塞控制采用四种算法，即 满开始、拥塞避免、快充次、快恢复</p><p><strong>拥塞控制算法</strong></p><hr><p>-慢开始算法的思路是，不要一开始就发送大量的数据，先探测一下网络的拥塞程度，也就是由小到大逐渐增加拥塞窗口的大小</p><hr><p>为了防止cwnd增长过大引起网络拥塞，还需设置一个慢开始门限ssthresh状态变量。ssthresh的用法如下：当cwnd&lt;ssthresh时，使用慢开始算法。<br>当cwnd&gt;ssthresh时，改用拥塞避免算法。<br>当cwnd=ssthresh时，慢开始与拥塞避免算法任意</p><p><strong>拥塞避免算法</strong></p><p>拥塞避免算法让拥塞窗口缓慢增长，即每经过一个往返时间RTT就把发送方的拥塞窗口cwnd加1，而不是加倍。这样拥塞窗口按线性规律缓慢增长。</p><p>无论是在慢开始阶段还是在拥塞避免阶段，只要发送方判断网络出现拥塞（其根据就是没有按时收到确认，虽然没有收到确认可能是其他原因的分组丢失，但是因为无法判定，所以都当做拥塞来处理），就把慢开始门限ssthresh设置为出现拥塞时的发送窗口大小的一半（但不能小于2）。然后把拥塞窗口cwnd重新设置为1，执行慢开始算法。这样做的目的就是要迅速减少主机发送到网络中的分组数，使得发生拥塞的路由器有足够时间把队列中积压的分组处理完毕。<img src="https://static01.imgkr.com/temp/7cc2d108c68f4e34aede20b3b453a6b0.jpg" alt="v2-f7db63b1f00cbd8170e1435616e06216_720w"></p><p>（1）拥塞窗口cwnd初始化为1个报文段，慢开始门限初始值为16<br>（2）执行慢开始算法，指数规律增长到第4轮，即cwnd=16=ssthresh，改为执行拥塞避免算法，拥塞窗口按线性规律增长<br>（3）假定cwnd=24时，网络出现超时（拥塞），则更新后的ssthresh=12，cwnd重新设置为1，并执行慢开始算法。当cwnd=12=ssthresh时，改为执行拥塞避免算法</p><h5 id="TCP三次握手"><a href="#TCP三次握手" class="headerlink" title="TCP三次握手"></a>TCP三次握手</h5><hr><p><img src="https://static01.imgkr.com/temp/391b3d19f2ae462d94e48745ecf2e477.png" alt="image-20201109202921191"></p><p>TCP的连接建立，我们常常称为三次握手。</p><p>A： 您好，我是A。</p><p>B：您好A，我是B。</p><p>A：您好B</p><p>为什么要三次，而不是两次？按说两个人打招呼，一来一回就可以了，为什么不是四次？</p><p>假设这个通路是非常不可靠的，A要发起一个连接，当发了第一个请求渺无音信的时候，会有很多的可能性，比如第一个请求包丢了，再如果没有丢，但是绕了弯路，超时了，还有B没有响应，不想和我连接。</p><p>A不能确认结果，于是再发，再发。终于有一个请求包到了B，但是请求包到了B的这个事情，目前A还是不知道，A还有可能再发。</p><p>B收到了请求包，就知道了A的存在，并且知道A要和它建立连接。如果B不愿意建立连接，则A会重试一阵后放弃，连接建立失败，没有是问题；如果B是乐意建立连接，则会发送应答包给A。</p><p>当然对于B来说，这个应答包也是一如网络深似海，不知道能不能到达A。这个时候B自然不能认为连接是建立好了，因为应答包仍然会丢，会绕弯路，或者A已经挂了都有可能。</p><p>而且这个时候B还能碰到一个诡异的现象就是，A和B原来建立了连接，做了简单的通信，结束了连接。还记得吗？ A建立连接的时候，请求包重复发了几次，有的请求包绕了一个大圈又回来了，B会认为这也是一个正常的请求话，因此建立了连接，可以想象这个连接会不会进行下去，也没有终结的时候，纯属单相思了。<strong>因而两次握手肯定不行。</strong></p><p>B发送的应答可能会发送很多次，但是只要一次到达A，A就认为连接已经建立了，因为对与A来说，他的消息有去有回。A会给B发送应答之应答，而B也在等这个消息，才能确认连接建立，只有等到了这个消息，对于B来讲，才算他的消息有去有回。</p><p>当然A发送给B的应答之应答也会丢，也会绕路，甚至B挂了。按理来说，还应该有个应答之应答之应答，这样下去没底了。所以四次握手是可以的，四十次都可以，关键四百次也不能保证就真的可靠了。只要双方的消息都有去有回，就基本可以了。</p><p>好在大部分情况下，A和B建立连接之后，A会马上发送数据的，一旦A发送数据，则很多问题都得到了解决。例如A发送给B的应答丢了，当A后续发送的数据到达的时候,B可以认为这个连接已经建立，或者B压根就挂了，A发送的数据，会报错，说B不可达，A就知道B出事情了。</p><p>当然你可以说A比较坏，就是不发数据，建立连接后空着。我们在程序设计的时候，可以要求开启keepalive机制，即使没有真实的数据包，也有探活包。</p><p>三次握手除了双方建立连接外，主要还是为了沟通一件事情，就是<strong>TCP包的序号问题。</strong></p><p>A要告诉B我这面发起的包的序号起始是从哪个号开始的，B同样也要告诉A，B发起的包的序号是从哪个号开始的。为什么序号都不能从1开始呢？因为这样往往会出现冲突。</p><p>例如，A连上B之后，发送了1，2，3三个包，但是发送3的时候，中间丢了，或者绕路了，于是重新发送，后来A掉线了，重新连上B后，序号又从1开始，然后发送2，但是压根没想发送3,但是上次绕路的那个3又回来了，发给了B，B自然认为，这就是下一个包，于是发送了错误。</p><p>因而，每个连接都要有不同的序号。这个序号的起始序号是随着时间变化的，可以看成一个32位的计数器，没4微秒加一，如果计算下，如果到重复，需要4个多小时，那个绕路的包早就死翘翘了，因为我们都知道IP包头里有个TTL，也即生存时间。</p><h5 id="TCP四次挥手"><a href="#TCP四次挥手" class="headerlink" title="TCP四次挥手"></a>TCP四次挥手</h5><p>A：啊，我不想玩了。</p><p>B：噢，你不想玩了我知道了。</p><p>这个时候，还只是A不想玩了，也即A不会再放松数据了，但是B能不能在ACK的时候直接关闭呢？当然不可以了，很有可能A是发完了最后的数据就准备不玩了，但是B还没做完自己的事情，还是可以发送数据的，所以称为半关闭的状态。</p><p>这个时候A可以选择不再接受数据了，也可以选择在接收一段数据，等待B也主动关闭。</p><p>B：A啊，好吧，我也不玩了，拜拜。</p><p>A：好的，拜拜。</p><p>这样整个连接就关闭了。但是这个过程有没有异常情况呢？当然有，上面是和平分手的场面。</p><p>A开始说 “不玩了”，B说“知道了”，这个回合没什么问题，因为在此前，双方还处于合作状态，如果A说“不玩了”，没有收到回复，则A会重新发送“不玩了”。但是这个回合结束之后，就有可能出现异常情况了，因为已经有乙方率先撕破脸。</p><p>一种情况是，A说完“不玩了”之后，直接跑路，是会有问题的，因为B还没有发起结束，而如果A跑路，B就算发起结束，也得不到回答，B就不知道该怎么办了。另一种情况，A说完“不玩了”，B直接跑路，也是有问题的，因为A不知道B是还有事情要处理，还是过一会儿会发送结束。</p><p><img src="https://static01.imgkr.com/temp/aa5a17546cf94df4bee9bce8a544e54e.png" alt="image-20201109204021605"></p><p>那怎么解决这些问题？TCP协议专门设计了几个状态来处理这些问题。</p><p>断开的时候，我们可以看到，当A说“不玩了”，就会进入 FIN_WAIT_1的状态，B收到“A不玩”的消息后，发送知道了，就进入CLOSE_WAIT的状态。</p><p>A收到“B说知道了”，就进入FIN_WAIT_2的状态，如果这个时候B直接跑路，则A将永远在这个状态。TCP协议里面并没有对这个状态的处理，但是Linux有，可以调整tcp_fin_timeout这个参数，设置一个超时时间。</p><p>如果B没有跑路，发送了“B也不玩了”的请求到达A是，A发送“知道B也不玩了”的ACK后，从FIN_WAIT_2状态结束，按说A可以跑路了，但是最后的这个ACK万一B收不到呢？则B会重新发送一个“B不玩了”，这个时候A已经跑路的话，B就在也收不到ACK了，因而TCP协议要求A最后等待一段时间TIME_WAIT，这个时间要足够长，长到如果B没收到ACK的话，“B说不玩了”会重发的，A会重新发一个ACK并且足够时间到达B。</p><p>A直接跑路还是有一个问题是，A的端口就直接空出来了，但是B不知道，B原来发送的很多的包还有可能在路上，如果A的端口被一个新的应用占用了，这个新的应用会受到上个连接B发过来的包，虽然序列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来B发送的所有的包都死翘翘了，再空处端口来。</p><p>等待的时间设为2MSL，MSL是Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网络上存在的最长时间，超过这个时间报文将被丢弃。因为TCP报文基于是IP协议的，而IP头中有一个TTL域，是IP数据包可以经过的最大路由数，每经过一个处理他的路由器此值就减1，当此值位0则数据包将被丢弃，同时发送ICMP报文通知源主机。协议规定MSL位2分钟，实际应用中常用的是30秒，1分钟和两分钟等。</p><p>还有一种情况就是，B超过了2MSL的时间，依然没有收到他发的FIN的ACK，怎么办呢？按照TCP的原理，B当然还会重发FIN，这个时候A再收到这个包之后，A就表示，我已经在这里等了这么长时间了，已经仁至义尽了，之后的我都不会认了。于是就直接发送RST，B就知道A早就跑路了。</p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机 </tag>
            
            <tag> 网络 </tag>
            
            <tag> TCP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>DNS协议</title>
      <link href="/2020/10/20/DNS%E5%8D%8F%E8%AE%AE/"/>
      <url>/2020/10/20/DNS%E5%8D%8F%E8%AE%AE/</url>
      
        <content type="html"><![CDATA[<h3 id="DNS协议"><a href="#DNS协议" class="headerlink" title="DNS协议"></a>DNS协议</h3><h4 id="DNS服务器"><a href="#DNS服务器" class="headerlink" title="DNS服务器"></a>DNS服务器</h4><p>在网络世界中，你肯定记得住网站的名称，但是很难记住网站的IP地址，因而也需要一个地址簿，就是DNS服务器。</p><p>由此可见，DNS在日常生活中多么重要。每个人上网，都需要访问它，但是同时，这对它来讲也是非常大的挑战。一旦它出了故障，整个互联网都将瘫痪。另外，上网的人分布在全世界各地，如果大家都去同一个地方访问某一台服务器，时延将会非常大。因而，<code>DNS服务器，一定要设置成高可用、高并发和分布式的</code>。</p><p>于是就有了这样树状的层次结构。</p><p><img src="https://static01.imgkr.com/temp/63de54c0f60146e3b5f734d3c7a0fb73.png" alt="image-20201114200828449"></p><ul><li><p>根DNS服务器：返回顶级域DNS服务器的IP地址；</p></li><li><p>顶级域DNS服务器：返回权威DNS服务器的IP地址；</p></li><li><p>权威DNS服务器：返回相应主机的IP地址。</p></li></ul><h4 id="DNS解析流程"><a href="#DNS解析流程" class="headerlink" title="DNS解析流程"></a>DNS解析流程</h4><p>为了提高DNS的解析性能，很多网络都会就近部署DNS缓存服务器。于是，就有了以下的DNS解析流程。</p><ol><li>电脑客户端会发出一个DNS请求，问<code> www.163.com</code>的IP是啥，并发给<code>本地域名服务器（本地DNS）</code>。那本地域名服务器（本地DNS）是什么呢？如果是通过DHCP配置，本地DNS是由你的网络服务商，如电信、移动等自动分配，它通常在网络服务商的某个机房。</li><li>本地DNS收到来自客户端的请求。你可以想象这台服务器上缓存了一张域名与之对应IP地址的大表格。如果能找到<code>www.163.com</code>，它直接就返回IP地址。如果没有，本地DNS就回去问它的根域名服务器：“老大，能告诉我<code>www.163.com </code>的 IP地址吗？”根域名服务器是最高层次，全球共有13套。他不直接用于域名解析，但能指明一条道路。</li><li>根DNS收到来自本地DNS的请求，发现后缀是 .com ，说 ：“噢，<code>www.163.com</code> 啊，这个域名是由.com区域管理，我给你它的顶级域名服务器地址，你去问问它把。”</li><li>本地DNS转向问顶级域名服务器：“老二，你能告诉我<code>www.163.com</code>的IP地址吗？” 顶级域名服务器就是大名鼎鼎的比如.com、.net.、.org这些一级域名，它负责管理二级域名，比如163.com，所以他能提供一条更清晰的方向。</li><li>顶级域名服务器说：“我给你负责<code>www.163.com</code> 区域的权威DNS服务器的地址，你去问他应该能问道。”</li><li>本地DNS转向问权威DNS服务器：“您好，<code>www.163.com</code>对应的IP地址是啥？” 163.com的权威DNS服务器，它是域名解析结果的原出处。为啥叫权威呢？就是我的域名我做主。</li><li>权威DNS服务器查询后将对应的IP地址告诉本地DNS。</li><li>本地DNS再将IP地址返回客户端，客户端和目标建立连接。</li></ol><p><img src="https://static01.imgkr.com/temp/d6601ca92b5341da92465570cd096614.png" alt="image-20201114202816067"></p>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机 </tag>
            
            <tag> 网络 </tag>
            
            <tag> DNS </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Http连接管理</title>
      <link href="/2020/10/20/HTPP%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86/"/>
      <url>/2020/10/20/HTPP%E8%BF%9E%E6%8E%A5%E7%AE%A1%E7%90%86/</url>
      
        <content type="html"><![CDATA[<h3 id="HTPP连接管理"><a href="#HTPP连接管理" class="headerlink" title="HTPP连接管理"></a>HTPP连接管理</h3><h4 id="短链接"><a href="#短链接" class="headerlink" title="短链接"></a>短链接</h4><p>HTTP 协议最初（0.9/1.0）是个非常简单的协议，通信过程采用了简单的“请求-= - 应答” 方式。</p><p>它底层的数据传输基于TCP/IP，每次发送请求前需要先于服务器建立连接，收到响应报文后立即关闭连接。</p><p>因为客户端与服务器的整个连接过程很短暂，不会与服务器保持长时间的连接状态，所以就被称为“<code>短链接</code>”。</p><p>短链接的缺点相当严重，因为在TCP协议里，建立连接和关闭连接都是非常“<code>昂贵</code> ” 的操作。TCP建立连接要有“<code>三次握手</code>”，发送3个数据包，需要一个RTT；关闭连接是“<code>四次挥手</code>”，需要2个RTT。</p><p>而 HTTP 的一次简单“请求 - 响应”通常只需要 4 个包，如果不算服务器内部的处理时间，最多是 2 个 RTT。这么算下来，浪费的时间就是“3÷5=60%”，有三分之二的时间被浪费掉了，传输效率低得惊人。</p><p><img src="https://static01.imgkr.com/temp/cbf74426ab20464cb9b60852afdb8005.png" alt="img"></p><p>单纯地从理论上讲，TCP 协议你可能还不太好理解，我就拿打卡考勤机来做个形象的比喻吧。</p><p>假设你的公司买了一台打卡机，放在前台，因为这台机器比较贵，所以专门做了一个保护罩盖着它，公司要求每次上下班打卡时都要先打开盖子，打卡后再盖上盖子。</p><p>可是偏偏这个盖子非常牢固，打开关闭要费很大力气，打卡可能只要 1 秒钟，而开关盖子却需要四五秒钟，大部分时间都浪费在了毫无意义的开关盖子操作上了。</p><p>可想而知，平常还好说，一到上下班的点在打卡机前就会排起长队，每个人都要重复“开盖 - 打卡 - 关盖”的三个步骤，你说着急不着急。</p><p>在这个比喻里，打卡机就相当于服务器，盖子的开关就是 TCP 的连接与关闭，而每个打卡的人就是 HTTP 请求，很显然，短连接的缺点严重制约了服务器的服务能力，导致它无法处理更多的请求。</p><h4 id="长连接"><a href="#长连接" class="headerlink" title="长连接"></a>长连接</h4><p>针对短链接暴露出的缺点，HTPP协议就提出了“<code>长连接</code>” 的通信方式，也叫<code>持久连接</code>、<code>连接保活</code>、<code>连接复用</code>。</p><p>其实解决办法也很简单，用的就是 “<code>成本均摊</code>” 的思路，既然TCP的连接和关闭非常耗时间，难么就把这个时间成本由原来的一个“<code>请求 - 应答</code>” 均摊到多个 “<code>请求 - 应答</code>” 上。</p><p><img src="https://static01.imgkr.com/temp/4671de88ec9e4c46a9db1eac6a57bcf3.png"></p><p>在短连接里发送了三次 HTTP“请求 - 应答”，每次都会浪费 60% 的 RTT 时间。而在长连接的情况下，同样发送三次请求，因为只在第一次时建立连接，在最后一次时关闭连接，所以浪费率就是“3÷9≈33%”，降低了差不多一半的时间损耗。显然，如果在这个长连接上发送的请求越多，分母就越大，利用率也就越高。</p><p>继续用刚才的打卡机的比喻，公司也觉得这种反复“开盖 - 打卡 - 关盖”的操作太“反人类”了，于是颁布了新规定，早上打开盖子后就不用关上了，可以自由打卡，到下班后再关上盖子。</p><p>这样打卡的效率（即服务能力）就大幅度提升了，原来一次打卡需要五六秒钟，现在只要一秒就可以了，上下班时排长队的景象一去不返，大家都开心。</p><h4 id="连接相关的头字段"><a href="#连接相关的头字段" class="headerlink" title="连接相关的头字段"></a>连接相关的头字段</h4><p>由于长连接对性能的改善效果非常显著，所以在HTTP/1.1 中的连接都会默认启用长连接。不需要用什么特殊的头字段指定，只要向服务器发送了第一次请求，后续的请求都会重复利用第一次打开的TCP连接，也就是长连接，在这个连接上收发数据。</p><p>当然，我们可以在请求头里明确地要求使用长连接机制，使用的字段是Connection，值是“keep-alive”。</p><p>不过不管客户端是否显示要求长连接，如果服务器支持长连接，他总会在响应报文里放一个“<code>Connection：keep-alive</code>” 字段，告诉客户端：“我是支持长连接的，接下来就用这个TCP连接一直收发数据吧”。</p><p>因为TCP连接长时间不关闭，服务器必须在内存里保存它的状态，这就占用了服务器的资源。如果有大量的空闲长连接只连不发，就会很快耗费服务器的资源，导致服务器无法为真正有需要的用户提供服务。</p><p>所以，长连接也需要在恰当的时间关闭，不能永远保持与服务器的连接，这在客户端或者服务器都可以做到。</p><p>在客户端，可以在请求头里加上“<code>Connection：close</code>”字段，告诉服务器：“这次通信后就关闭连接”。服务器看到这个字段，就知道客户端要主动关闭连接，于是在响应报文里也家伙是那个这个字段，发送之后就调用Socket API关闭TCP连接。</p><blockquote><p>服务器通常不会主动关闭连接，但也可以使用一些策略。拿Nginx来举例，它有两种方式：</p></blockquote><ol><li>使用“<code>keepalive_timeout</code>”  指令，设置长连接的超时时间，如果在一段时间内连接上没有任何数据收发就主动断开连接，避免空闲连接占用系统资源。</li><li>使用“<code>keepalive_requests</code>” 指令，设置长连接上可发送的最大请求次数。比如设置成1000，那么但Nginx在这个连接上处理了1000个请求后，也会主动断开连接。</li></ol><h4 id="对头阻塞"><a href="#对头阻塞" class="headerlink" title="对头阻塞"></a>对头阻塞</h4><p>看完了短链接和长连接，接下来就要说到著名的 “队头阻塞”了。</p><p>“<code>队头阻塞</code>” 与短链接和长连接无关，而是由HTTP基本的 “请求 - 应答” 模型所导致的。</p><p>因为HTTP规定报文必须是 “一发一收”，这就形成了一个先进先出的 “串行” 队列。队列里的请求没有轻重缓急的优先级，只有入队的先后顺序，排在前面的请求最优先处理。</p><p>如果队首的请求因为处理的太慢耽误了时间，那么队列里后面的所有请求也不得跟着一起等待，结果就是其他的请求承担了不应有的时间成本。</p><p><img src="https://static01.imgkr.com/temp/b460c2c9aba24ab7894a7a99039cfd0c.png"></p><p>还是用打卡机做个比喻。</p><p>上班的时间点上，打击都在排队打卡，可这个时候偏偏在最前面的那个人遇到了打卡机故障，怎么也不能打卡成功，急得满头大汗。等找人把打卡机修好，后面排队的所有人全吃了。</p><h4 id="性能优化"><a href="#性能优化" class="headerlink" title="性能优化"></a>性能优化</h4><p>因为“请求 - 应答” 模型不能变，所以“对头阻塞” 问题在HTPP/1.1 里无法解决，只能<strong>缓解</strong>，有什么办法呢？</p><p>公司里可以在多买几台打卡机放在前台，这样大家可以不用挤在一个队伍里，分散打卡，一个队伍偶尔阻塞也不要紧，可以改换到其他不阻塞的队伍。</p><p>这在HTTP里就是“<code>并发连接</code>”，也就是同时对一个域名发起多个长连接，用数量来解决质量的问题。</p><p>但这种方式也存在缺陷。如果每个客户端都想自己快，建立很多个连接，用户数 × 并发数就会是天王数字。服务器的资源根本扛不住，或者被服务器认为是而已攻击，反而会造成 “拒绝服务”。</p><p>所以，HTTP协议建议客户端使用并发，但不能 “<code>滥用</code>” 并法。RFC2616里明确限制每个客户端最多并发2个连接。不过时间证明这个数字实在是太小了，众多浏览器都无视标准，把这个上限提高了到了6~8。后来修订的RFC7230也就“顺水推舟”，取消了这个“2” 的限制。</p><p>但“<code>并发连接</code>” 所压榨出的性能也跟不上高速发展的互联网无无止境的需求，还有别的什么办法吗？</p><p>公司发展的太快了，员工越来越多，上下班打卡成了迫在眉睫的大问题。前台空间有限，放不下更多的打卡机了，怎么办？那就多开几个打卡的地方，每个楼层、办公区的入口也放上三四台打卡机，把人进一步分流，不要都往前台挤。</p><p>这个就是 <strong>“<code>域名分片（domain sharding）</code>”</strong> 技术，还是用数量来解决质量的思路。</p><p>HTPP协议和浏览器不是限制并发连接数量吗？好，那我就多开几个域名，比如shard1.chrono.com、shard2.chrono.com，而这些域名都指向同一台服务器，这样实际长连接的数量就又上去了，真是美滋滋。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul><li>早期的HTTP协议使用短链接，收到响应后就立即关闭连接，效率很低；</li><li>HTTP/1.1 默认启用长连接，在一个连接上收发多个请求响应，提高了传输效率；</li><li>服务器会发送“<code>Connection: keep-alive</code>” 字段表示启用了长连接；</li><li>报文头里如果有 “<code>Connection: close</code>”  就意味着长连接即将关闭；</li><li>过多的长连接会占用服务器资源，所以服务器会用一些策略有选择地关闭长连接；</li><li>“<code>对头阻塞</code>” 问题会导致性能下降，可以用 “<code>并发连接</code>” 和 “<code>域名分片</code>”  的技术缓解。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机 </tag>
            
            <tag> 网络 </tag>
            
            <tag> HTTP </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>HTTP的Cookie机制</title>
      <link href="/2020/10/20/HTTP%E7%9A%84Cookie%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/10/20/HTTP%E7%9A%84Cookie%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<h3 id="HTTP的Cookie机制"><a href="#HTTP的Cookie机制" class="headerlink" title="HTTP的Cookie机制"></a>HTTP的Cookie机制</h3><h4 id="Cookie的工作过程"><a href="#Cookie的工作过程" class="headerlink" title="Cookie的工作过程"></a>Cookie的工作过程</h4><p>当用户通过浏览器第一次访问服务器的时候，服务器肯定不知道他的身份的。所以，就要创建一个独特的身份标识数据，格式是 “<code>key=value</code>”，然后放进<code>Set-Cookie</code>字段里，随着响应报文一同发给浏览器。</p><p>浏览器收到响应报文，看到里面有<code>Set-Cookie</code>，就知道这是服务器给的身份标识，于是就保存起来，下次请求的时候就自动把这个值放进<code>Cookie</code>字段里发给服务器。</p><p>因为第二次请求里面有了<code>Cookie</code>字段，服务器就知道这个用户不是新人，之前来过，就可以拿出Cookie里的值，识别出用户的身份，然后提供个性化的服务。</p><p>不过因为服务器的 “<code>记忆能力</code>” 实在是太差，一张小纸条经常不够用。所以，服务器有时会在响应头里添加多个 <code>Set-Cookie</code>，存储多个 “<code>key=value</code>”。但浏览器这边发送时不需要多个<code>Cookie</code>字段，只需要在一行里用 “<code>;</code>” 隔开就行。</p><p><img src="https://static01.imgkr.com/temp/8cc8f3668a994f2eb3425a30c1ce04a3.png" alt="img"></p><p>从这张图中我们也能够看到，Cookie是由浏览器负责存储的，而不是操作系统。所以，他是”浏览器绑定“ 的，只能在本浏览器内生效。</p><p>如果你换个浏览器或者换台电脑，新的浏览器里没有服务器对应的Cookie，就好像时脱掉了贴着纸条的衣服，”健忘“ 的服务器也就认不出来了，只能再走一遍Set-Cookie 流程。</p><p>Cookie的属性</p><p>说到这里，你应该知道了，Cookie就是服务器委托浏览器存储在客户端里的一些数据，而这些数据通常都会记录用户的关键识别信息。所以，就需要在“<code>key=value</code>” 外再用一些手段来保护，防止外泄或窃取，这些手段就是Cookie的属性。</p><p><img src="https://static01.imgkr.com/temp/e1b21f941464457398ba971f5283518f.png"></p><p>首先，我们应该<code>设置Cookie的生存周期</code>，也就是它的有效期，让他只能在一段时间内可用，就像是食品的“保鲜期”，一旦超时这个期限浏览器就认为时Cookie失效，在存储里删除，也不会发送给服务器。</p><p>Cookie的有效期可以使用Expires 和 Max-Age 两个属性来设置。</p><p>“<code>Expires</code>” 俗称 “过期时间”，用的时绝对的时间点，可以理解为“截止日期”。“<code>Max-Age</code>” 用的时相对时间，单位时秒，浏览器用收到报文的时间点再加上Max-Age，就可以得到失效的绝对时间。</p><p>Expires 和 Max-Age 可以同时出现，两者的失效时间可以一致，也可以不一致，当浏览器会优先采用Max-Age计算失效期。</p><p>比如在这个例子里，Expires 标记的过期时间是“GMT 2019 年 6 月 7 号 8 点 19 分”，而 Max-Age 则只有 10 秒，如果现在是 6 月 6 号零点，那么 Cookie 的实际有效期就是“6 月 6 号零点过 10 秒”。</p><p>其次，我们需要“<code>设置Cookie的作用域</code>”，让浏览器仅发送给特定的服务器和URI，避免被其他网站盗用。</p><p>作用域的设置比较简单，“<code>Domain</code>” 和 ”<code>Path</code>“ 指定了Cookie所属的域名和路径，浏览器在发送Cookie前会从URI中提取出host和path部分，比对Cookie的属性。如果不满足条件，就不会在请求头里发送Cookie。</p><p>最后要考虑的就是”<code>Cookie的安全性了</code>“，尽量不要让服务器意外的人看到。</p><p>写过前端的同学一定知道，在JS脚本里可以用document.cookie来读写Cookie数据，这就带来了安全隐患，有可能会导致”跨站脚本“（XSS）攻击窃取数据。</p><p>属性 ”<code>HttpOnly</code>“ 会告诉浏览器，此Cookie只能通过浏览器HTTP协议传输，禁止其他方式访问，浏览器的JS引擎就会禁用document.cookie等一切相关的API，脚本攻击也就无从谈起了。</p><p>另外一个属性 ”<code>SameSite</code>“ 可以防范 ”<code>跨站请求伪造</code>“（CSRF）攻击，设置成 ”SameSite=Strict“ 可以严格限定Cookie不能随着跳转连接跨站发送，而”<code>SameSit=Lax</code>“ 则略宽松一点，允许GET/HEAD等安全方法，但禁止POST跨站发送。</p><p>还有一个属性叫 ”Secure“，表示这个Cookie仅能用HTTPS协议加密传输，明文的HTTP协议会禁止发送。但Cookie本身不是加密的，浏览器里还是以明文的形式存在。</p><h4 id="Cookie的应用"><a href="#Cookie的应用" class="headerlink" title="Cookie的应用"></a>Cookie的应用</h4><p>现在我们回到最开始的话题，有了Cookie，服务器就有了 “<code>记忆能力</code>”，能够保存“状态”，那么应该如何使用Cookie呢？</p><p>Cookie最基本的一个用途就是<code>身份识别</code>，保存用户的登录信息，实现会话事务。</p><p>比如，你用账号和密码登录某电商，登录成功后网站服务器就会发给浏览器一个Cookie，内容大概是“<code>name=yourid</code>”，这样就成功地把身份标签贴在了你身上。</p><p>之后你在网站里面随便访问哪件商品的页面，浏览器都会自动把身份Cookie发送给服务器，所以服务器总会知道你的身份，一方面免去了重复登陆的麻烦，另一方面也能够自动记录你的浏览记录和购物下单（在后台数据库或者也用Cookie），实现了 “<code>状态保持</code>”。</p><p>Cookie的另一个常见用途就是<code>广告追踪</code>。</p><p>你上网的时候肯定看过很多的广告图片，这些图片背后都是广告商网站（例如Google），他会“偷偷地” 给你贴上Cookie小纸条，这样你上其他地网站，别地广告就能能用Cookie读出你的身份，然后做行为分析，再推给你广告。</p><p>这种Cookie不是由访问地主站存储地，所以又叫 “第三方Cookie”。如果广告商势力很大，广告到处都是，那么就比较“恐怖”了，无论你走到哪里他都会通过Cookie认出你来，实现广告“精准打击”。</p><p>为了防止滥用Cookie搜集用户隐私，互联网组织相继提出了DNT（Do Not Track）和 P3P，但实际作用不大。</p><h4 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h4><ul><li>Cookie 是服务器委托浏览器存储地一些数据，让服务器有了 “记忆能力”；</li><li>响应报文使用Set-Cookie字段发送 “key=value” 形式的Cookie值；</li><li>请求报文里用地Cookie字段发送多个Cookie值；</li><li>为了保护Cookie，还要给他设置有效期、作用域等属性，常用的由Max-Age、Expires、Domain、HttpOnly等；</li><li>Cookie最基本的用途是身份识别，实现有状态的会话事务。</li></ul>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机 </tag>
            
            <tag> 网络 </tag>
            
            <tag> HTTP </tag>
            
            <tag> Cookie </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>计算机网络体系</title>
      <link href="/2020/10/19/%E8%AE%A1%E7%AE%97%E7%BA%A7%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/"/>
      <url>/2020/10/19/%E8%AE%A1%E7%AE%97%E7%BA%A7%E7%BD%91%E7%BB%9C%E6%80%BB%E7%BB%93/</url>
      
        <content type="html"><![CDATA[<h3 id="计算级网络总结"><a href="#计算级网络总结" class="headerlink" title="计算级网络总结"></a>计算级网络总结</h3><h3 id="OSI-参考模型"><a href="#OSI-参考模型" class="headerlink" title="OSI 参考模型"></a>OSI 参考模型</h3><ul><li><p>OSI 参考模型是又国际标准组织（ISO）于1984年提出的分层网络体系结构模型，共分为七层结构，每层完成特定的网络功能。</p><p><img src="https://static01.imgkr.com/temp/2b44d748e33844ee9dd86b2a2458644e.png"></p></li></ul><ul><li><p>OSI参考模型的通信过程</p><p><img src="https://static01.imgkr.com/temp/61a852b45d164ea7ae8d571cc181adef.png" alt="image-20201018162458038"></p></li></ul><ul><li><p>OSI 参考模型的数据通信过程</p><p><img src="https://static01.imgkr.com/temp/1ad7e39cb7ce42768c8328bf179f7554.png" alt="image-20201018162613073"></p></li></ul><ul><li>为什么需要数据封装<ul><li>增加控制信息：每层都会给用户数据增加对应的头生成对应的协议数据单元（PDU）</li><li>控制信息主要包括<ul><li>地址（Address）：标识发送端和接收端</li><li>用于差错检测编码</li><li>协议控制：实现协议功能的附加信息，如: 优先级（priority）、服务质量（QoS）、 和安全控制等 </li></ul></li></ul></li></ul><h4 id="物理层"><a href="#物理层" class="headerlink" title="物理层"></a>物理层</h4><h6 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h6><p><img src="https://static01.imgkr.com/temp/965cb3dfb69c41dd92fcf40cd3a2c31f.png" alt="image-20201018165057660"></p><p>实现每一个比特的传输。</p><h6 id="通信方式"><a href="#通信方式" class="headerlink" title="通信方式"></a>通信方式</h6><p>根据信息在传输线上的传送方向，分为以下三种通信方式：</p><ul><li>单工通信：单向传输  例： 电视台与电视</li><li>半双工通信：双向交替传输  例：对讲机</li><li>全双工通信：双向同时传输 </li></ul><h4 id="数据链路层"><a href="#数据链路层" class="headerlink" title="数据链路层"></a>数据链路层</h4><p><img src="https://static01.imgkr.com/temp/cef2ba82d46f4097a616b864b168ddcf.png" alt="image-20201018165137817"></p><ul><li><p>负责结点-结点（node-to-node）的数据传输</p></li><li><p>组帧：将网络层传输下来的分组添加首部和尾部，用于标记帧的开始和结束</p></li><li><p>物理寻址： 物理层没办法完成寻址，数据链路层在帧头部加入物理地址标识数据</p><p>​    <img src="https://static01.imgkr.com/temp/47b597db1e1144778da75ea5dd396afe.png" alt="image-20201018170157118"></p></li><li><p>差错控制： 检测并重传损失帧或丢失帧，避免重复帧</p></li><li><p>流量控制：降低接收端和发送端传输速度差，避免淹没发送端</p></li></ul><h4 id="网络层"><a href="#网络层" class="headerlink" title="网络层"></a>网络层</h4><p><img src="https://static01.imgkr.com/temp/1bcf1cb3184d4373aba5b28a1b2332b2.png" alt="image-20201019212313385"></p><h6 id="功能-1"><a href="#功能-1" class="headerlink" title="功能"></a>功能</h6><ul><li><p>负责源主机到目的主机数据分组</p><ul><li>可能穿越多个网络</li></ul></li><li><p>逻辑寻址</p><ul><li>全局唯一逻辑地址，确保数据分组被送达目的主机，如IP地址。</li></ul></li><li><p>路由</p><ul><li>路由器互联网络，并路由分组至最终目的地</li><li>路径选择</li></ul></li><li><p>分组转发</p></li></ul><p><img src="https://static01.imgkr.com/temp/832c0373a57c48538b4ff0714e1bd825.png" alt="image-20201019212615562"></p><h4 id="传输层"><a href="#传输层" class="headerlink" title="传输层"></a>传输层</h4><h6 id="功能-2"><a href="#功能-2" class="headerlink" title="功能"></a>功能</h6><p><img src="https://static01.imgkr.com/temp/72e03f1a755d49efb3708fe22db93fc1.png" alt="image-20201019212652451"></p><ul><li><p>负责源-目的（端到端）（进程间）完整的报文传输</p></li><li><p>分段与重组</p></li><li><p>SAP寻址</p><ul><li>确保将完整报文提交给正确进程，如端口号：</li></ul></li></ul><p><img src="https://static01.imgkr.com/temp/35bc08e80bbb448491ab709bcc22960e.png" alt="image-20201019212855262"></p><ul><li><p>连接控制：负责端到端的连接建立，维护，拆除。</p></li><li><p>流量控制：解决端到端的流量控制，负责匹配两端传输速度。</p></li><li><p>差错控制</p></li></ul><h4 id="会话层"><a href="#会话层" class="headerlink" title="会话层"></a>会话层</h4><p>  <img src="https://static01.imgkr.com/temp/40c9bd08213e4080b4d68b3f730b9330.png" alt="image-20201019221011219"></p><h6 id="功能-3"><a href="#功能-3" class="headerlink" title="功能"></a>功能</h6><ul><li>对话控制</li><li>同步： 在数据流中插入 同步点</li><li>是最薄的一层</li></ul><h4 id="表示层"><a href="#表示层" class="headerlink" title="表示层"></a>表示层</h4><p><img src="https://static01.imgkr.com/temp/1340b0ab60b04614a472c437aae6c709.png" alt="image-20201019221148901"></p><h6 id="功能-4"><a href="#功能-4" class="headerlink" title="功能"></a>功能</h6><ul><li><p>数据表示转化</p><ul><li>转换为主机独立的编码</li></ul></li><li><p>加密/解密</p></li><li><p>压缩/解压缩</p></li></ul><h4 id="应用层"><a href="#应用层" class="headerlink" title="应用层"></a>应用层</h4><p>  <img src="https://static01.imgkr.com/temp/fdf8d8c3500b4dff8cb2c3169179c303.png" alt="image-20201019221516060"></p><h6 id="功能-5"><a href="#功能-5" class="headerlink" title="功能"></a>功能</h6><ul><li><p>支持用户通过用户代理（如浏览器）或网络接口使用网络（服务）</p></li><li><p>典型的应用层服务：</p><ul><li>文件传输（FTP）</li><li>电子邮件（SMTP）</li><li>Web（HTTP）</li></ul></li></ul><h3 id="TCP-IP模型"><a href="#TCP-IP模型" class="headerlink" title="TCP/IP模型"></a>TCP/IP模型</h3><p><img src="https://static01.imgkr.com/temp/36981dbe707a49fba482528afb19f755.png" alt="image-20201019221916512"></p><h4 id="五层参考模型"><a href="#五层参考模型" class="headerlink" title="五层参考模型"></a>五层参考模型</h4><ol><li>综合了OIS和TCP/IP的优点</li><li>应用层：支持各种网络应用，FTP，SMTP，HTTP</li><li>传输层：进程-进程的数据传输，TCP，UDP </li><li>网络层：源主机到目的主机的数据分组路由与转发，IP协议、路由协议等</li><li>链路层：相邻网络元素（主机、交换机、路由器）的数据传输。</li><li>物理层：比特传输</li></ol>]]></content>
      
      
      <categories>
          
          <category> 计算机网络 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 计算机 </tag>
            
            <tag> 网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🧔Mysql索引</title>
      <link href="/2020/09/04/MySql%20%E7%B4%A2%E5%BC%95%E6%A6%82%E8%A7%88/"/>
      <url>/2020/09/04/MySql%20%E7%B4%A2%E5%BC%95%E6%A6%82%E8%A7%88/</url>
      
        <content type="html"><![CDATA[<h3 id="索引是万能的吗？"><a href="#索引是万能的吗？" class="headerlink" title="索引是万能的吗？"></a>索引是万能的吗？</h3><p>首先要了解什么是索引(index)。数据库中的索引，就好比一本书的目录，它可以帮我们快速进行特定值的定位与查找，从而加快数据查询的效率。</p><p>索引就是帮助数据库管理系统搞笑获取数据的数据结构。</p><p>索引不是万能的，在有些情况下使用索引反而会让效率变低。</p><p>在数据表中的数据行数比较少的情况下，比如不到1000行，是不需要创建索引的。另外，当数据重复度大，比如高于10%的时候，也不需要对这个字段创建索引。</p><h3 id="索引的种类有哪些"><a href="#索引的种类有哪些" class="headerlink" title="索引的种类有哪些"></a>索引的种类有哪些</h3><p>从功能逻辑上说，索引主要有4种，分别是普通索引、唯一索引、主键索引和全文索引。</p><p>普通索引是基础的索引，没有任何约束，主要用于提高查询效率。唯一索引就是在普通索引的基础上增加了数据唯一性的约束，在一张数据表里可以有多个唯一索引。主键索引在唯一索引的基础上增加了不为空的约束，也就是NOT NULL + UNIQUE，一张表里最多只有一个主键索引。全文索引用的不多，MySQL自带的全文索引只支持英文。我们通常可以采用专门的全文搜索引擎，比如ES。</p><p>其实前三种索引（普通索引，唯一索引，主键索引）都是一类索引，只不过对数据的约束性逐渐提升。在一张数据表中只能有一个主键索引，这是由主键索引的物理方式决定的，因为数据存储在文件中只能按照一种顺序进行存储。但可以有多个普通索引或多个唯一索引。</p><p>按照物理实现方式，索引可以分为2种：聚集索引和非聚集索引。我们也可以把非聚集索引称为二级索引或者辅助索引。</p><h4 id="聚集索引"><a href="#聚集索引" class="headerlink" title="聚集索引"></a>聚集索引</h4><p>聚集索引可以按照主键来排序存储数据，这样在查找行的时候非常有效。举个例子，如果是一本汉语字典，我们想要查找“数”这个字，直接在书中找汉语拼音的位置即可，也就是拼音shu。这样找到了索引的位置，在他后面就是我们想要找的数据行。</p><h4 id="非聚集索引"><a href="#非聚集索引" class="headerlink" title="非聚集索引"></a>非聚集索引</h4><p>在数据库系统会有单独的存储空间存放非聚集索引，这些索引项是按照顺序存储的，但索引项指向的内容是随机存储的。也就是说系统会进行两次查找，第一次先找到索引，第二次找到索引对应的位置取出数据行。非聚集索引不会把索引指向的内容像聚集索引一样直接放到索引的后面，而是维护单独的索引表（只维护索引，不维护索引指向的数据），为数据的检索提供方便。还以汉语字典为例，如果想要查找“数”字，那么按照部首查找的方式，先找到“数”字的偏旁部首，然后这个目录会告诉我们“数字”存放在低多少页，我们再去指定的页码找到这个字。</p><p>聚集索引与非聚集索引的原理不同，在使用上也有一些区别：</p><ol><li>聚集索引的叶子节点存储的就是我们的数据记录，非聚集索引的叶子节点存储的是数据位置。非聚集索引不会影响数据表的物理存储结构。</li><li>一个表只能有一个聚集索引，因为只能有一种排序存储的方式，但可以有多个非聚集索引，也就是多个索引目录提供数据检索，</li><li>使用聚集索引的时候，数据的查询效率高，但如果对数据进行插入，删除，更新等操作，效率会比非聚集索引低。</li></ol><p>建议：</p><ol><li>对WHERE子句的字段建立索引，可以大幅提升查询效率。</li><li>采用聚集索引进行数据查询，比使用非聚集索引查询效率略高。如果查询次数较多，还是尽量使用主键索引进行数据查询。</li></ol><p>除了业务逻辑和物理实现方式，索引还可以按照字段个数进行划分，分成单一索引和联合索引。</p><p>索引列为一列时为单一索引；多个列组合在一起创建的索引叫做联合索引。</p><p>创建联合索引时，我们需要注意创建时的顺序问题，因为联合索引（x，y，z）和（z，y，x）在使用的时候效率可能会存在差别。</p><p>这里需要说明的是联合索引存在最左匹配原则，也就是按照最左优先的方式进行索引的匹配。比如刚才举例的 (x, y, z)，如果查询条件是 WHERE x=1 AND y=2 AND z=3，就可以匹配上联合索引；如果查询条件是 WHERE y=2，就无法匹配上联合索引。</p><h3 id="索引原理"><a href="#索引原理" class="headerlink" title="索引原理"></a>索引原理</h3><p>数据库服务器的两种存储介质，分别为硬盘和内存。内存属于临时存储，容量有限，而当发生意外时会造成数据丢失；硬盘相当于永久存储介质，这也是为什么我们需要把数据保存到硬盘上。</p><p>虽然内存的读取速度很快，但我们还是需要将索引存放到硬盘上，这样的话，当我们在硬盘上进行查询时，也就产生了磁盘的I/O操作。相比于内存的存取来说，硬盘的I/O存取消耗的时间要高很多，所消耗的时间也就越大。如果我们能让索引的数据结构尽量减少硬盘的I/O操作，所消耗的时间也就越小。</p><h4 id="二叉树的局限性"><a href="#二叉树的局限性" class="headerlink" title="二叉树的局限性"></a>二叉树的局限性</h4><p>二分查找法是一种高效的数据检索方式，时间复杂度为O(log2n），是不是采用二叉树就适合作为索引的数据结构呢？</p><h4 id="二叉搜索树"><a href="#二叉搜索树" class="headerlink" title="二叉搜索树"></a>二叉搜索树</h4><p>假设搜索插入的数值为key：</p><ol><li>如果key大于根节点，则在右子树种进行查找；</li><li>如果key小于根节点，则在左子树中进行查找；</li><li>如果key等于根节点，也就是找到了这个节点，返回根节点即可。</li></ol><p>例子，对数列（34，22，89，5，23，77，91）创造出来的二叉树如图：<br><img src="https://static01.imgkr.com/temp/c465fc5c2d85480488f42e1ac8164d6c.png" alt="image.png"></p><p>但是存在特殊的情况，就是有时候二叉树的深度非常大。比如（5，22，23，34，77，89，91）二叉搜索树如图所示：<br><img src="https://static01.imgkr.com/temp/556038be101c4745bdffed1dd8073e5a.png" alt="image.png"></p><p>可以看出来第一个数的深度时3，也就是说最多只需要3次比较，就可以找到节点，而第二棵树的深度时7，最多需要7次比较才能找到节点。</p><p>第二棵树也属于二分查找树，但是性能已经退化成了一条链表，查找数据的时间复杂度编程了O(n)。为了解决这个问题，人们提出了平衡二叉搜索树（AVL树），它在二分搜索树的基础上增加了约束，每个节点的左子树和右子树的高度不能超过1，也就是左子树和右子树仍然为平衡二叉树。</p><p>常见的平衡二叉树有很多种，包括了平衡二叉树、红黑树、数堆、伸展树。平衡二叉搜索树是最早提出来的自平衡二叉搜索树，当我们提到平衡二叉树时一般指的就是平衡二叉搜索树。事实上第一棵树就属于平衡二叉搜索树，搜索时间复杂度就是O(log2n)。</p><p>数据查询的时间主要依赖于磁盘I/O的次数，如果我们采用二叉树的形式，即使通过平衡二叉树进行了改进，树的深度也是O(log2n)，当n比较大时，深度也是比较高的，比如：<br><img src="https://static01.imgkr.com/temp/766d4b5674094a7cbb9af0c478263bb6.png" alt="image.png"></p><p>每访问一次节点就需要进行一次磁盘 I/O 操作，对于上面的树来说，我们需要进行 5 次 I/O 操作。虽然平衡二叉树比较的效率高，但是树的深度也同样高，这就意味着磁盘 I/O 操作次数多，会影响整体数据查询的效率。</p><p>针对同样的数据，如果我们把二叉树改成了M叉树呢？当M=3时，同样的31个节点由三叉树进行存储：<br><img src="https://static01.imgkr.com/temp/a6fa9744fb354d2aad0db67964518a26.png" alt="image.png"></p><p>你能看到此时树的高度降低了，当数据量 N 大的时候，以及树的分叉数 M 大的时候，M 叉树的高度会远小于二叉树的高度。</p><h4 id="B树"><a href="#B树" class="headerlink" title="B树"></a>B树</h4><p>如果使用二叉树作为索引的实现结构，会让树变的很高，增加硬盘的I/O次数，影响数据查询的时间。因此一个节点就不能只有2个子节点，而应该允许有M个子节点（M&gt;2）。</p><p>B树的出现就是为了解决这个问题的，英文时Balance Tree，也就是平衡多路搜索树，他的高度远小于平衡二叉树的高度。</p><p>B树的结构如下图所示：</p><p><img src="https://static01.imgkr.com/temp/cd8478bcece9462389cbd47539dd1902.png" alt="image.png"></p><p>B树作为平衡的多路搜索树，他的每一个节点最多可以包括M个子节点，M称为B树的阶。同时你能看到，每个磁盘块种包括了关键字和子节点的指针。如果一个磁盘块种包括了x个关键字，那么指针树就是x+1。对于一个100阶的B树来说，如果由三层的话最多可以存储约100万的索引数据。对于大量的索引数据来说，采用B树的结构是非常合适的，因为树的高度要远小二叉树的高度。</p><p>然后我们来看下如何用 B 树进行查找。假设我们想要查找的关键字是 9，那么步骤可以分为以下几步：</p><ol><li>我们与根节点的关键字 (17，35）进行比较，9 小于 17 那么得到指针 P1；</li><li>按照指针 P1 找到磁盘块 2，关键字为（8，12），因为 9 在 8 和 12 之间， 所以我们得到指针 P2；</li><li>按照指针 P2 找到磁盘块 6，关键字为（9，10），然后我们找到了关键字 9</li></ol><p>你能看出来在 B 树的搜索过程中，我们比较的次数并不少，但如果把数据读取出来然后在内存中进行比较，这个时间就是可以忽略不计的。而读取磁盘块本身需要进行 I/O 操作，消耗的时间比在内存中进行比较所需要的时间要多，是数据查找用时的重要因素，B 树相比于平衡二叉树来说磁盘 I/O 操作要少，在数据查询中比平衡二叉树效率要高。</p><h4 id="B-树"><a href="#B-树" class="headerlink" title="B+树"></a>B+树</h4><p>B+树基于B树做出了改进，主流的DBMS都支持B+树的索引方式，比如MySQL。</p><p>与B树的差异有以下几点：</p><ol><li>k 个孩子的节点就有 k 个关键字。也就是孩子数量 = 关键字数，而 B 树中，孩子数量 = 关键字数 +1。<ol start="2"><li>非叶子节点的关键字也会同时存在在子节点中，并且是在子节点中所有关键字的最大（或最小）。</li><li>非叶子节点仅用于索引，不保存数据记录，跟记录有关的信息都放在叶子节点中。而 B 树中，非叶子节点既保存索引，也保存数据记录。</li><li>所有关键字都在叶子节点出现，叶子节点构成一个有序链表，而且叶子节点本身按照关键字的大小从小到大顺序链接。</li></ol></li></ol><p><img src="https://static01.imgkr.com/temp/752a5cd4890746bea6ee634a923c2b7b.png" alt="image.png"></p><p>比如，我们想要查找关键字 16，B+ 树会自顶向下逐层进行查找：</p><ol><li>与根节点的关键字 (1，18，35) 进行比较，16 在 1 和 18 之间，得到指针 P1（指向磁盘块 2）</li><li>找到磁盘块 2，关键字为（1，8，14），因为 16 大于 14，所以得到指针 P3（指向磁盘块 7）</li><li>找到磁盘块 7，关键字为（14，16，17），然后我们找到了关键字 16，所以可以找到关键字 16 所对应的数据。</li></ol><p>整个过程一共进行了 3 次 I/O 操作，看起来 B+ 树和 B 树的查询过程差不多，但是 B+ 树和 B 树有个根本的差异在于，B+ 树的中间节点并不直接存储数据。这样的好处都有什么呢？</p><p>首先，B+ 树查询效率更稳定。因为 B+ 树每次只有访问到叶子节点才能找到对应的数据，而在 B 树中，非叶子节点也会存储数据，这样就会造成查询效率不稳定的情况，有时候访问到了非叶子节点就可以找到关键字，而有时需要访问到叶子节点才能找到关键字。</p><p>其次，B+ 树的查询效率更高，这是因为通常 B+ 树比 B 树更矮胖（阶数更大，深度更低），查询所需要的磁盘 I/O 也会更少。同样的磁盘页大小，B+ 树可以存储更多的节点关键字。</p><p>不仅是对单个关键字的查询上，在查询范围上，B+ 树的效率也比 B 树高。这是因为所有关键字都出现在 B+ 树的叶子节点中，并通过有序链表进行了链接。而在 B 树中则需要通过中序遍历才能完成查询范围的查找，效率要低很多。</p><p>总结<br>磁盘的 I/O 操作次数对索引的使用效率至关重要。虽然传统的二叉树数据结构查找数据的效率高，但很容易增加磁盘 I/O 操作的次数，影响索引使用的效率。因此在构造索引的时候，我们更倾向于采用“矮胖”的数据结构。</p><p>B 树和 B+ 树都可以作为索引的数据结构，在 MySQL 中采用的是 B+ 树，B+ 树在查询性能上更稳定，在磁盘页大小相同的情况下，树的构造更加矮胖，所需要进行的磁盘 I/O 次数更少，更适合进行关键字的范围查询。</p>]]></content>
      
      
      <categories>
          
          <category> MySQL </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Mysql </tag>
            
            <tag> 数据库 </tag>
            
            <tag> 索引 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🧔Java常见面试题</title>
      <link href="/2020/09/04/Java%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/"/>
      <url>/2020/09/04/Java%E5%B8%B8%E8%A7%81%E9%9D%A2%E8%AF%95%E9%A2%98/</url>
      
        <content type="html"><![CDATA[<h3 id="1-Java面向对象编程三大特征：封装-继承-多态"><a href="#1-Java面向对象编程三大特征：封装-继承-多态" class="headerlink" title="1.Java面向对象编程三大特征：封装 继承 多态"></a>1.Java面向对象编程三大特征：封装 继承 多态</h3><p><strong>封装</strong></p><p>封装把一个对象的属性私有化，同时提供一些可以被外界访问的属性的方法，如果属性不想被外界访问，我们大可不必提供给外界访问。但是如果一个类没有提供给外界访问的方法，那么这个类也没有什么意义了。</p><p><strong>继承</strong></p><p>继承时使用已存在的类的定义作为基础建立新类的技术，新类的定义可以增加新的数据或新的功能，也可以用父类的功能，但不能选择性地继承父类。通过使用继承我们能够非常方便的复用以前的代码。</p><h6 id="关于继承的三点："><a href="#关于继承的三点：" class="headerlink" title="关于继承的三点："></a>关于继承的三点：</h6><p>1.子类拥有父类对象所有的属性和方法(包括私有属性和私有方法)，但是父类中的私有属性和方法子类是无法访问的，<strong>只是拥有</strong>。<br>2.子类可以拥有自己属性和方法，即子类可以对父类进行扩展。<br>3.子类可以用自己的方式实现父类的方法</p><p><strong>多态</strong></p><p>所谓多态就是指程序中定义的应用变量所指向的具体类型和通过该引用变量发出的方法调用在编程时并不确定，而是在程序运行期间才确定的，即一个引用变量到底会指向哪个类的实例对象，该引用变量发出的方法调用到底是哪个类中实现的方法，必须由程序运行期间才能决定。</p><p>在Java中有两种形式可以实现多态:继承和接口</p><h3 id="2-String-StringBuffer-和-StringBuilder的区别是什么？String为什么是不可变的"><a href="#2-String-StringBuffer-和-StringBuilder的区别是什么？String为什么是不可变的" class="headerlink" title="2.String StringBuffer 和 StringBuilder的区别是什么？String为什么是不可变的"></a>2.String StringBuffer 和 StringBuilder的区别是什么？String为什么是不可变的</h3><p>可变性</p><p>简单的来说：String 类中使用的final关键字修饰字符数组保存字符串，private final char value[]，所以String对象是不可变的。</p><pre><code>补充：在Java9之后，String类的实现改用byte数组存储字符串 private final byte[] value</code></pre><p>而StringBuilder 与 StringBuffer 都继承自AbstractStringBuilder类，在AbstractStringBuilder中也是使用字符数组保存字符串char[] value 但是没有用final关键字修饰，所以这两种对象都是可变的，</p><p>线程安全性</p><p>String 中的对象是不可变的，也就可以理解为常量，线程安全。AbstractStringBuilder 是 StringBuilder与StringBuffer的公共父类，定义了一些字符串的基本操作。StringBuffer对方法加了同步锁或者对调用的方法加了同步锁，所以是线程安全的。StringBuilder并没有对方法进行加同步锁，所以是非线程安全的。</p><p>性能</p><p>每次对String类型进行改变的时候，都会产生一个新的String对象，然后将指针指向新的String对象。StringBuffer 每次都会对StringBuffer对象本身进行操作，而不是生成新的对象并未改变对象的引用。相同情况下使用StringBuilder相比使用StringBuffer仅能获得10%~15%左右的性能提升，但却要冒线程不安全的风险。</p><p>对于三者的使用总结：</p><ol><li>操作少量的数据：使用String</li><li>单线程下操作大量数据：使用StringBuilder</li><li>多线程下操作大量数据：使用StringBuffer</li></ol><h3 id="2-Java集合框架"><a href="#2-Java集合框架" class="headerlink" title="2.Java集合框架"></a>2.Java集合框架</h3><p><strong>Collection</strong></p><ol><li>List</li></ol><ul><li>ArrayList Object数组</li><li>Vector Object数组</li><li>LinkedList 双向链表(jdk1.6之前为循环，jdk1.7取消了循环)</li></ul><ol start="2"><li>Set</li></ol><ul><li>HashSet (无需且唯一)：基于HashMap实现的，底层采用HashMap来保存元素</li><li>LinkedHashSet：LinkedHashSet继承于HashSet，并且其内部是通过LinkedHashMap来实现的。</li><li>TreeSet（有序唯一）</li></ul><p>Vector是Java早期早期提供的线程安全的动态数组，如果不是线程安全，并不建议选择，毕竟同步是有额外开销的。Vector内部是使用对象数组来保存数据，可以根据需要自动的增加容量，当数组已满时，会创建新的数组，并拷贝原有数组数据。</p><p>ArrayList是应用更加广泛的动态数组实现，他本身不是线程安全的，所以性能要好很多。与Vector近似，ArrayList也是可以根据需要调整容量（默认容量为10），不过两者的逻辑有所区别，<strong>Vector扩容时会提高1倍，而ArrayList则是增加50%。</strong></p><p>LinkedList顾名思义是Java提供双向链表，所以它不需要上面两种那样调整容量，他也不是线程安全的。</p>]]></content>
      
      
      <categories>
          
          <category> Java </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Java </tag>
            
            <tag> 面试 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🧔Redis深度历险读书笔记</title>
      <link href="/2020/09/04/Redis%E6%B7%B1%E5%BA%A6%E5%8E%86%E9%99%A9%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/"/>
      <url>/2020/09/04/Redis%E6%B7%B1%E5%BA%A6%E5%8E%86%E9%99%A9%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0%E4%B8%80/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis应用-分布式锁"><a href="#Redis应用-分布式锁" class="headerlink" title="Redis应用-分布式锁"></a>Redis应用-分布式锁</h2><p>分布式应用进行逻辑处理时经常会遇到并发问题。</p><p>比如一个操作要修改用户的状态，修改状态需要先读出用户的状态，在内存里进行修改，改完再存回去。如果这样的操作同时进行了，就会出现并发问题，因为读取和保存的两个操作不是原子的。</p><p>这个时候就要使用到分布式锁来限制程序的并发执行。Redis分布式锁使用非常广泛</p><h3 id="分布式锁"><a href="#分布式锁" class="headerlink" title="分布式锁"></a>分布式锁</h3><p>分布式锁本质上是要实现的目标就是在Redis里面占一个茅坑，当别的进程也要来占坑时，发现已经有人在那里了，就只好放弃或者稍后再试。</p><p>占坑一般是使用setnx （set if not exists）指令，只允许一个客户端占坑。先来先占，用完了，在调用del指令释放茅坑。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;setnx lock:codehole  true</span><br><span class="line">OK</span><br><span class="line">....do something </span><br><span class="line">&gt;del lock:codehole&#39;  &#x2F;&#x2F;用来删除锁</span><br><span class="line">(integer) 1</span><br></pre></td></tr></table></figure><p>但是有个问题，如果逻辑执行到中间出现异常了，可能会导致del指令没有调用，这样就会陷入死锁，锁永远得不到释放。</p><p>于是我们在拿到锁之后，再给锁加上一个过期时间，比如5秒，这样即使中间出现异常也可以保证5秒之后锁会的到释放。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">&gt;setnx lock:codehole true </span><br><span class="line">OK</span><br><span class="line">&gt;expire lock:codehole 5</span><br><span class="line">... do something </span><br><span class="line">&gt;del lockLc:codehole </span><br><span class="line">(integer )1</span><br></pre></td></tr></table></figure><p>但是以上逻辑还是有问题。如果setnx 和 expire 之间服务器进程突然挂掉了，可能是因为机器掉电或者是被认为杀掉的，就可能导致expire得不到执行，也会造成死锁。</p><p>这种问题的根源就在于setnx 和 expire 是两条指令而不是原子指令。如果这两条指令可以一起执行就不会出现问题。</p><p>为了解决这个问题，Redis2.8版本中作者加入了set指令的扩展参数，使得setnx和expire指令可以一起执行了</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&gt;set lock:codehole true ex 5 nx </span><br><span class="line">OK</span><br><span class="line">... dosomething </span><br><span class="line">&gt;del lock:codehole </span><br><span class="line"></span><br></pre></td></tr></table></figure><p>上面的指令就是setnx和expire 组合在一起的原子指令，它就是分布式锁的奥义所在。</p><h3 id="超时问题"><a href="#超时问题" class="headerlink" title="超时问题"></a>超时问题</h3><p>Redis 的分布式锁不能解决超时问题，如果在加锁和释放锁之间的逻辑执行的太长，以至于超出了锁的超时限制，就会出现问题。因为这时候锁过期了，第二个线程重新持有了这把锁，但是紧接着第一个线程执行完了业务逻辑，就把锁给释放了，第三个线程就会在第二个线程逻辑执行完之间拿到了锁。</p><p>为了避免这个问题，Redis分布式锁不要用较长时间的任务。如果真的偶尔出现了，数据的小波错乱可能需人工介入解决</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">tag &#x3D; random.nextint()  # 随机数 </span><br><span class="line">if redis.set(key, tag, nx&#x3D;True, ex&#x3D;5):</span><br><span class="line">do_something() </span><br><span class="line">redis.delifequals(key, tag)  # 假象的 delifequals 指令 </span><br></pre></td></tr></table></figure><p>有一个更加安全的方案是为set指令的value 参数设置为一个随机数，释放锁时先匹配随机数是否一致，然后在删除key。但是匹配value 和 删除key不是一个原子操作，redis也没有提供类似于delifequals这样的指令，这就需要使用Lua脚本来处理了，因为Lua脚本可以保证连续多个指令的原子性操作。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># delifequals </span><br><span class="line">if redis.call(&quot;get&quot;,KEYS[1]) &#x3D;&#x3D; ARGV[1] then    </span><br><span class="line">return redis.call(&quot;del&quot;,KEYS[1]) </span><br><span class="line">else</span><br><span class="line">return 0 end</span><br></pre></td></tr></table></figure><h3 id="可重入性"><a href="#可重入性" class="headerlink" title="可重入性"></a>可重入性</h3><p>可重入性是指线程在持有锁的情况下再次请求加锁，如果这一个锁支持同一个线程多次加锁，那么这个锁就是可重入的。比如Java语言里有个ReentrantLock就是可重入锁。Redis分布式锁如果要支持可重入，需要对客户端的set方法进行包装，使用线程的ThreadLocal变量存储当前持有锁的计数。</p><h3 id="扩展"><a href="#扩展" class="headerlink" title="扩展"></a>扩展</h3><p>在集群环境下，主节点挂掉时，从节点会取而代之，客户端上却并没有明显感知。原先第一个客户端在主节点中申请成功了一把锁，但是这把锁还没有来的及同步到从节点，主节点突然挂掉了。然后从节点变成了主节点，这个新的节点内部没有这把锁，所以但另一个客户端进来请求加锁时，立即就批准了。这样就会导致系统中同样一把锁被两个客户端同时持有，不安全由此产生。</p><p>不过这种不安全也仅仅是在主从发生 failover 的情况下才会产生，而且持续时间极短，业务系统多数情况下可以容忍。</p><h4 id="Redlock算法"><a href="#Redlock算法" class="headerlink" title="Redlock算法"></a>Redlock算法</h4><p>为了解决这个问题，Antirez发明了Redlock算法，他的流程比较复杂，不过有了很多开源的library做了良好的封装，用户拿来用即可</p><p>为了使用 Redlock，需要提供多个 Redis 实例，这些实例之前相互独立没有主从关系。同很多分布式算法一样，redlock 也使用「大多数机制」。 加锁时，它会向过半节点发送 set(key, value, nx=True, ex=xxx) 指令，只要过半节点 set 成功，那就认为加锁成功。释放锁时，需要向所有节点发送 del 指令。不过 Redlock 算法还需要考虑出错重试、时钟漂移等很多细节问题，同时因为 Redlock 需要向多个节点进行读写，意味着相比单实例 Redis 性能会下降一些</p><h4 id="Redlock使用场景"><a href="#Redlock使用场景" class="headerlink" title="Redlock使用场景"></a>Redlock使用场景</h4><p>如果你很在乎高可用性，希望挂了一台 redis 完全不受影响，那就应该考虑 redlock。不过代价也是有的，需要更多的 redis 实例，性能也下降了，代码上还需要引入额外的 library，运维上也需要特殊对待，这些都是需要考虑的成本，使用前请再三斟酌</p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis深度历险 </tag>
            
            <tag> 读书笔记 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🧔Redis内存淘汰机制</title>
      <link href="/2020/09/04/Redis%E7%9A%84%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6%E4%BB%A5%E5%8F%8A%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E6%9C%BA%E5%88%B6/"/>
      <url>/2020/09/04/Redis%E7%9A%84%E5%86%85%E5%AD%98%E6%B7%98%E6%B1%B0%E6%9C%BA%E5%88%B6%E4%BB%A5%E5%8F%8A%E6%8C%81%E4%B9%85%E5%8C%96%E7%9A%84%E6%9C%BA%E5%88%B6/</url>
      
        <content type="html"><![CDATA[<p>Redis中有个设置时间过期的功能，即对存储在redis中的值可以设置一个过期时间。如果设置了一批key只能存活1个小时，那么1小时候，redis会把这写key直接全部删掉吗？ redis是怎么做的呢？</p><p>redis主要采用两种机制来处理过起了的key，他并没有直接删除掉。</p><h4 id="定期删除"><a href="#定期删除" class="headerlink" title="定期删除"></a>定期删除</h4><p>定期删除：redis默认每个100ms就<strong>随机抽取</strong>一些设置了过期时间的key，检查其是否过期，如果过期了就删除，但是这里的key是随机抽取出来的，因为如果redis里有大量的key都设置了过期时间，每个100s去遍历所有的过期key，无疑会给cup带来压力。</p><h4 id="惰性删除"><a href="#惰性删除" class="headerlink" title="惰性删除"></a>惰性删除</h4><p>惰性删除：定期删除可能会导致很多的key到了过期时间，却没有被删除掉，这导致redis中存在很多无用的key，除非系统去查一下这个key，这个key才会被redis给删除掉。这就是所谓的惰性删除。</p><p>但是仅仅通过这两种策略还是有问题的，如果没有及时去查，大量的过期key堆积在内存中，导致redis内存被消耗尽了。怎么解决呢？那就是redis的内存淘汰机制。</p><p>redis提供了6中数据淘汰策略：</p><ol><li>volatile-lru：从已设置过期时间的数据集中挑选最近最少使用的淘汰。</li><li>volatile-ttl：从已设置过期时间的数据集中挑选将要过期的key淘汰。</li><li>volatile-random：从已设置过期时间的数据集中随机淘汰。</li><li>allkeys-lru：当前内存不足已容纳新写入的数据是，在所有的键中，挑选最近最少使用的键进行删除。</li><li>allkeys-random：从数据集中任意选择数据淘汰。</li><li>no-eviction：禁止驱逐数据，内存不足时就报错。</li></ol><h3 id="redis的持久化机制-怎么保证redis挂掉之后在重启数据可以恢复"><a href="#redis的持久化机制-怎么保证redis挂掉之后在重启数据可以恢复" class="headerlink" title="redis的持久化机制(怎么保证redis挂掉之后在重启数据可以恢复)"></a>redis的持久化机制(怎么保证redis挂掉之后在重启数据可以恢复)</h3><p>很多时候我们需要持久化数据也就是将内存中的数据写入到硬盘里面，为的是重启机器，机器故障后恢复。</p><p>Redis支持两种不同的持久化操作，Redis的一种持久化方式叫快照（RDB），另外一种方式是只追加文件（append-only-file，AOF）。这两种方式各有千秋。</p><h4 id="快照持久化（RDB）"><a href="#快照持久化（RDB）" class="headerlink" title="快照持久化（RDB）"></a>快照持久化（RDB）</h4><p>Redis可以通过创建快照来获得存储在内存里面的数据在某个时间节点上的副本。Redis创建快照之后，可以对快照进行备份，可以将快照复制到其他服务器从而创建具有相同数据的服务器副本（Redis主从结构），还可以在原地以便重启服务器的时候使用。</p><p>Redis默认采用快照持久化，在redis.conf配置文件中默认有此下配置：</p><pre><code>save 900 1 #在900s之后，如果至少有1个key发生变化，Redis就会自动触发BGSAVE命令创建快照。save 300 10 #在300s之后，如果至少有10个key发生变化，Redis就会自动触发BGSAVE命令创建快照。save 60 10000 #在60s之后，如果至少有10000个key发生变化，Redis就会自动触发BGSAVE命令创建快照。</code></pre><h4 id="AOF-持久化"><a href="#AOF-持久化" class="headerlink" title="AOF 持久化"></a>AOF 持久化</h4><p>与快照持久化相比，AOF有更好的实时性。默认情况下Redis没有开启AOF方式的持久化，可以通过appendonly参数开启：</p><pre><code>appendonly yes</code></pre><p>开启AOF持久化后每执行一条会更改Redis中的数据命令，Redis机会将该命令写入硬盘中的AOF文件。AOF文件的保存位置和RDB文件的位置相同，都是通过dir参数设置的，默认的文件名是appledonly.aof</p><p>在Redis的配置文件中存在三种不同的AOF持久化方式，分别是：</p><pre><code>appendfsync always   #每次有数据修改发生时都会写入AOF文件，这样会严重降低Reids的速度appendfsync everysec #每秒同步一次，显示的将多个写命令同步到磁盘appendfsync no       #让操作系统决定何时进行同步</code></pre><p>建议使用appendfsync everysec选项，让Redis每秒只同步一次AOF文件，Redis性能几乎没有受到任何影响。即使系统崩掉，最多只会丢失一秒之内产生的数据。</p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>Redis 还可以同时使用 AOF 持久化和 RDB 持久化。 在这种情况下， 当 Redis 重启时， 它会优先使用 AOF 文件来还原数据集， 因为 AOF 文件保存的数据集通常比 RDB 文件所保存的数据集更完整。</p><h3 id="RDB的优点"><a href="#RDB的优点" class="headerlink" title="RDB的优点"></a>RDB的优点</h3><ul><li><p>RDB的文件非常紧凑，他保存redis在某个时间上的数据集。</p></li><li><p>RDB适合灾难恢复：他只有一个文件，并且文件非常紧凑。</p></li><li><p>RDB可以最大化节省Redis的性能：父进程在保存RDB的时候只需要<strong>fork</strong>出一个进程即可，父进程无需执行磁盘的IO。</p></li><li><p>RDB在恢复大数据集的时候要比AOF快。</p><h3 id="RDB的缺点"><a href="#RDB的缺点" class="headerlink" title="RDB的缺点"></a>RDB的缺点</h3></li><li><p>如果你要尽量避免Redis在出问题的时候丢失数据，那RDB可能不合适，一旦停机他可能会失去好几分钟的数据。相信这是没人可以接受的。</p></li><li><p>每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。 在数据集比较庞大时， fork() 可能会非常耗时，造成服务器在某某毫秒内停止处理客户端； 如果数据集非常巨大，并且 CPU 时间非常紧张的话，那么这种停止时间甚至可能会长达整整一秒。 虽然 AOF 重写也需要进行 fork() ，但无论 AOF 重写的执行间隔有多长，数据的耐久性都不会有任何损失。</p></li></ul><h3 id="AOF的优点"><a href="#AOF的优点" class="headerlink" title="AOF的优点"></a>AOF的优点</h3><ul><li>使用AOF会让Redis变得非常耐久，比如：你可以设置不同的策略，比如每秒钟同步一次，一秒钟同步一次(默认)，每写一次同步一次，默认就可以很节省性能，而且最多也就丢失一秒的数据。</li><li>AOF 文件是一个只进行追加操作的日志文件（append only log）， 因此对 AOF 文件的写入不需要进行 seek ， 即使日志因为某些原因而包含了未写入完整的命令（比如写入时磁盘已满，写入中途停机，等等）， redis-check-aof 工具也可以轻易地修复这种问题。</li><li>Redis 可以在 AOF 文件体积变得过大时，自动地在后台对 AOF 进行重写： 重写后的新 AOF 文件包含了恢复当前数据集所需的最小命令集合。 整个重写操作是绝对安全的，因为 Redis 在创建新 AOF 文件的过程中，会继续将命令追加到现有的 AOF 文件里面，即使重写过程中发生停机，现有的 AOF 文件也不会丢失。 而一旦新 AOF 文件创建完毕，Redis 就会从旧 AOF 文件切换到新 AOF 文件，并开始对新 AOF 文件进行追加操作。</li></ul><h3 id="AOF的缺点"><a href="#AOF的缺点" class="headerlink" title="AOF的缺点"></a>AOF的缺点</h3><ul><li>对于相同的数据集来说，AOF的文件大小要比RDB的大。</li><li>根据所使用的 fsync 策略，AOF 的速度可能会慢于 RDB 。 在一般情况下， 每秒 fsync 的性能依然非常高， 而关闭 fsync 可以让 AOF 的速度和 RDB 一样快， 即使在高负荷之下也是如此。 不过在处理巨大的写入载入时，RDB 可以提供更有保证的最大延迟时间（latency）。</li></ul>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 内存淘汰机制 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🧔Redis基础知识</title>
      <link href="/2020/09/04/Redis%E7%AE%80%E4%BB%8B/"/>
      <url>/2020/09/04/Redis%E7%AE%80%E4%BB%8B/</url>
      
        <content type="html"><![CDATA[<h2 id="Redis简介"><a href="#Redis简介" class="headerlink" title="Redis简介"></a>Redis简介</h2><p>简单来说redis就是一个数据库，不过与传统的数据库不同的是<br>redis的数据是存在内存中的，所以读写速度非常快，因此redis被广泛应用于缓存方向。另外，redis也经常来做分布式锁。redis提供了多种数据类型来支持不同的业务场景。</p><h2 id="Redis常见的数据结构以及使用场景分析"><a href="#Redis常见的数据结构以及使用场景分析" class="headerlink" title="Redis常见的数据结构以及使用场景分析"></a>Redis常见的数据结构以及使用场景分析</h2><h3 id="String"><a href="#String" class="headerlink" title="String"></a>String</h3><pre><code>常用命令：set，get，decr，incr，mget等。</code></pre><p>String数据结构是简单的key-value类型，value其实不仅可以是String，也可以是数字。常规计数：微博数，粉丝数等。</p><h3 id="Hash"><a href="#Hash" class="headerlink" title="Hash"></a>Hash</h3><pre><code>常用命令：hget，hset，hgetall等。</code></pre><p>hash是一个string类型的field和value的映射表，hash特别适合用于存储对象，后续操作的时候，你可以直接仅仅修改这个对象中的某个字段的值。比如:</p><pre><code>key=uservalue=&#123;    &quot;id&quot;:1,    &quot;name&quot;:&quot;test&quot;,    &quot;age&quot;:22&#125;</code></pre><h3 id="List"><a href="#List" class="headerlink" title="List"></a>List</h3><pre><code>常用命令：lpush，rpush，lpop，lrange</code></pre><p>List就是链表，Redis list的应用场景非常多，也是Redis最重要的数据结构之一，比如微博的关注列表，粉丝列表，消息列表。</p><p>Redis list 的实现为一个双向链表，既可以支持方向查找和遍历，更方便操作，不过带来了额外的内存开销。</p><p>另外可以通过lrange命令，就是从某个元素的开始读取多少个元素，可以基于list实现分页查询，这个很棒，基于redis实现简单的高性能分页，可以做类似微博那种下拉不断分页的东西，性能高。</p><h3 id="Set"><a href="#Set" class="headerlink" title="Set"></a>Set</h3><pre><code>常用命令：sadd，spop，smembers，sinion等</code></pre><p>set对外提供的功能与list类似是一个列表的功能，特殊之外在于set是可以排重的。</p><p>当你需要存储一个列表数据，又不希望有重复数据时，set时一个很好的选择，并且set提供了判断某个成员是否在一个set集合内的重要接口，这个时list不能提供的。可以通过set轻易实现交集，并集，补集，差集。</p><pre><code>判断member是否在set中    sismember key member    存在返回1，0表示不存在或者key不存在    </code></pre><p>比如：在微博应用中，将一个用户的所有关注存在一个set中，并将其粉丝存在一个集合中，redis可以非常方便的实现共同关注，共同爱好的功能。</p><pre><code>sinterstore dstkey key1...keyN   将key1~keyn的交集存入dskey中</code></pre><h3 id="Sorted-Set"><a href="#Sorted-Set" class="headerlink" title="Sorted Set"></a>Sorted Set</h3><pre><code>常用命令：zadd，zrange，zrem，zcard等</code></pre><p>和set相比sorted set增加了一个权重参数score，使得集合中的元素能够按照score进行排序。</p><p>举例：在直播系统中，实时排行信息包含直播间在线用户列表，各种礼物排行榜，弹幕消息等信息。</p><h3 id="redis设置过期时间"><a href="#redis设置过期时间" class="headerlink" title="redis设置过期时间"></a>redis设置过期时间</h3><p>Redis中有个设置时间过期的功能，即对存储在redis数据库中的值可以设置一个过期时间。作为一个缓存数据库，这是非常实用的。如短信验证码。</p><p>在set key的时候，都可以给一个expire time，就是过期时间，通过过期时间指定这个key可以存过的时间。</p><p><strong>下篇文章介绍redis的内存淘汰机制</strong></p>]]></content>
      
      
      <categories>
          
          <category> Redis </category>
          
      </categories>
      
      
        <tags>
            
            <tag> Redis </tag>
            
            <tag> 缓存 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🕵️‍♂️RabbitMQ 实现延迟消息（以订单超时为例）</title>
      <link href="/2020/09/04/RabbitMQ%20%E5%AE%9E%E7%8E%B0%E5%BB%B6%E8%BF%9F%E6%B6%88%E6%81%AF%EF%BC%88%E4%BB%A5%E8%AE%A2%E5%8D%95%E8%B6%85%E6%97%B6%E4%B8%BA%E4%BE%8B%EF%BC%89/"/>
      <url>/2020/09/04/RabbitMQ%20%E5%AE%9E%E7%8E%B0%E5%BB%B6%E8%BF%9F%E6%B6%88%E6%81%AF%EF%BC%88%E4%BB%A5%E8%AE%A2%E5%8D%95%E8%B6%85%E6%97%B6%E4%B8%BA%E4%BE%8B%EF%BC%89/</url>
      
        <content type="html"><![CDATA[<h5 id="铺垫"><a href="#铺垫" class="headerlink" title="铺垫"></a>铺垫</h5><p>RabbitMQ延迟消息以来的是其死信机制</p><p>首先启动RabbitMQ服务器，并在配置文件配置好相关配置</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">rabbitmq:</span></span><br><span class="line">  <span class="attr">host:</span> <span class="string">localhost</span>      <span class="comment"># ip地址</span></span><br><span class="line">  <span class="attr">port:</span> <span class="number">5672</span>           <span class="comment"># 端口</span></span><br><span class="line">  <span class="attr">virtual-host:</span> <span class="string">/mall</span>  <span class="comment">#虚拟机</span></span><br><span class="line">  <span class="attr">username:</span> <span class="string">mall</span>       <span class="comment">#用户名</span></span><br><span class="line">  <span class="attr">password:</span> <span class="string">mall</span>       <span class="comment">#密码</span></span><br><span class="line">  <span class="attr">publisher-confirms:</span> <span class="literal">true</span></span><br></pre></td></tr></table></figure><p><strong>整体流程图</strong><br><img src="http://www.yinshi.网址:8090/upload/2020/3/%E6%9C%AA%E5%91%BD%E5%90%8D%E6%96%87%E4%BB%B6-4ec6438a8a3c486cb45a4c8f462d4017.png" alt="延迟消息.png"></p><h3 id="一、使用SpringDataRabbitMQ配置MQ的交换机与队列"><a href="#一、使用SpringDataRabbitMQ配置MQ的交换机与队列" class="headerlink" title="一、使用SpringDataRabbitMQ配置MQ的交换机与队列"></a>一、使用SpringDataRabbitMQ配置MQ的交换机与队列</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Configuration</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">RabbitMqConfig</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *订单队列中消息超时后将消息发送到这个交换机</span></span><br><span class="line"><span class="comment">     * 相当于死信交换机</span></span><br><span class="line"><span class="comment">     * */</span></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function">DirectExchange <span class="title">orderDirect</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (DirectExchange) ExchangeBuilder.directExchange(<span class="string">&quot;order.exchange&quot;</span>)</span><br><span class="line">                .durable(<span class="keyword">true</span>)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 将订单消息推送到订单队列的交换机</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * */</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> DirectExchange <span class="title">orderTtlDirect</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> (DirectExchange) ExchangeBuilder.directExchange(<span class="string">&quot;order.ttl.exchange&quot;</span>)</span><br><span class="line">                .durable(<span class="keyword">true</span>)</span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     *接收取消订单的消息队列(超时后消息转发到这个队列)</span></span><br><span class="line"><span class="comment">     * **/</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Queue <span class="title">orderQueue</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> <span class="keyword">new</span> Queue(<span class="string">&quot;order.queue&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 接收订单的消息队列，到期后转发消息转发到orderDirect</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     * **/</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Queue <span class="title">orderTtlQueue</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> QueueBuilder.durable(<span class="string">&quot;orderTtl.queue&quot;</span>)</span><br><span class="line">                .withArgument(<span class="string">&quot;x-dead-letter-exchange&quot;</span>,<span class="string">&quot;order.exchange&quot;</span>) <span class="comment">//过期后发送的交换机</span></span><br><span class="line">                .withArgument(<span class="string">&quot;x-dead-letter-routing-key&quot;</span>,<span class="string">&quot;order&quot;</span>) <span class="comment">//过期后发送的routingkey</span></span><br><span class="line">                .build();</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 绑定订单队列到交换机</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Binding <span class="title">orderTtlBinding</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> BindingBuilder.bind(orderTtlQueue())</span><br><span class="line">                .to(orderTtlDirect())</span><br><span class="line">                .with(<span class="string">&quot;orderTtl&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">    <span class="comment">/**</span></span><br><span class="line"><span class="comment">     * 取消订单的消息绑定交换机</span></span><br><span class="line"><span class="comment">     *</span></span><br><span class="line"><span class="comment">     */</span></span><br><span class="line"></span><br><span class="line">    <span class="meta">@Bean</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> Binding <span class="title">orderBinding</span><span class="params">()</span></span>&#123;</span><br><span class="line">        <span class="keyword">return</span> BindingBuilder.bind(orderQueue())</span><br><span class="line">                .to(orderDirect())</span><br><span class="line">                .with(<span class="string">&quot;order&quot;</span>);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="二、添加消息发送方"><a href="#二、添加消息发送方" class="headerlink" title="二、添加消息发送方"></a>二、添加消息发送方</h3><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Component</span></span><br><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">CancelOrderSender</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">private</span> <span class="keyword">static</span> Logger logger = LoggerFactory.getLogger(CancelOrderSender.class);</span><br><span class="line"></span><br><span class="line">    <span class="meta">@Autowired</span></span><br><span class="line">    <span class="keyword">private</span> RabbitTemplate rabbitTemplate;</span><br><span class="line"></span><br><span class="line">    <span class="comment">//消息类型为Long的订单id</span></span><br><span class="line">    <span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">sendMessage</span><span class="params">(Long orderId)</span></span>&#123;</span><br><span class="line">        rabbitTemplate.convertAndSend(<span class="string">&quot;order.ttl.exchange&quot;</span>,<span class="string">&quot;orderTtl&quot;</span></span><br><span class="line">                , orderId, <span class="keyword">new</span> MessagePostProcessor() &#123;</span><br><span class="line">                    <span class="meta">@Override</span></span><br><span class="line">                    <span class="function"><span class="keyword">public</span> Message <span class="title">postProcessMessage</span><span class="params">(Message message)</span> <span class="keyword">throws</span> AmqpException </span>&#123;</span><br><span class="line">                        message.getMessageProperties().setExpiration(<span class="string">&quot;5000&quot;</span>);<span class="comment">//过期时间为5秒</span></span><br><span class="line">                        <span class="keyword">return</span> message;</span><br><span class="line">                    &#125;</span><br><span class="line">                &#125;);</span><br><span class="line">        logger.info(<span class="string">&quot;send delay message orderId:&#123;&#125;&quot;</span>,orderId);</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="三、启动测试查看日志输出"><a href="#三、启动测试查看日志输出" class="headerlink" title="三、启动测试查看日志输出"></a>三、启动测试查看日志输出</h3><p>5秒后收到了过期的消息</p><p><img src="http://www.yinshi.网址:8090/upload/2020/3/TIM%E6%88%AA%E5%9B%BE20200307231052-aac98a5ba4e0447fbb81a4fcf1b114f4.png" alt="TIM截图20200307231052.png"></p><p>到此结束！</p>]]></content>
      
      
      <categories>
          
          <category> RabbitMQ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RabbitMQ </tag>
            
            <tag> 消息队列 </tag>
            
            <tag> 延迟队列 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>🧙‍♀️RabbitMQ入门</title>
      <link href="/2020/09/04/RabbitMQ%E5%85%A5%E9%97%A8/"/>
      <url>/2020/09/04/RabbitMQ%E5%85%A5%E9%97%A8/</url>
      
        <content type="html"><![CDATA[<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>RabbitMQ是由erlang语言开发，基于AMQP（Advanced Message Queue 高级消息队列协议）协议实现的消息队列，它是一种应用程序之间的通信方法，消息队列在分布式系统开发中应用非常广泛。</p><h1 id="相关定义"><a href="#相关定义" class="headerlink" title="相关定义"></a>相关定义</h1><ul><li>Broker： 简单来说就是消息队列服务器实体</li><li>Exchange：它指定消息按什么规则，路由到哪个队列</li><li>Queue：消息队列的载体，每个消息都会投入到一个或多个消息队列中</li><li>Binding：绑定，它的作用就是把exchange和queue按照路由规则绑定起来</li><li>Routing Key： 路由关键字，exchange根据这个关键字进行消息投递</li><li>VHost： 虚拟主机，一个broker里可以开设多个vhost，用作不同用户的权限分离。</li><li>Producer： 消息生产者，就是投递消息的程序</li><li>Consumer： 消息消费者，就是接受消息的程序</li><li>Channel： 消息通道，在客户端的每个连接里，可建立多个channel，每个channel代表一个会话任务</li></ul><p><strong>由Exchange、Queue、RoutingKey三个才能决定一个从Exchange到Queue的唯一的线路。</strong></p><h1 id="RabbitMQ的工作模式"><a href="#RabbitMQ的工作模式" class="headerlink" title="RabbitMQ的工作模式"></a>RabbitMQ的工作模式</h1><p> RabbitMQ的官方网站中一共介绍了6种工作模式。<a href="https://www.rabbitmq.com/getstarted.html">6种工作模式</a></p><h4 id=""><a href="#" class="headerlink" title=""></a></h4><h3 id="1-Hello-world-简单模式"><a href="#1-Hello-world-简单模式" class="headerlink" title="1. Hello world 简单模式"></a>1. Hello world 简单模式</h3><p><img src="https://static01.imgkr.com/temp/9f706b05f5b64d91917014687d6cbab6.png" alt="image.png"></p><p>P：生产者：也就是要发送消息的程序</p><p>C：消费者：消息的接受者会监听消息生产者，会一直等待消息到来</p><p>应用场景: 聊天</p><p><strong>Producter 如果发送消息时，如果发送的队列没有绑定交换机和routing key的话，那么将会使用默认的交换机并且将发送的消息队列名作为routing key</strong></p><h3 id="2-Work-queues-工作模式"><a href="#2-Work-queues-工作模式" class="headerlink" title="2. Work queues 工作模式"></a>2. Work queues 工作模式</h3><p><img src="https://static01.imgkr.com/temp/ec86c4977cc44aa3adb78db41dd31934.png" alt="image.png"></p><p>多个消费者监听只听同一名称的队列消费消息（消费者属于竞争关系）</p><h3 id="3-Publish-发布与订阅模式"><a href="#3-Publish-发布与订阅模式" class="headerlink" title="3.Publish 发布与订阅模式"></a>3.Publish 发布与订阅模式</h3><p><img src="https://static01.imgkr.com/temp/3e843a1e17d34746a32c8889331d6e47.png" alt="image.png"></p><p>这种模式添加了一个角色X即交换机Exchange</p><p>多个队列绑定相同的交换机接收相同的消息<br>多个消费者监听相对的队列接收相同的消息</p><p><strong>这种模式需要使用fanout 类型的交换机，这种交换机不处理routing key 只需要将队列绑定到交换机上就可以，因此，fanout类型的交换机转发消息是最快的。</strong> </p><h3 id="4-Routing-路由模式"><a href="#4-Routing-路由模式" class="headerlink" title="4.Routing 路由模式"></a>4.Routing 路由模式</h3><p><img src="https://static01.imgkr.com/temp/b8baa95a8bed4f27b3b0fbc6206f2784.png" alt="image.png"></p><p><strong>队列通过routingkey 绑定 direct类型的交换机，生产者向交换机发送消息时，也需要指定相应的routingkey 交换机就会把这个routingkey对应的消息发送到绑定改rotingkey的队列中，如果routingkey不一致则交换机不会把消息发送到队列中</strong></p><h3 id="5-Topics-通配符模式"><a href="#5-Topics-通配符模式" class="headerlink" title="5.Topics 通配符模式"></a>5.Topics 通配符模式</h3><p><img src="https://static01.imgkr.com/temp/6e3323bea2cc4dbbb733948431929e67.png" alt="image.png">v</p><p>Exchange：使用topic模式的交换机，这种类型的交换机与direct相比就是在绑定routingkey时可以使用通配符</p><p>通配符匹配规则</p><p>#：匹配一个或多个词</p><p>*：匹配不多不少恰好1个词</p><p>举例：</p><p><strong>item.#：</strong> 能够匹配<code>item.insert.abc</code>或者<code>item.insert</code></p><p>*<em>item.<em>：</em></em>只能匹配<code>item.insert</code></p>]]></content>
      
      
      <categories>
          
          <category> RabbitMQ </category>
          
      </categories>
      
      
        <tags>
            
            <tag> RabbitMQ </tag>
            
            <tag> 消息队列 </tag>
            
        </tags>
      
    </entry>
    
    
  
  
</search>
